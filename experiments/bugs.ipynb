{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JFd0ppeJyX1o"
   },
   "source": [
    "## **Bug Report**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "id": "2c7S2VEH1I97"
   },
   "source": [
    "#### Pegasus Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 540
    },
    "executionInfo": {
     "elapsed": 19204,
     "status": "error",
     "timestamp": 1607356631227,
     "user": {
      "displayName": "Marco Pietro Abrate",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gjh-8YF-8BlnrkN9mLZ0xfVOWfOh7kYncpYRv-Y=s64",
      "userId": "15422244832836998434"
     },
     "user_tz": -60
    },
    "hidden": true,
    "id": "YTogmPWX1K4i",
    "outputId": "dd1335af-6636-4ce5-8271-b9bce5dbaa14"
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-075cd8fd6c62>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtransformers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPegasusTokenizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPegasusTokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'google/pegasus-large'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/transformers/utils/dummy_sentencepiece_objects.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m         \u001b[0mrequires_sentencepiece\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/transformers/file_utils.py\u001b[0m in \u001b[0;36mrequires_sentencepiece\u001b[0;34m(obj)\u001b[0m\n\u001b[1;32m    459\u001b[0m     \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"__name__\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    460\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_sentencepiece_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 461\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSENTENCEPIECE_IMPORT_ERROR\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    462\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    463\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: \nPegasusTokenizer requires the SentencePiece library but it was not found in your environment. Checkout the instructions on the\ninstallation page of its repo: https://github.com/google/sentencepiece#installation and follow the ones\nthat match your environment.\n",
      "",
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install -U transformers\n",
    "\n",
    "from transformers import PegasusTokenizer\n",
    "tokenizer = PegasusTokenizer.from_pretrained('google/pegasus-large')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3309,
     "status": "ok",
     "timestamp": 1607356656413,
     "user": {
      "displayName": "Marco Pietro Abrate",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gjh-8YF-8BlnrkN9mLZ0xfVOWfOh7kYncpYRv-Y=s64",
      "userId": "15422244832836998434"
     },
     "user_tz": -60
    },
    "hidden": true,
    "id": "Wd0sR4WH69gi",
    "outputId": "e916e5e6-4d4b-4dd2-c007-e816d5d577c8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sentencepiece\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e5/2d/6d4ca4bef9a67070fa1cac508606328329152b1df10bdf31fb6e4e727894/sentencepiece-0.1.94-cp36-cp36m-manylinux2014_x86_64.whl (1.1MB)\n",
      "\r",
      "\u001b[K     |▎                               | 10kB 24.0MB/s eta 0:00:01\r",
      "\u001b[K     |▋                               | 20kB 30.8MB/s eta 0:00:01\r",
      "\u001b[K     |▉                               | 30kB 22.9MB/s eta 0:00:01\r",
      "\u001b[K     |█▏                              | 40kB 17.8MB/s eta 0:00:01\r",
      "\u001b[K     |█▌                              | 51kB 13.7MB/s eta 0:00:01\r",
      "\u001b[K     |█▊                              | 61kB 15.1MB/s eta 0:00:01\r",
      "\u001b[K     |██                              | 71kB 14.2MB/s eta 0:00:01\r",
      "\u001b[K     |██▍                             | 81kB 14.3MB/s eta 0:00:01\r",
      "\u001b[K     |██▋                             | 92kB 14.3MB/s eta 0:00:01\r",
      "\u001b[K     |███                             | 102kB 14.7MB/s eta 0:00:01\r",
      "\u001b[K     |███▎                            | 112kB 14.7MB/s eta 0:00:01\r",
      "\u001b[K     |███▌                            | 122kB 14.7MB/s eta 0:00:01\r",
      "\u001b[K     |███▉                            | 133kB 14.7MB/s eta 0:00:01\r",
      "\u001b[K     |████▏                           | 143kB 14.7MB/s eta 0:00:01\r",
      "\u001b[K     |████▍                           | 153kB 14.7MB/s eta 0:00:01\r",
      "\u001b[K     |████▊                           | 163kB 14.7MB/s eta 0:00:01\r",
      "\u001b[K     |█████                           | 174kB 14.7MB/s eta 0:00:01\r",
      "\u001b[K     |█████▎                          | 184kB 14.7MB/s eta 0:00:01\r",
      "\u001b[K     |█████▋                          | 194kB 14.7MB/s eta 0:00:01\r",
      "\u001b[K     |█████▉                          | 204kB 14.7MB/s eta 0:00:01\r",
      "\u001b[K     |██████▏                         | 215kB 14.7MB/s eta 0:00:01\r",
      "\u001b[K     |██████▌                         | 225kB 14.7MB/s eta 0:00:01\r",
      "\u001b[K     |██████▊                         | 235kB 14.7MB/s eta 0:00:01\r",
      "\u001b[K     |███████                         | 245kB 14.7MB/s eta 0:00:01\r",
      "\u001b[K     |███████▍                        | 256kB 14.7MB/s eta 0:00:01\r",
      "\u001b[K     |███████▋                        | 266kB 14.7MB/s eta 0:00:01\r",
      "\u001b[K     |████████                        | 276kB 14.7MB/s eta 0:00:01\r",
      "\u001b[K     |████████▎                       | 286kB 14.7MB/s eta 0:00:01\r",
      "\u001b[K     |████████▌                       | 296kB 14.7MB/s eta 0:00:01\r",
      "\u001b[K     |████████▉                       | 307kB 14.7MB/s eta 0:00:01\r",
      "\u001b[K     |█████████                       | 317kB 14.7MB/s eta 0:00:01\r",
      "\u001b[K     |█████████▍                      | 327kB 14.7MB/s eta 0:00:01\r",
      "\u001b[K     |█████████▊                      | 337kB 14.7MB/s eta 0:00:01\r",
      "\u001b[K     |██████████                      | 348kB 14.7MB/s eta 0:00:01\r",
      "\u001b[K     |██████████▎                     | 358kB 14.7MB/s eta 0:00:01\r",
      "\u001b[K     |██████████▋                     | 368kB 14.7MB/s eta 0:00:01\r",
      "\u001b[K     |██████████▉                     | 378kB 14.7MB/s eta 0:00:01\r",
      "\u001b[K     |███████████▏                    | 389kB 14.7MB/s eta 0:00:01\r",
      "\u001b[K     |███████████▌                    | 399kB 14.7MB/s eta 0:00:01\r",
      "\u001b[K     |███████████▊                    | 409kB 14.7MB/s eta 0:00:01\r",
      "\u001b[K     |████████████                    | 419kB 14.7MB/s eta 0:00:01\r",
      "\u001b[K     |████████████▍                   | 430kB 14.7MB/s eta 0:00:01\r",
      "\u001b[K     |████████████▋                   | 440kB 14.7MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████                   | 450kB 14.7MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████▎                  | 460kB 14.7MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████▌                  | 471kB 14.7MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████▉                  | 481kB 14.7MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████                  | 491kB 14.7MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████▍                 | 501kB 14.7MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████▊                 | 512kB 14.7MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████                 | 522kB 14.7MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████▎                | 532kB 14.7MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████▋                | 542kB 14.7MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████▉                | 552kB 14.7MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████▏               | 563kB 14.7MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████▌               | 573kB 14.7MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████▊               | 583kB 14.7MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████               | 593kB 14.7MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████▍              | 604kB 14.7MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████▋              | 614kB 14.7MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████              | 624kB 14.7MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████▏             | 634kB 14.7MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████▌             | 645kB 14.7MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████▉             | 655kB 14.7MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████             | 665kB 14.7MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████▍            | 675kB 14.7MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████▊            | 686kB 14.7MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████            | 696kB 14.7MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████▎           | 706kB 14.7MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████▋           | 716kB 14.7MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████▉           | 727kB 14.7MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████▏          | 737kB 14.7MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████▌          | 747kB 14.7MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████▊          | 757kB 14.7MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████          | 768kB 14.7MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████▎         | 778kB 14.7MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████▋         | 788kB 14.7MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████         | 798kB 14.7MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████▏        | 808kB 14.7MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████▌        | 819kB 14.7MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████▉        | 829kB 14.7MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████        | 839kB 14.7MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████▍       | 849kB 14.7MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████▊       | 860kB 14.7MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████       | 870kB 14.7MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████▎      | 880kB 14.7MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████▋      | 890kB 14.7MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████▉      | 901kB 14.7MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████▏     | 911kB 14.7MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████▌     | 921kB 14.7MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████▊     | 931kB 14.7MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████     | 942kB 14.7MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████▎    | 952kB 14.7MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████▋    | 962kB 14.7MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████    | 972kB 14.7MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████▏   | 983kB 14.7MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████▌   | 993kB 14.7MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████▉   | 1.0MB 14.7MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████████   | 1.0MB 14.7MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████████▍  | 1.0MB 14.7MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████████▊  | 1.0MB 14.7MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████████  | 1.0MB 14.7MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████████▎ | 1.1MB 14.7MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████████▋ | 1.1MB 14.7MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████████▉ | 1.1MB 14.7MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████████▏| 1.1MB 14.7MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████████▍| 1.1MB 14.7MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████████▊| 1.1MB 14.7MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████████| 1.1MB 14.7MB/s \n",
      "\u001b[?25hInstalling collected packages: sentencepiece\n",
      "Successfully installed sentencepiece-0.1.94\n"
     ]
    }
   ],
   "source": [
    "!pip install sentencepiece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 540
    },
    "executionInfo": {
     "elapsed": 2964,
     "status": "error",
     "timestamp": 1607356656415,
     "user": {
      "displayName": "Marco Pietro Abrate",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gjh-8YF-8BlnrkN9mLZ0xfVOWfOh7kYncpYRv-Y=s64",
      "userId": "15422244832836998434"
     },
     "user_tz": -60
    },
    "hidden": true,
    "id": "wrC60jzO7AMR",
    "outputId": "55c9d420-7e33-4288-87f7-e48b1d8fad4f"
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-075cd8fd6c62>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtransformers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPegasusTokenizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPegasusTokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'google/pegasus-large'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/transformers/utils/dummy_sentencepiece_objects.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m         \u001b[0mrequires_sentencepiece\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/transformers/file_utils.py\u001b[0m in \u001b[0;36mrequires_sentencepiece\u001b[0;34m(obj)\u001b[0m\n\u001b[1;32m    459\u001b[0m     \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"__name__\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    460\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_sentencepiece_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 461\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSENTENCEPIECE_IMPORT_ERROR\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    462\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    463\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: \nPegasusTokenizer requires the SentencePiece library but it was not found in your environment. Checkout the instructions on the\ninstallation page of its repo: https://github.com/google/sentencepiece#installation and follow the ones\nthat match your environment.\n",
      "",
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from transformers import PegasusTokenizer\n",
    "tokenizer = PegasusTokenizer.from_pretrained('google/pegasus-large')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "id": "Cxw3lbFR1ElM"
   },
   "source": [
    "#### Length Penalty Not Influencing Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9955,
     "status": "ok",
     "timestamp": 1607359913246,
     "user": {
      "displayName": "Marco Pietro Abrate",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gjh-8YF-8BlnrkN9mLZ0xfVOWfOh7kYncpYRv-Y=s64",
      "userId": "15422244832836998434"
     },
     "user_tz": -60
    },
    "hidden": true,
    "id": "bD457AZtBGvE",
    "outputId": "440faf46-7740-47f9-943c-62aaaa137da2",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/99/84/7bc03215279f603125d844bf81c3fb3f2d50fe8e511546eb4897e4be2067/transformers-4.0.0-py3-none-any.whl (1.4MB)\n",
      "\r",
      "\u001b[K     |▎                               | 10kB 21.2MB/s eta 0:00:01\r",
      "\u001b[K     |▌                               | 20kB 15.3MB/s eta 0:00:01\r",
      "\u001b[K     |▊                               | 30kB 13.2MB/s eta 0:00:01\r",
      "\u001b[K     |█                               | 40kB 12.1MB/s eta 0:00:01\r",
      "\u001b[K     |█▏                              | 51kB 8.7MB/s eta 0:00:01\r",
      "\u001b[K     |█▌                              | 61kB 9.4MB/s eta 0:00:01\r",
      "\u001b[K     |█▊                              | 71kB 9.3MB/s eta 0:00:01\r",
      "\u001b[K     |██                              | 81kB 9.4MB/s eta 0:00:01\r",
      "\u001b[K     |██▏                             | 92kB 9.4MB/s eta 0:00:01\r",
      "\u001b[K     |██▍                             | 102kB 8.4MB/s eta 0:00:01\r",
      "\u001b[K     |██▋                             | 112kB 8.4MB/s eta 0:00:01\r",
      "\u001b[K     |███                             | 122kB 8.4MB/s eta 0:00:01\r",
      "\u001b[K     |███▏                            | 133kB 8.4MB/s eta 0:00:01\r",
      "\u001b[K     |███▍                            | 143kB 8.4MB/s eta 0:00:01\r",
      "\u001b[K     |███▋                            | 153kB 8.4MB/s eta 0:00:01\r",
      "\u001b[K     |███▉                            | 163kB 8.4MB/s eta 0:00:01\r",
      "\u001b[K     |████▏                           | 174kB 8.4MB/s eta 0:00:01\r",
      "\u001b[K     |████▍                           | 184kB 8.4MB/s eta 0:00:01\r",
      "\u001b[K     |████▋                           | 194kB 8.4MB/s eta 0:00:01\r",
      "\u001b[K     |████▉                           | 204kB 8.4MB/s eta 0:00:01\r",
      "\u001b[K     |█████                           | 215kB 8.4MB/s eta 0:00:01\r",
      "\u001b[K     |█████▎                          | 225kB 8.4MB/s eta 0:00:01\r",
      "\u001b[K     |█████▋                          | 235kB 8.4MB/s eta 0:00:01\r",
      "\u001b[K     |█████▉                          | 245kB 8.4MB/s eta 0:00:01\r",
      "\u001b[K     |██████                          | 256kB 8.4MB/s eta 0:00:01\r",
      "\u001b[K     |██████▎                         | 266kB 8.4MB/s eta 0:00:01\r",
      "\u001b[K     |██████▌                         | 276kB 8.4MB/s eta 0:00:01\r",
      "\u001b[K     |██████▉                         | 286kB 8.4MB/s eta 0:00:01\r",
      "\u001b[K     |███████                         | 296kB 8.4MB/s eta 0:00:01\r",
      "\u001b[K     |███████▎                        | 307kB 8.4MB/s eta 0:00:01\r",
      "\u001b[K     |███████▌                        | 317kB 8.4MB/s eta 0:00:01\r",
      "\u001b[K     |███████▊                        | 327kB 8.4MB/s eta 0:00:01\r",
      "\u001b[K     |████████                        | 337kB 8.4MB/s eta 0:00:01\r",
      "\u001b[K     |████████▎                       | 348kB 8.4MB/s eta 0:00:01\r",
      "\u001b[K     |████████▌                       | 358kB 8.4MB/s eta 0:00:01\r",
      "\u001b[K     |████████▊                       | 368kB 8.4MB/s eta 0:00:01\r",
      "\u001b[K     |█████████                       | 378kB 8.4MB/s eta 0:00:01\r",
      "\u001b[K     |█████████▏                      | 389kB 8.4MB/s eta 0:00:01\r",
      "\u001b[K     |█████████▌                      | 399kB 8.4MB/s eta 0:00:01\r",
      "\u001b[K     |█████████▊                      | 409kB 8.4MB/s eta 0:00:01\r",
      "\u001b[K     |██████████                      | 419kB 8.4MB/s eta 0:00:01\r",
      "\u001b[K     |██████████▏                     | 430kB 8.4MB/s eta 0:00:01\r",
      "\u001b[K     |██████████▍                     | 440kB 8.4MB/s eta 0:00:01\r",
      "\u001b[K     |██████████▋                     | 450kB 8.4MB/s eta 0:00:01\r",
      "\u001b[K     |███████████                     | 460kB 8.4MB/s eta 0:00:01\r",
      "\u001b[K     |███████████▏                    | 471kB 8.4MB/s eta 0:00:01\r",
      "\u001b[K     |███████████▍                    | 481kB 8.4MB/s eta 0:00:01\r",
      "\u001b[K     |███████████▋                    | 491kB 8.4MB/s eta 0:00:01\r",
      "\u001b[K     |███████████▉                    | 501kB 8.4MB/s eta 0:00:01\r",
      "\u001b[K     |████████████▏                   | 512kB 8.4MB/s eta 0:00:01\r",
      "\u001b[K     |████████████▍                   | 522kB 8.4MB/s eta 0:00:01\r",
      "\u001b[K     |████████████▋                   | 532kB 8.4MB/s eta 0:00:01\r",
      "\u001b[K     |████████████▉                   | 542kB 8.4MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████                   | 552kB 8.4MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████▎                  | 563kB 8.4MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████▋                  | 573kB 8.4MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████▉                  | 583kB 8.4MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████                  | 593kB 8.4MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████▎                 | 604kB 8.4MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████▌                 | 614kB 8.4MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████▉                 | 624kB 8.4MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████                 | 634kB 8.4MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████▎                | 645kB 8.4MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████▌                | 655kB 8.4MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████▊                | 665kB 8.4MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████                | 675kB 8.4MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████▎               | 686kB 8.4MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████▌               | 696kB 8.4MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████▊               | 706kB 8.4MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████               | 716kB 8.4MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████▏              | 727kB 8.4MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████▌              | 737kB 8.4MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████▊              | 747kB 8.4MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████              | 757kB 8.4MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████▏             | 768kB 8.4MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████▍             | 778kB 8.4MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████▋             | 788kB 8.4MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████             | 798kB 8.4MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████▏            | 808kB 8.4MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████▍            | 819kB 8.4MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████▋            | 829kB 8.4MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████▉            | 839kB 8.4MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████▏           | 849kB 8.4MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████▍           | 860kB 8.4MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████▋           | 870kB 8.4MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████▉           | 880kB 8.4MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████           | 890kB 8.4MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████▎          | 901kB 8.4MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████▋          | 911kB 8.4MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████▉          | 921kB 8.4MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████          | 931kB 8.4MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████▎         | 942kB 8.4MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████▌         | 952kB 8.4MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████▉         | 962kB 8.4MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████         | 972kB 8.4MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████▎        | 983kB 8.4MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████▌        | 993kB 8.4MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████▊        | 1.0MB 8.4MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████        | 1.0MB 8.4MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████▎       | 1.0MB 8.4MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████▌       | 1.0MB 8.4MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████▊       | 1.0MB 8.4MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████       | 1.1MB 8.4MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████▏      | 1.1MB 8.4MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████▌      | 1.1MB 8.4MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████▊      | 1.1MB 8.4MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████      | 1.1MB 8.4MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████▏     | 1.1MB 8.4MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████▍     | 1.1MB 8.4MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████▋     | 1.1MB 8.4MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████     | 1.1MB 8.4MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████▏    | 1.1MB 8.4MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████▍    | 1.2MB 8.4MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████▋    | 1.2MB 8.4MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████▉    | 1.2MB 8.4MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████▏   | 1.2MB 8.4MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████▍   | 1.2MB 8.4MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████▋   | 1.2MB 8.4MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████▉   | 1.2MB 8.4MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████████   | 1.2MB 8.4MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████████▎  | 1.2MB 8.4MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████████▋  | 1.2MB 8.4MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████████▉  | 1.3MB 8.4MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████████  | 1.3MB 8.4MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████████▎ | 1.3MB 8.4MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████████▌ | 1.3MB 8.4MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████████▉ | 1.3MB 8.4MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████████ | 1.3MB 8.4MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████████▎| 1.3MB 8.4MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████████▌| 1.3MB 8.4MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████████▊| 1.3MB 8.4MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████████| 1.4MB 8.4MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████████| 1.4MB 8.4MB/s \n",
      "\u001b[?25hRequirement already satisfied, skipping upgrade: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
      "Requirement already satisfied, skipping upgrade: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.8)\n",
      "Requirement already satisfied, skipping upgrade: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
      "Collecting tokenizers==0.9.4\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0f/1c/e789a8b12e28be5bc1ce2156cf87cb522b379be9cadc7ad8091a4cc107c4/tokenizers-0.9.4-cp36-cp36m-manylinux2010_x86_64.whl (2.9MB)\n",
      "\u001b[K     |████████████████████████████████| 2.9MB 30.8MB/s \n",
      "\u001b[?25hCollecting sacremoses\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
      "\u001b[K     |████████████████████████████████| 890kB 53.9MB/s \n",
      "\u001b[?25hRequirement already satisfied, skipping upgrade: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.5)\n",
      "Requirement already satisfied, skipping upgrade: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
      "Requirement already satisfied, skipping upgrade: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
      "Requirement already satisfied, skipping upgrade: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.4)\n",
      "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.11.8)\n",
      "Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n",
      "Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
      "Requirement already satisfied, skipping upgrade: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
      "Requirement already satisfied, skipping upgrade: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.15.0)\n",
      "Requirement already satisfied, skipping upgrade: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
      "Requirement already satisfied, skipping upgrade: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.17.0)\n",
      "Requirement already satisfied, skipping upgrade: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n",
      "Building wheels for collected packages: sacremoses\n",
      "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893257 sha256=c46ba148644ea32f45c97612119dac247c1ce061a2fa7c06b05fbc885e2aec7f\n",
      "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
      "Successfully built sacremoses\n",
      "Installing collected packages: tokenizers, sacremoses, transformers\n",
      "Successfully installed sacremoses-0.0.43 tokenizers-0.9.4 transformers-4.0.0\n",
      "Collecting sentencepiece\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e5/2d/6d4ca4bef9a67070fa1cac508606328329152b1df10bdf31fb6e4e727894/sentencepiece-0.1.94-cp36-cp36m-manylinux2014_x86_64.whl (1.1MB)\n",
      "\u001b[K     |████████████████████████████████| 1.1MB 8.4MB/s \n",
      "\u001b[?25hInstalling collected packages: sentencepiece\n",
      "Successfully installed sentencepiece-0.1.94\n"
     ]
    }
   ],
   "source": [
    "!pip install -U transformers\n",
    "!pip install sentencepiece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 104,
     "referenced_widgets": [
      "ae89cb8da37b4973a788be1b5e6b3414",
      "ff19f372faba4c5d858adc458c6461b9",
      "bc016971b8f24f29949de3f78b2336cd",
      "9932097da8de489da0674e2867668886",
      "748c6acaa0ba44e1a2306e1c07ceeb05"
     ]
    },
    "executionInfo": {
     "elapsed": 136524,
     "status": "ok",
     "timestamp": 1607360039829,
     "user": {
      "displayName": "Marco Pietro Abrate",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gjh-8YF-8BlnrkN9mLZ0xfVOWfOh7kYncpYRv-Y=s64",
      "userId": "15422244832836998434"
     },
     "user_tz": -60
    },
    "hidden": true,
    "id": "yCzod0OizR5U",
    "outputId": "e001d880-5762-45d6-c445-a5d5acdffc78"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae89cb8da37b4973a788be1b5e6b3414",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1912529.0, style=ProgressStyle(descript…"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff19f372faba4c5d858adc458c6461b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=65.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc016971b8f24f29949de3f78b2336cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=88.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9932097da8de489da0674e2867668886",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=2866.0, style=ProgressStyle(description…"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "748c6acaa0ba44e1a2306e1c07ceeb05",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=2275327883.0, style=ProgressStyle(descr…"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers import PegasusTokenizer\n",
    "tokenizer = PegasusTokenizer.from_pretrained('google/pegasus-large')\n",
    "from transformers import PegasusForConditionalGeneration\n",
    "model = PegasusForConditionalGeneration.from_pretrained('google/pegasus-large').to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "id": "V6A3oy_X36--"
   },
   "outputs": [],
   "source": [
    "articles =\\\n",
    "'''Editor's note: In our Behind the Scenes series, CNN correspondents share their experiences in covering news and analyze the stories behind the events. Here, Soledad O'Brien takes users inside a jail where many of the inmates are mentally ill. An inmate housed on the \"forgotten floor,\" where many mentally ill inmates are housed in Miami before trial. MIAMI, Florida (CNN) -- The ninth floor of the Miami-Dade pretrial detention facility is dubbed the \"forgotten floor.\" Here, inmates with the most severe mental illnesses are incarcerated until they're ready to appear in court. Most often, they face drug charges or charges of assaulting an officer --charges that Judge Steven Leifman says are usually \"avoidable felonies.\" He says the arrests often result from confrontations with police. Mentally ill people often won't do what they're told when police arrive on the scene -- confrontation seems to exacerbate their illness and they become more paranoid, delusional, and less likely to follow directions, according to Leifman. So, they end up on the ninth floor severely mentally disturbed, but not getting any real help because they're in jail. We toured the jail with Leifman. He is well known in Miami as an advocate for justice and the mentally ill. Even though we were not exactly welcomed with open arms by the guards, we were given permission to shoot videotape and tour the floor.  Go inside the 'forgotten floor' » . At first, it's hard to determine where the people are. The prisoners are wearing sleeveless robes. Imagine cutting holes for arms and feet in a heavy wool sleeping bag -- that's kind of what they look like. They're designed to keep the mentally ill patients from injuring themselves. That's also why they have no shoes, laces or mattresses. Leifman says about one-third of all people in Miami-Dade county jails are mentally ill. So, he says, the sheer volume is overwhelming the system, and the result is what we see on the ninth floor. Of course, it is a jail, so it's not supposed to be warm and comforting, but the lights glare, the cells are tiny and it's loud. We see two, sometimes three men -- sometimes in the robes, sometimes naked, lying or sitting in their cells. \"I am the son of the president. You need to get me out of here!\" one man shouts at me. He is absolutely serious, convinced that help is on the way -- if only he could reach the White House. Leifman tells me that these prisoner-patients will often circulate through the system, occasionally stabilizing in a mental hospital, only to return to jail to face their charges. It's brutally unjust, in his mind, and he has become a strong advocate for changing things in Miami. Over a meal later, we talk about how things got this way for mental patients. Leifman says 200 years ago people were considered \"lunatics\" and they were locked up in jails even if they had no charges against them. They were just considered unfit to be in society. Over the years, he says, there was some public outcry, and the mentally ill were moved out of jails and into hospitals. But Leifman says many of these mental hospitals were so horrible they were shut down. Where did the patients go? Nowhere. The streets. They became, in many cases, the homeless, he says. They never got treatment. Leifman says in 1955 there were more than half a million people in state mental hospitals, and today that number has been reduced 90 percent, and 40,000 to 50,000 people are in mental hospitals. The judge says he's working to change this. Starting in 2008, many inmates who would otherwise have been brought to the \"forgotten floor\"  will instead be sent to a new mental health facility -- the first step on a journey toward long-term treatment, not just punishment. Leifman says it's not the complete answer, but it's a start. Leifman says the best part is that it's a win-win solution. The patients win, the families are relieved, and the state saves money by simply not cycling these prisoners through again and again. And, for Leifman, justice is served. E-mail to a friend .\n",
    "LONDON, England (Reuters) -- Harry Potter star Daniel Radcliffe gains access to a reported £20 million ($41.1 million) fortune as he turns 18 on Monday, but he insists the money won't cast a spell on him. Daniel Radcliffe as Harry Potter in \"Harry Potter and the Order of the Phoenix\" To the disappointment of gossip columnists around the world, the young actor says he has no plans to fritter his cash away on fast cars, drink and celebrity parties. \"I don't plan to be one of those people who, as soon as they turn 18, suddenly buy themselves a massive sports car collection or something similar,\" he told an Australian interviewer earlier this month. \"I don't think I'll be particularly extravagant. \"The things I like buying are things that cost about 10 pounds -- books and CDs and DVDs.\" At 18, Radcliffe will be able to gamble in a casino, buy a drink in a pub or see the horror film \"Hostel: Part II,\" currently six places below his number one movie on the UK box office chart. Details of how he'll mark his landmark birthday are under wraps. His agent and publicist had no comment on his plans. \"I'll definitely have some sort of party,\" he said in an interview. \"Hopefully none of you will be reading about it.\" Radcliffe's earnings from the first five Potter films have been held in a trust fund which he has not been able to touch. Despite his growing fame and riches, the actor says he is keeping his feet firmly on the ground. \"People are always looking to say 'kid star goes off the rails,'\" he told reporters last month. \"But I try very hard not to go that way because it would be too easy for them.\" His latest outing as the boy wizard in \"Harry Potter and the Order of the Phoenix\" is breaking records on both sides of the Atlantic and he will reprise the role in the last two films.  Watch I-Reporter give her review of Potter's latest » . There is life beyond Potter, however. The Londoner has filmed a TV movie called \"My Boy Jack,\" about author Rudyard Kipling and his son, due for release later this year. He will also appear in \"December Boys,\" an Australian film about four boys who escape an orphanage. Earlier this year, he made his stage debut playing a tortured teenager in Peter Shaffer's \"Equus.\" Meanwhile, he is braced for even closer media scrutiny now that he's legally an adult: \"I just think I'm going to be more sort of fair game,\" he told Reuters. E-mail to a friend . Copyright 2007 Reuters. All rights reserved.This material may not be published, broadcast, rewritten, or redistributed.\n",
    "MINNEAPOLIS, Minnesota (CNN) -- Drivers who were on the Minneapolis bridge when it collapsed told harrowing tales of survival. \"The whole bridge from one side of the Mississippi to the other just completely gave way, fell all the way down,\" survivor Gary Babineau told CNN. \"I probably had a 30-, 35-foot free fall. And there's cars in the water, there's cars on fire. The whole bridge is down.\" He said his back was injured but he determined he could move around. \"I realized there was a school bus right next to me, and me and a couple of other guys went over and started lifting the kids off the bridge. They were yelling, screaming, bleeding. I think there were some broken bones.\"  Watch a driver describe his narrow escape » . At home when he heard about the disaster, Dr. John Hink, an emergency room physician, jumped into his car and rushed to the scene in 15 minutes. He arrived at the south side of the bridge, stood on the riverbank and saw dozens of people lying dazed on an expansive deck. They were in the middle of the Mississippi River, which was churning fast, and he had no way of getting to them. He went to the north side, where there was easier access to people. Ambulances were also having a hard time driving down to the river to get closer to the scene. Working feverishly, volunteers, EMTs and other officials managed to get 55 people into ambulances in less than two hours. Occasionally, a pickup truck with a medic inside would drive to get an injured person and bring him back up even ground, Hink told CNN. The rescue effort was controlled and organized, he said; the opposite of the lightning-quick collapse. \"I could see the whole bridge as it was going down, as it was falling,\" Babineau said. \"It just gave a rumble real quick, and it all just gave way, and it just fell completely, all the way to the ground. And there was dust everywhere and it was just like everyone has been saying: It was just like out of the movies.\" Babineau said the rear of his pickup truck was dangling over the edge of a broken-off section of the bridge. He said several vehicles slid past him into the water. \"I stayed in my car for one or two seconds. I saw a couple cars fall,\" he said. \"So I stayed in my car until the cars quit falling for a second, then I got out real quick, ran in front of my truck -- because behind my truck was just a hole -- and I helped a woman off of the bridge with me. \"I just wanted off the bridge, and then I ran over to the school bus. I started grabbing kids and handing them down. It was just complete chaos.\" He said most of the children were crying or screaming. He and other rescuers set them on the ground and told them to run to the river bank, but a few needed to be carried because of their injuries.  See rescuers clamber over rubble » . Babineau said he had no rescue training. \"I just knew what I had to do at the moment.\" Melissa Hughes, 32, of Minneapolis, told The Associated Press that she was driving home when the western edge of the bridge collapsed under her. \"You know that free-fall feeling? I felt that twice,\" Hughes said. A pickup landed on top of her car, but she was not hurt. \"I had no idea there was a vehicle on my car,\" she told AP. \"It's really very surreal.\" Babineau told the Minneapolis Star-Tribune: \"On the way down, I thought I was dead. I literally thought I was dead. \"My truck was completely face down, pointed toward the ground, and my truck got ripped in half. It was folded in half, and I can't believe I'm alive.\"  See and hear eyewitness accounts » . Bernie Toivonen told CNN's \"American Morning\" that his vehicle was on a part of the bridge that ended up tilted at a 45-degree angle. \"I knew the deck was going down, there was no question about it, and I thought I was going to die,\" he said. After the bridge settled and his car remained upright, \"I just put in park, turned the key off and said, 'Oh, I'm alive,' \" he said. E-mail to a friend .\n",
    "BAGHDAD, Iraq (CNN) -- Dressed in a Superman shirt, 5-year-old Youssif held his sister's hand Friday, seemingly unaware that millions of people across the world have been touched by his story. Nearby, his parents talked about the new future and hope they have for their boy -- and the potential for recovery from his severe burns. Youssif holds his sister's hand Friday. He's wearing a facial mask often used to help burn victims. It's the best birthday present the Iraqi family could ever have imagined for their boy: Youssif turns 6 next Friday. \"I was so happy I didn't know what to do with myself,\" his mother, Zainab, told CNN, a broad smile across her face. \"I didn't think the reaction would be this big.\" His father said he was on the roof of his house when CNN called him with the news about the outpouring of support for his son. \"We just want to thank everyone who has come forward,\" he said. \"We knew there was kindness out there.\" Like his wife, he couldn't stop smiling. He talked about how he tried in vain to get help for his son in Baghdad, leaving \"no stone unturned\" on a mission to help his boy. There were many trips to the Ministry of Health. He says he even put in a request to Iraq's parliament for help. The family eventually told CNN their story -- that Youssif was grabbed by masked men outside their home on January 15, doused in gasoline and set on fire. Simply by coming forward, his parents put themselves in incredible danger. No one has been arrested or held accountable in Youssif's case.  Watch CNN's Arwa Damon describe 'truly phenomenal' outpouring » . Shortly after Youssif's story aired Wednesday, the Children's Burn Foundation -- a nonprofit organization based in Sherman Oaks, California, that provides support for burn victims locally, nationally and internationally -- agreed to pay for the transportation for Youssif and his family to come to the United States and to set up a fund for donations. You can make a donation at the foundation's site by clicking here. There's a drop-down menu under the \"general donation\" area that is marked \"Youssif's fund.\" The foundation says it will cover all medical costs -- from surgeries for Youssif to housing costs to any social rehabilitation that might be needed for him. Surgeries will be performed by Dr. Peter Grossman, a plastic surgeon with the affiliated Grossman Burn Center who is donating his services for Youssif's cause. Officials are still trying to get the appropriate visas for the family's travels. \"We are prepared to have them come here, set them up in a housing situation, provide support for them and begin treatment,\" said Barbara Friedman, executive director of the Children's Burn Foundation. \"We expect that the treatment will be from between six months to a year with many surgeries.\" She added, \"He will be getting the absolute best care that's available.\" Youssif's parents said they know it's going to be a lengthy and difficult process and that adjusting to their stay in America may not be easy. But none of that matters -- getting help for their boy is first and foremost. \"I will do anything for Youssif,\" his father said, pulling his son closer to him. \"Our child is everything.\" His mother tried to coax Youssif to talk to us on this day. But he didn't want to; his mother says he's shy outside of their home. The biggest obstacle now is getting the visas to leave, and the serious security risks they face every day and hour they remain in Iraq. But this family -- which saw the very worst in humanity on that January day -- has new hope in the world. That is partly due to the tens of thousands of CNN.com users who were so moved by the story and wanted to act. CNN Iraqi staff central to bringing this story together were also overwhelmed with the generosity coming from people outside of their border. In a nation that largely feels abandoned by the rest of the world, it was a refreshing realization. E-mail to a friend . CNN.com senior producer Wayne Drash contributed to this report in Atlanta.\n",
    "WASHINGTON (CNN) -- Doctors removed five small polyps from President Bush's colon on Saturday, and \"none appeared worrisome,\" a White House spokesman said. The polyps were removed and sent to the National Naval Medical Center in Bethesda, Maryland, for routine microscopic examination, spokesman Scott Stanzel said. Results are expected in two to three days. All were small, less than a centimeter [half an inch] in diameter, he said. Bush is in good humor, Stanzel said, and will resume his activities at Camp David. During the procedure Vice President Dick Cheney assumed presidential power. Bush reclaimed presidential power at 9:21 a.m. after about two hours. Doctors used \"monitored anesthesia care,\" Stanzel said, so the president was asleep, but not as deeply unconscious as with a true general anesthetic. He spoke to first lady Laura Bush -- who is in Midland, Texas, celebrating her mother's birthday -- before and after the procedure, Stanzel said. Afterward, the president played with his Scottish terriers, Barney and Miss Beazley, Stanzel said. He planned to have lunch at Camp David and have briefings with National Security Adviser Stephen Hadley and White House Chief of Staff Josh Bolten, and planned to take a bicycle ride Saturday afternoon. Cheney, meanwhile, spent the morning at his home on Maryland's eastern shore, reading and playing with his dogs, Stanzel said. Nothing occurred that required him to take official action as president before Bush reclaimed presidential power. The procedure was supervised by Dr. Richard Tubb, Bush's physician, and conducted by a multidisciplinary team from the National Naval Medical Center in Bethesda, Maryland, the White House said. Bush's last colonoscopy was in June 2002, and no abnormalities were found, White House spokesman Tony Snow said. The president's doctor had recommended a repeat procedure in about five years. A colonoscopy is the most sensitive test for colon cancer, rectal cancer and polyps, small clumps of cells that can become cancerous, according to the Mayo Clinic. Small polyps may be removed during the procedure. Snow said on Friday that Bush had polyps removed during colonoscopies before becoming president. Snow himself is undergoing chemotherapy for cancer that began in his colon and spread to his liver.  Watch Snow talk about Bush's procedure and his own colon cancer » . \"The president wants to encourage everybody to use surveillance,\" Snow said. The American Cancer Society recommends that people without high risk factors or symptoms begin getting screened for signs of colorectal cancer at age 50. E-mail to a friend .\n",
    "(CNN)  -- The National Football League has indefinitely suspended Atlanta Falcons quarterback Michael Vick without pay, officials with the league said Friday. NFL star Michael Vick is set to appear in court Monday. A judge will have the final say on a plea deal. Earlier, Vick admitted to participating in a dogfighting ring as part of a plea agreement with federal prosecutors in Virginia. \"Your admitted conduct was not only illegal, but also cruel and reprehensible. Your team, the NFL, and NFL fans have all been hurt by your actions,\" NFL Commissioner Roger Goodell said in a letter to Vick. Goodell said he would review the status of the suspension after the legal proceedings are over. In papers filed Friday with a federal court in Virginia, Vick also admitted that he and two co-conspirators killed dogs that did not fight well. Falcons owner Arthur Blank said Vick's admissions describe actions that are \"incomprehensible and unacceptable.\" The suspension makes \"a strong statement that conduct which tarnishes the good reputation of the NFL will not be tolerated,\" he said in a statement.  Watch what led to Vick's suspension » . Goodell said the Falcons could \"assert any claims or remedies\" to recover $22 million of Vick's signing bonus from the 10-year, $130 million contract he signed in 2004, according to The Associated Press. Vick said he would plead guilty to one count of \"Conspiracy to Travel in Interstate Commerce in Aid of Unlawful Activities and to Sponsor a Dog in an Animal Fighting Venture\" in a plea agreement filed at U.S. District Court in Richmond, Virginia. The charge is punishable by up to five years in prison, a $250,000 fine, \"full restitution, a special assessment and 3 years of supervised release,\" the plea deal said. Federal prosecutors agreed to ask for the low end of the sentencing guidelines. \"The defendant will plead guilty because the defendant is in fact guilty of the charged offense,\" the plea agreement said. In an additional summary of facts, signed by Vick and filed with the agreement, Vick admitted buying pit bulls and the property used for training and fighting the dogs, but the statement said he did not bet on the fights or receive any of the money won. \"Most of the 'Bad Newz Kennels' operations and gambling monies were provided by Vick,\" the official summary of facts said. Gambling wins were generally split among co-conspirators Tony Taylor, Quanis Phillips and sometimes Purnell Peace, it continued. \"Vick did not gamble by placing side bets on any of the fights. Vick did not receive any of the proceeds from the purses that were won by 'Bad Newz Kennels.' \" Vick also agreed that \"collective efforts\" by him and two others caused the deaths of at least six dogs. Around April, Vick, Peace and Phillips tested some dogs in fighting sessions at Vick's property in Virginia, the statement said. \"Peace, Phillips and Vick agreed to the killing of approximately 6-8 dogs that did not perform well in 'testing' sessions at 1915 Moonlight Road and all of those dogs were killed by various methods, including hanging and drowning. \"Vick agrees and stipulates that these dogs all died as a result of the collective efforts of Peace, Phillips and Vick,\" the summary said. Peace, 35, of Virginia Beach, Virginia; Phillips, 28, of Atlanta, Georgia; and Taylor, 34, of Hampton, Virginia, already have accepted agreements to plead guilty in exchange for reduced sentences. Vick, 27, is scheduled to appear Monday in court, where he is expected to plead guilty before a judge.  See a timeline of the case against Vick » . The judge in the case will have the final say over the plea agreement. The federal case against Vick focused on the interstate conspiracy, but Vick's admission that he was involved in the killing of dogs could lead to local charges, according to CNN legal analyst Jeffrey Toobin. \"It sometimes happens -- not often -- that the state will follow a federal prosecution by charging its own crimes for exactly the same behavior,\" Toobin said Friday. \"The risk for Vick is, if he makes admissions in his federal guilty plea, the state of Virginia could say, 'Hey, look, you admitted violating Virginia state law as well. We're going to introduce that against you and charge you in our court.' \" In the plea deal, Vick agreed to cooperate with investigators and provide all information he may have on any criminal activity and to testify if necessary. Vick also agreed to turn over any documents he has and to submit to polygraph tests. Vick agreed to \"make restitution for the full amount of the costs associated\" with the dogs that are being held by the government. \"Such costs may include, but are not limited to, all costs associated with the care of the dogs involved in that case, including if necessary, the long-term care and/or the humane euthanasia of some or all of those animals.\" Prosecutors, with the support of animal rights activists, have asked for permission to euthanize the dogs. But the dogs could serve as important evidence in the cases against Vick and his admitted co-conspirators. Judge Henry E. Hudson issued an order Thursday telling the U.S. Marshals Service to \"arrest and seize the defendant property, and use discretion and whatever means appropriate to protect and maintain said defendant property.\" Both the judge's order and Vick's filing refer to \"approximately\" 53 pit bull dogs. After Vick's indictment last month, Goodell ordered the quarterback not to report to the Falcons training camp, and the league is reviewing the case. Blank told the NFL Network on Monday he could not speculate on Vick's future as a Falcon, at least not until he had seen \"a statement of facts\" in the case.  E-mail to a friend . CNN's Mike Phelan contributed to this report.\n",
    "BAGHDAD, Iraq (CNN) -- The women are too afraid and ashamed to show their faces or have their real names used. They have been driven to sell their bodies to put food on the table for their children -- for as little as $8 a day. Suha, 37, is a mother of three. She says her husband thinks she is cleaning houses when she leaves home. \"People shouldn't criticize women, or talk badly about them,\" says 37-year-old Suha as she adjusts the light colored scarf she wears these days to avoid extremists who insist women cover themselves. \"They all say we have lost our way, but they never ask why we had to take this path.\" A mother of three, she wears light makeup, a gold pendant of Iraq around her neck, and an unexpected air of elegance about her. \"I don't have money to take my kid to the doctor. I have to do anything that I can to preserve my child, because I am a mother,\" she says, explaining why she prostitutes herself. Anger and frustration rise in her voice as she speaks. \"No matter what else I may be, no matter how off the path I may be, I am a mother!\"  Watch a woman describe turning to prostitution to \"save my child\" » . Her clasped hands clench and unclench nervously. Suha's husband thinks that she is cleaning houses when she goes away. So does Karima's family. \"At the start I was cleaning homes, but I wasn't making much. No matter how hard I worked it just wasn't enough,\" she says. Karima, clad in all black, adds, \"My husband died of lung cancer nine months ago and left me with nothing.\" She has five children, ages 8 to 17. Her eldest son could work, but she's too afraid for his life to let him go into the streets, preferring to sacrifice herself than risk her child. She was solicited the first time when she was cleaning an office. \"They took advantage of me,\" she says softly. \"At first I rejected it, but then I realized I have to do it.\" Both Suha and Karima have clients that call them a couple times a week. Other women resort to trips to the market to find potential clients. Or they flag down vehicles. Prostitution is a choice more and more Iraqi women are making just to survive. \"It's increasing,\" Suha says. \"I found this 'thing' through my friend, and I have another friend in the same predicament as mine. Because of the circumstance, she is forced to do such things.\" Violence, increased cost of living, and lack of any sort of government aid leave women like these with few other options, according to humanitarian workers. \"At this point there is a population of women who have to sell their bodies in order to keep their children alive,\" says Yanar Mohammed, head and founder of the Organization for Women's Freedom in Iraq. \"It's a taboo that no one is speaking about.\" She adds, \"There is a huge population of women who were the victims of war who had to sell their bodies, their souls and they lost it all. It crushes us to see them, but we have to work on it and that's why we started our team of women activists.\" Her team pounds the streets of Baghdad looking for these victims often too humiliated to come forward. \"Most of the women that we find at hospitals [who] have tried to commit suicide\" have been involved in prostitution, said Basma Rahim, a member of Mohammed's team. The team's aim is to compile information on specific cases and present it to Iraq's political parties -- to have them, as Mohammed puts it, \"come tell us what [they] are ... going to do about this.\" Rahim tells the heartbreaking story of one woman they found who lives in a room with three of her children: \"She has sex while her three children are in the room, but she makes them stand in separate corners.\" According to Rahim and Mohammed, most of the women they encounter say they are driven to prostitution by a desperate desire for survival in the dangerously violent and unforgiving circumstances in Iraq. \"They took this path but they are not pleased,\" Rahim says. Karima says when she sees her children with food on the table, she is able to convince herself that it's worth it. \"Everything is for the children. They are the beauty in life and, without them, we cannot live.\" But she says, \"I would never allow my daughter to do this. I would rather marry her off at 13 than have her go through this.\" Karima's last happy memory is of her late husband, when they were a family and able to shoulder the hardships of life in today's Iraq together. Suha says as a young girl she dreamed of being a doctor, with her mom boasting about her potential in that career. Life couldn't have taken her further from that dream. \"It's not like we were born into this, nor was it ever in my blood,\" she says. What she does for her family to survive now eats away at her. \"I lay on my pillow and my brain is spinning, and it all comes back to me as if I am watching a movie.\" E-mail to a friend .\n",
    "WASHINGTON (CNN) -- White House press secretary Tony Snow, who is undergoing treatment for cancer, will step down from his post September 14 and be replaced by deputy press secretary Dana Perino, the White House announced Friday. White House press secretary Tony Snow will step down from his post on September 14. President Bush told reporters Friday that he will \"sadly accept\" Snow's resignation. Flanked by Snow and Perino in the White House press room, the president spoke warmly of his departing press secretary. \"It's been a joy to watch him spar with you,\" Bush told reporters.  Watch the announcement about Snow leaving » . Bush said he was certain of two things in regard to Snow. \"He'll battle cancer and win,\" Bush said, \"and he'll be a solid contributor to society.\" Turning to Snow, the president then said: \"I love you, and I wish you all the best.\" Snow, speaking after Bush at the start of the daily White House news conference, said he was leaving to earn more money. He took a big pay cut, he said, when he left his previous jobs as anchor and political analyst for Fox News. According to The Washington Post, Snow makes $168,000 as the White House spokesman. His family took out a loan when he started the job, \"and that loan is now gone.\" \"This job has really been a dream for me, a blast. I've had an enormous amount of fun and satisfaction,\" Snow said. He said he would continue to speak out on issues, and would do \"some radio, some TV, but I don't anticipate full-time anchor duties.\" Snow said he's received great satisfaction from talking to people about his illness. Snow's cancer was diagnosed for the first time in February 2005. His colon was removed, and after six months of treatment, doctors said the cancer was in remission. Perino announced March 27 that Snow's cancer had recurred, and that doctors had removed a growth from his abdomen the day before. Sources told CNN two weeks ago that Snow was planning to leave his job, possibly as early as September. Bush tapped Snow to replace Scott McClellan in April 2006. Snow had been an anchor for \"Fox News Sunday\" and a political analyst for the Fox News Channel, which he joined in 1996. He also hosted \"The Tony Snow Show\" on Fox News Radio. On Thursday, Snow told CNN his health is improving, citing two medical tests this month that found the cancer has not spread. \"The tumors are stable -- they are not growing,\" Snow said of the results from an MRI and a CAT scan. \"And there are no new growths. The health is good.\" The press secretary, whose hair has turned gray during chemotherapy treatment, said his black hair is expected to grow back in about a month. \"I'm also putting on weight again,\" he said after returning from a 10-day vacation. \"I actually feel very good about\" the health situation. Snow said on Friday he was to see his oncologist, and they will decide on some minor forms of chemotherapy to start as maintenance treatment. E-mail to a friend .\n",
    "WASHINGTON (CNN) -- As he awaits a crucial progress report on Iraq, President Bush will try to put a twist on comparisons of the war to Vietnam by invoking the historical lessons of that conflict to argue against pulling out. President Bush pauses Tuesday during a news conference at the  North American Leaders summit in Canada. On Wednesday in Kansas City, Missouri, Bush will tell members of the Veterans of Foreign Wars that \"then, as now, people argued that the real problem was America's presence and that if we would just withdraw, the killing would end,\" according to speech excerpts released Tuesday by the White House. \"Three decades later, there is a legitimate debate about how we got into the Vietnam War and how we left,\" Bush will say. \"Whatever your position in that debate, one unmistakable legacy of Vietnam is that the price of America's withdrawal was paid by millions of innocent citizens, whose agonies would add to our vocabulary new terms like 'boat people,' 're-education camps' and 'killing fields,' \" the president will say. The president will also make the argument that withdrawing from Vietnam emboldened today's terrorists by compromising U.S. credibility, citing a quote from al Qaeda leader Osama bin Laden that the American people would rise against the Iraq war the same way they rose against the war in Vietnam, according to the excerpts. \"Here at home, some can argue our withdrawal from Vietnam carried no price to American credibility, but the terrorists see things differently,\" Bush will say. On Tuesday, Democratic Senate Majority Leader Harry Reid said, \"President Bush's attempt to compare the war in Iraq to past military conflicts in East Asia ignores the fundamental difference between the two. Our nation was misled by the Bush Administration in an effort to gain support for the invasion of Iraq under false pretenses, leading to one of the worst foreign policy blunders in our history. \"While the President continues to stay-the-course with his failed strategy in Iraq, paid for by the taxpayers, American lives are being lost and there is still no political solution within the Iraqi government. It is time to change direction in Iraq, and Congress will again work to do so in the fall.\" The White House is billing the speech, along with another address next week to the American Legion, as an effort to \"provide broader context\" for the debate over the upcoming Iraq progress report by Gen. David Petraeus, the top U.S. military commander, and Ryan Crocker, the U.S. ambassador in Baghdad. President Bush has frequently asked lawmakers -- and the American people -- to withhold judgment on his troop \"surge\" in Iraq until the report comes out in September.  Watch Bush criticize the Iraqi government » . It is being closely watched on Capitol Hill, particularly by Republicans nervous about the political fallout from an increasingly unpopular war. Earlier this month, Defense Secretary Robert Gates said he would wait for the report before deciding when a drawdown of the 160,000 U.S. troops in Iraq might begin. Bush's speeches Wednesday and next week are the latest in a series of attempts by the White House to try to reframe the debate over Iraq, as public support for the war continues to sag. A recent CNN/Opinion Research Corporation poll found that almost two-thirds of Americans -- 64 percent -- now oppose the Iraq war, and 72 percent say that even if Petraeus reports progress, it won't change their opinion. The poll also found a great deal of skepticism about the report; 53 percent said they do not trust Petraeus to give an accurate assessment of the situation in Iraq. In addition to his analogy to Vietnam, Bush in Wednesday's speech will invoke other historical comparisons from Asia, including the U.S. defeat and occupation of Japan after World War II and the Korean War in the 1950s, according to the excerpts. \"In the aftermath of Japan's surrender, many thought it naive to help the Japanese transform themselves into a democracy. Then, as now, the critics argued that some people were simply not fit for freedom,\" Bush will say. \"Today, in defiance of the critics, Japan ... stands as one of the world's great free societies.\" Speaking about the Korean War, Bush will note that at the time \"critics argued that the war was futile, that we never should have sent our troops in, or that America's intervention was divisive here at home.\" \"While it is true that the Korean War had its share of challenges, America never broke its word,\" Bush will say. \"Without America's intervention during the war, and our willingness to stick with the South Koreans after the war, millions of South Koreans would now be living under a brutal and repressive regime.\" E-mail to a friend .\n",
    "WASHINGTON (CNN) -- There is \"no remaining hope\" of finding six men trapped for almost a month in a Utah coal mine alive, a federal official said Saturday. Isaac Arellano holds a candle and sings during a fundraiser for miners Tuesday in Price, Utah. \"Over the past 25 days, the Mine Safety and Health Administration has exhausted all known options in our attempt to reach the six miners,\" Richard Stickler, head of the agency, said in a statement. \"The thoughts and prayers of the dedicated professionals at MSHA are with the families.\" Sympathy for the failed efforts also came Saturday from the White House. \"Last night, a difficult decision was made to end the search,\" President Bush said in a statement. \"Laura and I are deeply saddened by this tragedy and continue to pray for the families of these men.\" Labor Secretary Elaine Chao called the ordeal \"heartbreaking.\" \"The grueling around-the-clock rescue operation that claimed three lives and injured six others has also taken a tremendous toll on the many brave rescuers and the local community, and our thoughts and prayers are with them all,\" Chao said in a statement. After drilling seven holes into mine tunnels from the mountaintop above, there has been no sign of the miners -- and microphones have picked up no sound from the men.  See a timeline of rescue efforts » . Tests showed underground oxygen levels were too low to sustain human life. \"We basically told the families that at this point in time we've run out of options,\" Stickler said at a news conference late Friday. \"We've consulted with the people that we have here, we've consulted with the technical support in Pittsburgh and we've consulted with private consultants in terms of where we can go,\" he said. \"And basically, through all the information we've gleaned over the past nearly four weeks in terms of the conditions we found, in terms of the air readings we found down there and ... everything else, we just don't know where else we can put a hole to get any other information.\"  See photos of the rescue mission » . There were no public statements Saturday from Bob Murray, president and CEO of Murray Mining, co-owner of the Crandall Canyon Mine, who was the outspoken face of the rescue operation for the first three weeks, then largely disappeared from public view. Federal officials became the spokesmen. No one from Murray Mining was present at Friday's news conference. \"They are done. It's finished,\" the attorney for the families said, according to the Saturday edition of The Salt Lake Tribune. \"It's a hard and bitter pill for our families, and there were quite a few tears shed,\" the newspaper quotes Colin King as saying. The men were trapped during a collapse on August 6, and it is not known whether they survived the cave-in. Efforts to reach them were suspended 10 days later when two rescuers and a federal mining official were killed, and six people were injured in a second collapse as they tried to tunnel horizontally toward the area where the men had been working. Murray said last week that the search effort would stop if no signs of life were found at the sixth hole. Under pressure from the families, however, he agreed to try one more time. Families wanted officials to drill a hole large enough to send down a rescue capsule. The effort to lower the robotic device down a seventh hole had been called \"a long shot\" by an official. MSHA's Stickler said that hole was drilled into the Crandall Canyon Mine on Thursday, but there were problems with a robotic camera that teams were trying to lower into it. Work resumed Friday, this time at the fourth hole, but the camera could only descend about 7 feet, he said. \"Basically, what it saw was really not that much. There was quite a bit of mud in there, water coming down the hole. It really couldn't go any farther than seven feet,\" he said of the latest try. In addition, the roof was sagging. \"The families asked many, many questions and we answered them all the best we could, basically coming to the conclusion that we had run out of options.\" Murray said last Saturday he has already filed paperwork with federal regulators to permanently close and seal the Crandall Canyon mine. \"I will never come back to that evil mountain,\" he said. Friends and family have identified the six missing miners as Luis Hernandez, Manuel Sanchez, Kerry Allred, Carlos Payan, Brandon Phillips and Don Erickson. E-mail to a friend .'''.split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "id": "Impzorj-4NXc"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.manual_seed(42)\n",
    "\n",
    "summ = {}\n",
    "model.to('cuda')\n",
    "for i, a in enumerate(articles):\n",
    "    summ[i] = []\n",
    "    for lp in [0.1, 1, 2]:\n",
    "        summ[i].append(\n",
    "            tokenizer.decode(\n",
    "                model.generate(\n",
    "                    tokenizer.encode(a, truncation=True, return_tensors='pt').to('cuda'),\n",
    "                    length_penalty=lp)[0],\n",
    "                skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1171,
     "status": "ok",
     "timestamp": 1607360447659,
     "user": {
      "displayName": "Marco Pietro Abrate",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gjh-8YF-8BlnrkN9mLZ0xfVOWfOh7kYncpYRv-Y=s64",
      "userId": "15422244832836998434"
     },
     "user_tz": -60
    },
    "hidden": true,
    "id": "8iqVZcCq-_R1",
    "outputId": "0f232c3a-af84-4c90-9fd2-e7f1d29aa2b1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1 527\n",
      "1 527\n",
      "2 766\n",
      "\n",
      "0.1 713\n",
      "1 713\n",
      "2 713\n",
      "\n",
      "0.1 430\n",
      "1 430\n",
      "2 740\n",
      "\n",
      "0.1 682\n",
      "1 682\n",
      "2 1087\n",
      "\n",
      "0.1 473\n",
      "1 473\n",
      "2 473\n",
      "\n",
      "0.1 304\n",
      "1 980\n",
      "2 980\n",
      "\n",
      "0.1 365\n",
      "1 564\n",
      "2 564\n",
      "\n",
      "0.1 608\n",
      "1 727\n",
      "2 727\n",
      "\n",
      "0.1 524\n",
      "1 524\n",
      "2 820\n",
      "\n",
      "0.1 618\n",
      "1 618\n",
      "2 618\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for k in summ.keys():\n",
    "    for i, lp in enumerate([0.1, 1, 2]):\n",
    "        print(lp, len(summ[k][i]))\n",
    "\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "id": "BpY_Z3uVJM-H"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "id": "CcBlX169bPDf"
   },
   "source": [
    "#### Bug BART XSum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1273,
     "status": "ok",
     "timestamp": 1607954301969,
     "user": {
      "displayName": "Marco Pietro Abrate",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gjh-8YF-8BlnrkN9mLZ0xfVOWfOh7kYncpYRv-Y=s64",
      "userId": "15422244832836998434"
     },
     "user_tz": -60
    },
    "hidden": true,
    "id": "Vuk0CGHHbPDk",
    "outputId": "15c72fe5-5a1b-495c-8fd1-e3ad8ed20a4f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 1609,
     "status": "ok",
     "timestamp": 1607954302459,
     "user": {
      "displayName": "Marco Pietro Abrate",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gjh-8YF-8BlnrkN9mLZ0xfVOWfOh7kYncpYRv-Y=s64",
      "userId": "15422244832836998434"
     },
     "user_tz": -60
    },
    "hidden": true,
    "id": "nsTmVNB5baqH"
   },
   "outputs": [],
   "source": [
    "drive_dir = '/content/drive/My\\ Drive/MAGMA:\\ Summarization/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 15594,
     "status": "ok",
     "timestamp": 1607954316609,
     "user": {
      "displayName": "Marco Pietro Abrate",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gjh-8YF-8BlnrkN9mLZ0xfVOWfOh7kYncpYRv-Y=s64",
      "userId": "15422244832836998434"
     },
     "user_tz": -60
    },
    "hidden": true,
    "id": "ouPGlGkdbWvE",
    "outputId": "95754b39-ae6d-446b-fac3-838066c8467c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already up-to-date: transformers in /usr/local/lib/python3.6/dist-packages (4.0.1)\n",
      "Requirement already satisfied, skipping upgrade: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
      "Requirement already satisfied, skipping upgrade: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.8)\n",
      "Requirement already satisfied, skipping upgrade: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.7)\n",
      "Requirement already satisfied, skipping upgrade: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
      "Requirement already satisfied, skipping upgrade: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers) (0.0.43)\n",
      "Requirement already satisfied, skipping upgrade: tokenizers==0.9.4 in /usr/local/lib/python3.6/dist-packages (from transformers) (0.9.4)\n",
      "Requirement already satisfied, skipping upgrade: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
      "Requirement already satisfied, skipping upgrade: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.5)\n",
      "Requirement already satisfied, skipping upgrade: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
      "Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n",
      "Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
      "Requirement already satisfied, skipping upgrade: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
      "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.12.5)\n",
      "Requirement already satisfied, skipping upgrade: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n",
      "Requirement already satisfied, skipping upgrade: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
      "Requirement already satisfied, skipping upgrade: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.15.0)\n",
      "Requirement already satisfied, skipping upgrade: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.17.0)\n",
      "Requirement already satisfied: pytorch-lightning==1.0.4 in /usr/local/lib/python3.6/dist-packages (1.0.4)\n",
      "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.6/dist-packages (from pytorch-lightning==1.0.4) (5.3.1)\n",
      "Requirement already satisfied: tqdm>=4.41.0 in /usr/local/lib/python3.6/dist-packages (from pytorch-lightning==1.0.4) (4.41.1)\n",
      "Requirement already satisfied: tensorboard>=2.2.0 in /usr/local/lib/python3.6/dist-packages (from pytorch-lightning==1.0.4) (2.3.0)\n",
      "Requirement already satisfied: fsspec>=0.8.0 in /usr/local/lib/python3.6/dist-packages (from pytorch-lightning==1.0.4) (0.8.4)\n",
      "Requirement already satisfied: numpy>=1.16.4 in /usr/local/lib/python3.6/dist-packages (from pytorch-lightning==1.0.4) (1.18.5)\n",
      "Requirement already satisfied: torch>=1.3 in /usr/local/lib/python3.6/dist-packages (from pytorch-lightning==1.0.4) (1.7.0+cu101)\n",
      "Requirement already satisfied: future>=0.17.1 in /usr/local/lib/python3.6/dist-packages (from pytorch-lightning==1.0.4) (0.18.2)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=2.2.0->pytorch-lightning==1.0.4) (50.3.2)\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=2.2.0->pytorch-lightning==1.0.4) (1.17.2)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=2.2.0->pytorch-lightning==1.0.4) (2.23.0)\n",
      "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorboard>=2.2.0->pytorch-lightning==1.0.4) (0.36.1)\n",
      "Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=2.2.0->pytorch-lightning==1.0.4) (3.12.4)\n",
      "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=2.2.0->pytorch-lightning==1.0.4) (1.15.0)\n",
      "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=2.2.0->pytorch-lightning==1.0.4) (0.10.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=2.2.0->pytorch-lightning==1.0.4) (3.3.3)\n",
      "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=2.2.0->pytorch-lightning==1.0.4) (1.34.0)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=2.2.0->pytorch-lightning==1.0.4) (1.7.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=2.2.0->pytorch-lightning==1.0.4) (0.4.2)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=2.2.0->pytorch-lightning==1.0.4) (1.0.1)\n",
      "Requirement already satisfied: dataclasses in /usr/local/lib/python3.6/dist-packages (from torch>=1.3->pytorch-lightning==1.0.4) (0.8)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.6/dist-packages (from torch>=1.3->pytorch-lightning==1.0.4) (3.7.4.3)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning==1.0.4) (4.6)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning==1.0.4) (0.2.8)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning==1.0.4) (4.1.1)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard>=2.2.0->pytorch-lightning==1.0.4) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard>=2.2.0->pytorch-lightning==1.0.4) (1.24.3)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard>=2.2.0->pytorch-lightning==1.0.4) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard>=2.2.0->pytorch-lightning==1.0.4) (2020.12.5)\n",
      "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard>=2.2.0->pytorch-lightning==1.0.4) (3.1.1)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0->pytorch-lightning==1.0.4) (1.3.0)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.6/dist-packages (from rsa<5,>=3.1.4; python_version >= \"3\"->google-auth<2,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning==1.0.4) (0.4.8)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard>=2.2.0->pytorch-lightning==1.0.4) (3.4.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0->pytorch-lightning==1.0.4) (3.1.0)\n",
      "Requirement already satisfied: git-python==1.0.3 in /usr/local/lib/python3.6/dist-packages (1.0.3)\n",
      "Requirement already satisfied: gitpython in /usr/local/lib/python3.6/dist-packages (from git-python==1.0.3) (3.1.11)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.6/dist-packages (from gitpython->git-python==1.0.3) (4.0.5)\n",
      "Requirement already satisfied: smmap<4,>=3.0.1 in /usr/local/lib/python3.6/dist-packages (from gitdb<5,>=4.0.1->gitpython->git-python==1.0.3) (3.0.4)\n",
      "Requirement already satisfied: rouge-score in /usr/local/lib/python3.6/dist-packages (0.0.4)\n",
      "Requirement already satisfied: nltk in /usr/local/lib/python3.6/dist-packages (from rouge-score) (3.2.5)\n",
      "Requirement already satisfied: absl-py in /usr/local/lib/python3.6/dist-packages (from rouge-score) (0.10.0)\n",
      "Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.6/dist-packages (from rouge-score) (1.15.0)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from rouge-score) (1.18.5)\n",
      "Requirement already satisfied: sacrebleu in /usr/local/lib/python3.6/dist-packages (1.4.14)\n",
      "Requirement already satisfied: portalocker in /usr/local/lib/python3.6/dist-packages (from sacrebleu) (2.0.0)\n",
      "Requirement already up-to-date: wandb in /usr/local/lib/python3.6/dist-packages (0.10.12)\n",
      "Requirement already satisfied, skipping upgrade: PyYAML in /usr/local/lib/python3.6/dist-packages (from wandb) (5.3.1)\n",
      "Requirement already satisfied, skipping upgrade: watchdog>=0.8.3 in /usr/local/lib/python3.6/dist-packages (from wandb) (1.0.1)\n",
      "Requirement already satisfied, skipping upgrade: GitPython>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from wandb) (3.1.11)\n",
      "Requirement already satisfied, skipping upgrade: shortuuid>=0.5.0 in /usr/local/lib/python3.6/dist-packages (from wandb) (1.0.1)\n",
      "Requirement already satisfied, skipping upgrade: subprocess32>=3.5.3 in /usr/local/lib/python3.6/dist-packages (from wandb) (3.5.4)\n",
      "Requirement already satisfied, skipping upgrade: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from wandb) (2.8.1)\n",
      "Requirement already satisfied, skipping upgrade: six>=1.13.0 in /usr/local/lib/python3.6/dist-packages (from wandb) (1.15.0)\n",
      "Requirement already satisfied, skipping upgrade: psutil>=5.0.0 in /usr/local/lib/python3.6/dist-packages (from wandb) (5.4.8)\n",
      "Requirement already satisfied, skipping upgrade: promise<3,>=2.0 in /usr/local/lib/python3.6/dist-packages (from wandb) (2.3)\n",
      "Requirement already satisfied, skipping upgrade: docker-pycreds>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from wandb) (0.4.0)\n",
      "Requirement already satisfied, skipping upgrade: Click>=7.0 in /usr/local/lib/python3.6/dist-packages (from wandb) (7.1.2)\n",
      "Requirement already satisfied, skipping upgrade: configparser>=3.8.1 in /usr/local/lib/python3.6/dist-packages (from wandb) (5.0.1)\n",
      "Requirement already satisfied, skipping upgrade: sentry-sdk>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from wandb) (0.19.5)\n",
      "Requirement already satisfied, skipping upgrade: requests<3,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from wandb) (2.23.0)\n",
      "Requirement already satisfied, skipping upgrade: protobuf>=3.12.0 in /usr/local/lib/python3.6/dist-packages (from wandb) (3.12.4)\n",
      "Requirement already satisfied, skipping upgrade: gitdb<5,>=4.0.1 in /usr/local/lib/python3.6/dist-packages (from GitPython>=1.0.0->wandb) (4.0.5)\n",
      "Requirement already satisfied, skipping upgrade: certifi in /usr/local/lib/python3.6/dist-packages (from sentry-sdk>=0.4.0->wandb) (2020.12.5)\n",
      "Requirement already satisfied, skipping upgrade: urllib3>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from sentry-sdk>=0.4.0->wandb) (1.24.3)\n",
      "Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.0.0->wandb) (2.10)\n",
      "Requirement already satisfied, skipping upgrade: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.0.0->wandb) (3.0.4)\n",
      "Requirement already satisfied, skipping upgrade: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.12.0->wandb) (50.3.2)\n",
      "Requirement already satisfied, skipping upgrade: smmap<4,>=3.0.1 in /usr/local/lib/python3.6/dist-packages (from gitdb<5,>=4.0.1->GitPython>=1.0.0->wandb) (3.0.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install -U transformers\n",
    "!pip install pytorch-lightning==1.0.4\n",
    "!pip install git-python==1.0.3\n",
    "!pip install rouge-score\n",
    "!pip install sacrebleu\n",
    "!pip install -U wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 15459,
     "status": "ok",
     "timestamp": 1607954316611,
     "user": {
      "displayName": "Marco Pietro Abrate",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gjh-8YF-8BlnrkN9mLZ0xfVOWfOh7kYncpYRv-Y=s64",
      "userId": "15422244832836998434"
     },
     "user_tz": -60
    },
    "hidden": true,
    "id": "PKml-cj1be8Q"
   },
   "outputs": [],
   "source": [
    "finetune_script = '\"/content/drive/My Drive/MAGMA: Summarization/seq2seq/finetune.py\"'\n",
    "eval_script = '\"/content/drive/My Drive/MAGMA: Summarization/seq2seq/run_eval.py\"'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 15327,
     "status": "ok",
     "timestamp": 1607954316611,
     "user": {
      "displayName": "Marco Pietro Abrate",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gjh-8YF-8BlnrkN9mLZ0xfVOWfOh7kYncpYRv-Y=s64",
      "userId": "15422244832836998434"
     },
     "user_tz": -60
    },
    "hidden": true,
    "id": "nVNMUUSDcBVF"
   },
   "outputs": [],
   "source": [
    "data_dir = '\"/content/drive/My Drive/MAGMA: Summarization/datasets/xsum\"'\n",
    "\n",
    "output_dir = '\"/content/drive/My Drive/MAGMA: Summarization/experiments/bug_bart_xsum_train\"'\n",
    "log_dir = output_dir + '/logs'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 14875,
     "status": "ok",
     "timestamp": 1607954316613,
     "user": {
      "displayName": "Marco Pietro Abrate",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gjh-8YF-8BlnrkN9mLZ0xfVOWfOh7kYncpYRv-Y=s64",
      "userId": "15422244832836998434"
     },
     "user_tz": -60
    },
    "hidden": true,
    "id": "xEgjZMyRgyqV",
    "outputId": "9b6d21af-71ce-453c-df91-720dbaebcce9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.6.9\n"
     ]
    }
   ],
   "source": [
    "!python3 --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 79867,
     "status": "ok",
     "timestamp": 1607954382159,
     "user": {
      "displayName": "Marco Pietro Abrate",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gjh-8YF-8BlnrkN9mLZ0xfVOWfOh7kYncpYRv-Y=s64",
      "userId": "15422244832836998434"
     },
     "user_tz": -60
    },
    "hidden": true,
    "id": "DXazLPeXbubk",
    "outputId": "420ad067-dac0-4de4-82d6-2bba6c965111"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-12-14 13:58:38.860898: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
      "/usr/local/lib/python3.6/dist-packages/pytorch_lightning/utilities/distributed.py:45: UserWarning: Checkpoint directory /content/drive/My Drive/MAGMA: Summarization/experiments/bug_bart_xsum_train exists and is not empty. With save_top_k=1, all files in this directory will be deleted when a checkpoint is saved!\n",
      "  warnings.warn(*args, **kwargs)\n",
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mmarcoabrate\u001b[0m (use `wandb login --relogin` to force relogin)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.10.12\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mbug_bart_xsum_train\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/marcoabrate/xsum\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/marcoabrate/xsum/runs/3txyq2kh\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in /content/wandb/run-20201214_135855-3txyq2kh\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run `wandb offline` to turn off syncing.\n",
      "\n",
      "Validation sanity check: 100%|██████████| 1/1 [00:01<00:00,  1.67s/it]/usr/local/lib/python3.6/dist-packages/pytorch_lightning/utilities/distributed.py:45: UserWarning: The validation_epoch_end should not return anything as of 9.1.to log, use self.log(...) or self.write(...) directly in the LightningModule\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/usr/local/lib/python3.6/dist-packages/pytorch_lightning/utilities/distributed.py:45: UserWarning: The {log:dict keyword} was deprecated in 0.9.1 and will be removed in 1.0.0\n",
      "Please use self.log(...) inside the lightningModule instead.\n",
      "\n",
      "# log on a step or aggregate epoch metric to the logger and/or progress bar\n",
      "# (inside LightningModule)\n",
      "self.log('train_loss', loss, on_step=True, on_epoch=True, prog_bar=True)\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 0:   0%|          | 0/6 [00:00<?, ?it/s] /usr/local/lib/python3.6/dist-packages/transformers/optimization.py:506: UserWarning: This overload of add_ is deprecated:\n",
      "\tadd_(Number alpha, Tensor other)\n",
      "Consider using one of the following signatures instead:\n",
      "\tadd_(Tensor other, *, Number alpha) (Triggered internally at  /pytorch/torch/csrc/utils/python_arg_parser.cpp:882.)\n",
      "  exp_avg_sq_row.mul_(beta2t).add_(1.0 - beta2t, update.mean(dim=-1))\n",
      "Epoch 0:  33%|███▎      | 2/6 [00:04<00:08,  2.05s/it, loss=243.788, v_num=q2kh]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 0:  50%|█████     | 3/6 [00:05<00:05,  1.92s/it, loss=243.788, v_num=q2kh]/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:216: UserWarning: Please also save or load the state of the optimizer when saving or loading the scheduler.\n",
      "  warnings.warn(SAVE_STATE_WARNING, UserWarning)\n",
      "Epoch 0:  50%|█████     | 3/6 [00:14<00:14,  4.73s/it, loss=243.788, v_num=q2kh]\n",
      "Epoch 0:  83%|████████▎ | 5/6 [00:14<00:02,  2.95s/it, loss=281.547, v_num=q2kh]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 0: 100%|██████████| 6/6 [00:16<00:00,  2.79s/it, loss=281.547, v_num=q2kh]\n",
      "Epoch 1:  33%|███▎      | 2/6 [00:13<00:27,  6.77s/it, loss=261.541, v_num=q2kh]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 1:  50%|█████     | 3/6 [00:16<00:16,  5.56s/it, loss=261.541, v_num=q2kh]\n",
      "Epoch 1:  83%|████████▎ | 5/6 [00:17<00:03,  3.45s/it, loss=255.774, v_num=q2kh]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 1: 100%|██████████| 6/6 [00:19<00:00,  3.21s/it, loss=255.774, v_num=q2kh]\n",
      "Epoch 1: 100%|██████████| 6/6 [00:19<00:00,  3.21s/it, loss=255.774, v_num=q2kh]\n",
      "\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish, PID 1153\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Program ended successfully.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find user logs for this run at: /content/wandb/run-20201214_135855-3txyq2kh/logs/debug.log\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find internal logs for this run at: /content/wandb/run-20201214_135855-3txyq2kh/logs/debug-internal.log\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            n_params 139420416\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  mp 139.42042\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             grad_mp 99.24096\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:               _step 20\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            _runtime 40\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          _timestamp 1607954375\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          lr_group_0 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          lr_group_1 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         global_step 7\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                loss 205.57329\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                 tpb 563\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  bs 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         src_pad_tok 93\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        src_pad_frac 0.15552\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:               epoch 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        val_avg_loss 173.24536\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      val_avg_rouge1 12.1439\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      val_avg_rouge2 1.7699\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      val_avg_rougeL 9.5427\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   val_avg_rougeLsum 10.4123\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    val_avg_gen_time 0.63597\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     val_avg_gen_len 128.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          step_count 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            n_params ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  mp ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             grad_mp ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:               _step ▁▁▂▂▂▃▃▃▄▄▅▅▅▆▆▆▇▇▇██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            _runtime ▁▂▂▂▂▂▄▄▄▄▄▇▇▇▇██████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          _timestamp ▁▂▂▂▂▂▄▄▄▄▄▇▇▇▇██████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          lr_group_0 █▇▆▅▄▃▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          lr_group_1 █▇▆▅▄▃▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         global_step ▁▂▂▃▄▄▅▆▆▇██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                loss ▃▅██▁▆▆▃\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                 tpb █▁▅▆█▅▆▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  bs ▁▁▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         src_pad_tok █▄▁▁█▁▁▄\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        src_pad_frac ▅█▁▁▅▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:               epoch ▁▁▁▁▁▁██████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        val_avg_loss █▃▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      val_avg_rouge1 ▂█▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      val_avg_rouge2 ▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      val_avg_rougeL ▂██▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   val_avg_rougeLsum ▂██▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    val_avg_gen_time ▁▂█▃\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     val_avg_gen_len ▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          step_count ▁▃▆█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33mbug_bart_xsum_train\u001b[0m: \u001b[34mhttps://wandb.ai/marcoabrate/xsum/runs/3txyq2kh\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!python3 $finetune_script \\\n",
    "--model_name_or_path facebook/bart-base \\\n",
    "--tokenizer_name facebook/bart-base \\\n",
    "--data_dir $data_dir \\\n",
    "--learning_rate 3e-5 --label_smoothing 0.1 --num_train_epochs 2 \\\n",
    "--sortish_sampler --freeze_embeds --adafactor \\\n",
    "--task summarization \\\n",
    "--do_train \\\n",
    "--max_source_length 1024 \\\n",
    "--max_target_length 60 \\\n",
    "--val_max_target_length 60 \\\n",
    "--test_max_target_length 100 \\\n",
    "--n_train 8 --n_val 2 \\\n",
    "--train_batch_size 2 --eval_batch_size 2 \\\n",
    "--eval_beams 2 \\\n",
    "--val_check_interval 0.5 \\\n",
    "--log_every_n_steps 1 \\\n",
    "--logger_name wandb \\\n",
    "--output_dir $output_dir \\\n",
    "--overwrite_output_dir \\\n",
    "--gpus 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "id": "3gFqfk6ccSFe"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "2c7S2VEH1I97"
   ],
   "name": "bugs.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "748c6acaa0ba44e1a2306e1c07ceeb05": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_3e2350a5b8d34947aeb58b064c2daaf1",
       "IPY_MODEL_3ac73ae78b454421ad182f0866d3ff9d"
      ],
      "layout": "IPY_MODEL_e50eb56d74004d2082a51e10781fd584"
     }
    },
    "9932097da8de489da0674e2867668886": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_276baa27b3b448269daf6943726d0590",
       "IPY_MODEL_30fcc38236fe4596948fe0252f271517"
      ],
      "layout": "IPY_MODEL_1ad4203c249c4c0f964de8a6863d7b2e"
     }
    },
    "ae89cb8da37b4973a788be1b5e6b3414": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_b56a894b4a2447adb3af2baf5d040454",
       "IPY_MODEL_98779bad9aee42328e3e53d75fd05543"
      ],
      "layout": "IPY_MODEL_3e61eebbe4d342998103df2e0ddd2dfc"
     }
    },
    "bc016971b8f24f29949de3f78b2336cd": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_12c56b752bfa4dcd8f034065bcd4a575",
       "IPY_MODEL_e5f9ec5b12ab4c1daeb726bc44505192"
      ],
      "layout": "IPY_MODEL_47b0a914c5bc400691860180bc484a61"
     }
    },
    "ff19f372faba4c5d858adc458c6461b9": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_288c1bf344eb41d59f83fc9935c51c75",
       "IPY_MODEL_3c1bd44ee69b4ac89079b3d0502afb87"
      ],
      "layout": "IPY_MODEL_5bf65a2b023f4e6a87eab43ff622f9df"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "magma_dir = '/home/marco/epfl/magma/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S0FByNNOIRvG"
   },
   "source": [
    "### **Config**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 16184,
     "status": "ok",
     "timestamp": 1610463826089,
     "user": {
      "displayName": "Marco Pietro Abrate",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gjh-8YF-8BlnrkN9mLZ0xfVOWfOh7kYncpYRv-Y=s64",
      "userId": "15422244832836998434"
     },
     "user_tz": -60
    },
    "id": "ClE5D523OTZG"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "sys.path.insert(0, magma_dir)\n",
    "import config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 16184,
     "status": "ok",
     "timestamp": 1610463826092,
     "user": {
      "displayName": "Marco Pietro Abrate",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gjh-8YF-8BlnrkN9mLZ0xfVOWfOh7kYncpYRv-Y=s64",
      "userId": "15422244832836998434"
     },
     "user_tz": -60
    },
    "id": "82WSp6khIcua"
   },
   "outputs": [],
   "source": [
    "MODEL = 't5'\n",
    "\n",
    "RE_SPLITTER = '\\n'              # do we split sentences of paragraphs?\n",
    "                                # use '\\.(?!\\d)|\\n' or '\\n', respectively\n",
    "\n",
    "TOKEN_MAX_LEN = 99              # max length of a word\n",
    "PARA_MIN_LENGTH = 2             # minimum length for a sentence or\n",
    "                                # a paragraph, in tokens\n",
    "\n",
    "RECALL_THRESHOLD = 0.7\n",
    "\n",
    "# Output path\n",
    "OUTPUT_PATH = magma_dir+'datasets/karger_books_para_wordembed/'+MODEL+'/'\n",
    "if not os.path.exists(OUTPUT_PATH):\n",
    "    os.makedirs(OUTPUT_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tb7fAfzaK4es"
   },
   "source": [
    "### **Init**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 16443,
     "status": "ok",
     "timestamp": 1610463826354,
     "user": {
      "displayName": "Marco Pietro Abrate",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gjh-8YF-8BlnrkN9mLZ0xfVOWfOh7kYncpYRv-Y=s64",
      "userId": "15422244832836998434"
     },
     "user_tz": -60
    },
    "id": "wvbMlPBxk45S"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import re\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import gensim\n",
    "from textwrap import fill\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "\n",
    "if 'pegasus' in MODEL:\n",
    "    from transformers import PegasusTokenizer\n",
    "    tokenizer =\\\n",
    "        PegasusTokenizer.from_pretrained('google/pegasus-large')\n",
    "elif 'bart' in MODEL:\n",
    "    from transformers import BartTokenizer\n",
    "    tokenizer =\\\n",
    "        BartTokenizer.from_pretrained('facebook/bart-large-cnn')\n",
    "elif 't5' in MODEL:\n",
    "    from transformers import T5Tokenizer\n",
    "    tokenizer =\\\n",
    "        T5Tokenizer.from_pretrained('t5-large')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eQGq4WLu3Gei"
   },
   "source": [
    "### **Karger Books Base Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "Z0lbkScg0a7j"
   },
   "outputs": [],
   "source": [
    "base_dataset = magma_dir+'datasets/karger_books_base/df.csv'\n",
    "df = pd.read_csv(base_dataset)\n",
    "df = df.set_index(['book', 'chapter', 'section', 'subsection'])\n",
    "df.bullets = df.bullets.map(eval, na_action='ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tSHT0mxuvkEp"
   },
   "source": [
    "### **Preprocessing**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-eRnW74aH95b"
   },
   "source": [
    "#### Preprocessing\n",
    "\n",
    "* Split based on RE_SPLITTER\n",
    "* Explode the dataset\n",
    "* Remove unwanted chars at beginning or end of sentence\n",
    "* Remove multiple spaces\n",
    "* Remove long words (> TOKEN_MAX_LEN chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "CDsT33j-wPCw",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Split in sentences / paragraphs based on RE_SPLITTER\n",
    "df.text =\\\n",
    "    df.text.map(lambda x: [p.strip() for p in re.split(RE_SPLITTER, x) if p!=''],\n",
    "                na_action='ignore')\n",
    "    \n",
    "# explode to get one row for each paragraph /sentence\n",
    "df = df.explode('text')\n",
    "df = df.rename(columns={'text': 'para'})\n",
    "df = df.dropna()\n",
    "\n",
    "# Remove unwanted chars at beginning or end of sentence\n",
    "df.para = df.para.map(lambda p: p.lstrip('.,;:-)] \\n'))\n",
    "df.para = df.para.map(lambda p: p.rstrip('.,;:-([ \\n'))\n",
    "\n",
    "# Remove multiple spaces\n",
    "df.para = df.para.map(lambda p:\n",
    "    re.sub('\\s+', ' ', p).strip())\n",
    "\n",
    "# Remove long words (> TOKEN_MAX_LEN chars)\n",
    "def para2words(para):\n",
    "    return gensim.utils.simple_preprocess(\n",
    "        para, deacc=True, max_len=TOKEN_MAX_LEN)\n",
    "df['para_proc'] = df.para.map(para2words)\n",
    "df['bullets_proc'] = df.bullets.map(lambda bs: [para2words(b) for b in bs])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Further Preprocessing\n",
    "\n",
    "* Remove stop words\n",
    "* Remove short sentences / paragraphs (< PARA_MIN_LENGTH tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Error loading stopwords: <urlopen error [Errno -2] Name or\n",
      "[nltk_data]     service not known>\n"
     ]
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = stopwords.words('english')\n",
    "\n",
    "df.para_proc = df.para_proc.map(lambda p:\n",
    "    [w for w in p if w not in stop_words])\n",
    "df.bullets_proc = df.bullets_proc.map(lambda bs:\n",
    "    [[w for w in b if w not in stop_words] for b in bs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove short sentences / paragraphs (< PARA_MIN_LENGTH tokens)\n",
    "df.loc[df.para_proc.map(len) <\\\n",
    "    PARA_MIN_LENGTH, 'para_proc'] = np.nan\n",
    "\n",
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.para = df.para.map(lambda p: p+'.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Assign Bullets to Best Para and Expand Functions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_best_metric_para(df, col_metric):\n",
    "    df['best_match'] = False\n",
    "\n",
    "    for idx, para  in df.groupby('bullets').progress_apply(\n",
    "        lambda g: g.iloc[g[col_metric].argmax()]).para.iteritems():\n",
    "        \n",
    "        df.loc[\\\n",
    "            (df['bullets'] == idx) &\\\n",
    "            (df['para'] == para), 'best_match'] = True\n",
    "    \n",
    "    para_too_short =\\\n",
    "        df[(df['compression_ratio'] >= config.MAX_RATIO) & df['best_match']]\n",
    "    print('Percentage of paragraphs which are too short to be summarized: %.2f %%'\\\n",
    "        %(len(para_too_short)/len(df[df['best_match']])*100))\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def expand_up_down(df, col_metric, verbose=False):\n",
    "    # for each bullet\n",
    "    for bul in tqdm(set(df.bullets.tolist())):\n",
    "        if verbose : print(bul)\n",
    "        df_bul = df[df['bullets'] == bul]\n",
    "        \n",
    "        # get book and chapter where this bullet is\n",
    "        book = df_bul.index.get_level_values(0)[0]\n",
    "        cpt = df_bul.index.get_level_values(1)[0]\n",
    "\n",
    "        df_bul = df_bul.reset_index()\n",
    "        if verbose : print(df_bul[df_bul['best_match']].para.tolist())\n",
    "        # get best match index\n",
    "        best_match_idx = np.where(df_bul['best_match'])[0][0]\n",
    "        merged_para_idx = [best_match_idx]\n",
    "\n",
    "        bul_num_tok = df_bul.loc[best_match_idx].bullets_num_tokens\n",
    "        comp_ratio = df_bul.loc[best_match_idx].compression_ratio\n",
    "        if verbose:\n",
    "            print('Book %s, Chapter %s'%(book, cpt))\n",
    "            print('Paragraphs in this chapter:', len(df_bul))\n",
    "            print('Location of best_bul index:', best_match_idx)\n",
    "            print('Compression ratio before merging: %.2f %%'%comp_ratio)\n",
    "            print()\n",
    "        while comp_ratio > config.MAX_RATIO:\n",
    "            if 0 in merged_para_idx:\n",
    "                if verbose : print('merge down')\n",
    "                new_para_idx = max(merged_para_idx)+1\n",
    "                df_bul.loc[new_para_idx, 'best_match'] = True\n",
    "                merged_para_idx.append(new_para_idx)\n",
    "\n",
    "            elif (len(df_bul)-1) in merged_para_idx:\n",
    "                if verbose : print('merge up')\n",
    "                new_para_idx = min(merged_para_idx)-1\n",
    "                df_bul.loc[new_para_idx, 'best_match'] = True\n",
    "                merged_para_idx.append(new_para_idx)\n",
    "\n",
    "            else:\n",
    "                if verbose : print('based on metric %s '%col_metric, end='')\n",
    "\n",
    "                if df_bul.loc[min(merged_para_idx)-1, col_metric] <\\\n",
    "                    df_bul.loc[max(merged_para_idx)+1, col_metric]:\n",
    "                    if verbose : print('merge down')\n",
    "                    new_para_idx = max(merged_para_idx)+1\n",
    "                    df_bul.loc[new_para_idx, 'best_match'] = True\n",
    "                    merged_para_idx.append(new_para_idx)\n",
    "                else:\n",
    "                    if verbose : print('merge up')\n",
    "                    new_para_idx = min(merged_para_idx)-1\n",
    "                    df_bul.loc[new_para_idx, 'best_match'] = True\n",
    "                    merged_para_idx.append(new_para_idx)         \n",
    "\n",
    "            merged_para_len = np.sum(df_bul[df_bul['best_match']].para_num_tokens.tolist())\n",
    "            comp_ratio = bul_num_tok / merged_para_len\n",
    "            if merged_para_len > tokenizer.model_max_length:\n",
    "                break\n",
    "            if verbose:\n",
    "                print(df_bul[df_bul['best_match']].para.tolist())\n",
    "                print('Compression ratio: %.2f %%'%comp_ratio)\n",
    "                print()\n",
    "\n",
    "        for p, b in zip(df_bul.loc[merged_para_idx]['para'].tolist(),\n",
    "            df_bul.loc[merged_para_idx]['bullets'].tolist()):\n",
    "            df.loc[(df['para'] == p) &\n",
    "                (df['bullets'] == b), 'best_match'] = True\n",
    "        if verbose : print()\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_stats(df):\n",
    "    num_para_tot = 18822\n",
    "    num_para_kept = np.sum(df.groupby('para')['best_match'].apply(np.any).tolist())\n",
    "    print('%d out of %d paragraphs are considered using this method.'%(num_para_kept, num_para_tot), end=' ')\n",
    "    print('Thus, %.2f %%'%(100*num_para_kept/num_para_tot))\n",
    "    \n",
    "    print()\n",
    "    df_count_tokens = df.groupby('para', sort=False).agg({\n",
    "        'best_match': lambda bm: np.any(list(bm)),\n",
    "        'para_num_tokens': lambda pnt: list(pnt)[0]})\n",
    "    num_tok_kept = df_count_tokens[df_count_tokens['best_match']].para_num_tokens.sum()\n",
    "    num_tok_tot = df_count_tokens.para_num_tokens.sum()\n",
    "\n",
    "    print('%d out of %d tokens are considered using this method.'%(num_tok_kept, num_tok_tot), end=' ')\n",
    "    print('Thus, %.2f %%'%(100*num_tok_kept/num_tok_tot))\n",
    "\n",
    "def print_stats_after_merge(df):\n",
    "    para_too_short = df[df['compression_ratio'] > config.MAX_RATIO]\n",
    "    print('Percentage of paragraphs which are too short to be summarized: %.2f %%'\\\n",
    "        %(len(para_too_short)/len(df)*100))\n",
    "    \n",
    "    print()\n",
    "    print('Paragraphs which are too long to fit into the model: %d paragraphs.'%\\\n",
    "          len(df[df['para_num_tokens'] > tokenizer.model_max_length]))\n",
    "    print(df[df['para_num_tokens'] > tokenizer.model_max_length])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Word2Vec Book Level**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Word Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "op = OUTPUT_PATH + 'w2v/'\n",
    "if not os.path.exists(op):\n",
    "    os.makedirs(op)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_w2v = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_w2v_book = df_w2v.groupby('book', sort=False).agg({\n",
    "    'para_proc': lambda pp: list(pp),\n",
    "    'bullets_proc': lambda bp: list(bp)[0]\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_w2v_book['corpus'] = df_w2v_book.para_proc + df_w2v_book.bullets_proc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 53/53 [00:35<00:00,  1.49it/s]\n"
     ]
    }
   ],
   "source": [
    "df_w2v_book['w2v'] = df_w2v_book.corpus.progress_map(lambda c:\\\n",
    "    gensim.models.Word2Vec(\n",
    "        c,\n",
    "        #size=128,\n",
    "        #window=3,\n",
    "        min_count=1,\n",
    "        sg=1, # 1 for skip-gram; otherwise CBOW.\n",
    "        seed = config.SEED))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 18773/18773 [00:01<00:00, 13738.85it/s]\n",
      "100%|██████████| 18773/18773 [00:00<00:00, 37845.82it/s]\n"
     ]
    }
   ],
   "source": [
    "def assign_word_vectors(r, col):\n",
    "    book = r.name[0]\n",
    "    wv = df_w2v_book.loc[book, 'w2v'].wv\n",
    "    wv_list = []\n",
    "    for x in r[col]:\n",
    "        try:\n",
    "            v = wv[x]\n",
    "        except:\n",
    "            continue\n",
    "        wv_list.append(v)\n",
    "    return wv_list\n",
    "\n",
    "df_w2v['para_wv'] = df_w2v.progress_apply(lambda row: assign_word_vectors(row, 'para_proc'), axis=1)\n",
    "\n",
    "# taking the average of the w2v vector of each paragraph\n",
    "df_w2v.para_wv = df_w2v.para_wv.progress_map(lambda p_wv: np.mean(p_wv, axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [para, bullets, para_proc, bullets_proc, para_wv]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "print(df_w2v[df_w2v.para_wv.isna()])\n",
    "df_w2v = df_w2v.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Explode, preprocess, w2v bullets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 114277/114277 [00:06<00:00, 16395.64it/s]\n",
      "100%|██████████| 114277/114277 [00:04<00:00, 24420.58it/s]\n"
     ]
    }
   ],
   "source": [
    "df_w2v = df_w2v.explode('bullets')\n",
    "\n",
    "df_w2v['bullets_proc'] = df_w2v.bullets.progress_map(para2words)\n",
    "df_w2v.bullets_proc = df_w2v.bullets_proc.progress_map(lambda b:\n",
    "    [w for w in b if w not in stop_words])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 114277/114277 [00:05<00:00, 20827.49it/s]\n",
      "100%|██████████| 114277/114277 [00:02<00:00, 50382.84it/s]\n"
     ]
    }
   ],
   "source": [
    "df_w2v['bullets_wv'] = df_w2v.progress_apply(lambda row: assign_word_vectors(row, 'bullets_proc'), axis=1)\n",
    "\n",
    "# taking the average of the w2v vector of each bullet\n",
    "df_w2v.bullets_wv = df_w2v.bullets_wv.progress_map(lambda b_wv: np.mean(b_wv, axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 114277/114277 [00:47<00:00, 2385.32it/s]\n",
      "100%|██████████| 114277/114277 [00:37<00:00, 3042.28it/s]\n"
     ]
    }
   ],
   "source": [
    "df_w2v['para_num_tokens'] = df_w2v.para.progress_map(lambda p: len(tokenizer.tokenize(p)))\n",
    "df_w2v['bullets_num_tokens'] = df_w2v.bullets.progress_map(lambda b: len(tokenizer.tokenize(b)))\n",
    "\n",
    "df_w2v['compression_ratio'] = df_w2v.bullets_num_tokens / df_w2v.para_num_tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculate cosine similarity between each couple bullet-para"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_sim(a, b):\n",
    "    return np.dot(a, b) / (np.linalg.norm(a)*np.linalg.norm(b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 114277/114277 [00:03<00:00, 37387.53it/s]\n"
     ]
    }
   ],
   "source": [
    "df_w2v['cosine_sim'] = df_w2v[['para_wv', 'bullets_wv']].progress_apply(lambda row:\\\n",
    "    cosine_sim(row[0], row[1]), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Find Best Match and Expand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2556/2556 [00:01<00:00, 1784.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of paragraphs which are too short to be summarized: 55.44 %\n"
     ]
    }
   ],
   "source": [
    "# find best match bullet-para for each bullet\n",
    "df_w2v = assign_best_metric_para(df_w2v, 'cosine_sim')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2556/2556 [01:36<00:00, 26.58it/s]\n"
     ]
    }
   ],
   "source": [
    "df_w2v = expand_up_down(df_w2v, 'cosine_sim')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4031 out of 18822 paragraphs are considered using this method. Thus, 21.42 %\n",
      "\n",
      "425779 out of 1493612 tokens are considered using this method. Thus, 28.51 %\n"
     ]
    }
   ],
   "source": [
    "print_stats(df_w2v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_w2v_merge = df_w2v[df_w2v['best_match']].reset_index().groupby(['book', 'chapter', 'bullets'], sort=False)\\\n",
    ".agg({\n",
    "    'para': lambda p: ' '.join(list(p)),\n",
    "    'para_num_tokens': sum,\n",
    "    'bullets_num_tokens': lambda bnt: list(bnt)[0]\n",
    "}).reset_index(level='bullets')\n",
    "df_w2v_merge = df_w2v_merge.rename(columns={'para': 'text'})\n",
    "\n",
    "df_w2v_merge['compression_ratio'] = df_w2v_merge.bullets_num_tokens / df_w2v_merge.para_num_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of paragraphs which are too short to be summarized: 0.31 %\n",
      "\n",
      "Paragraphs which are too long to fit into the model: 24 paragraphs.\n",
      "                                                                 bullets  \\\n",
      "book          chapter                                                      \n",
      "9781908541024 ch_6     Concurrent and adjuvant temozolomide chemother...   \n",
      "              ch_6     Anaplastic oligodendroglioma is a chemosensiti...   \n",
      "              ch_6     Observation may be an appropriate initial stra...   \n",
      "9781908541062 ch_10    Nine biological therapies are now licensed for...   \n",
      "9781908541086 ch_5     Clinicians and patients are best served by con...   \n",
      "              ch_11    Eating disorders not otherwise specified is th...   \n",
      "9781908541727 ch07     Urgently refer patients who present with any o...   \n",
      "              ch09     Refer urgently (the same day), patients with o...   \n",
      "              ch10     Refer urgently, to be seen the same day, if yo...   \n",
      "              ch10     Refer within 1 week, any child with:- squint (...   \n",
      "              ch11     Refer urgently, to be seen by an ophthalmologi...   \n",
      "9781908541901 ch_4     A 12-lead ECG should be performed and reviewed...   \n",
      "9781910797273 chp5     Newer DMTs, such as natalizumab, alemtuzumab a...   \n",
      "9781910797297 chp3     T-cell receptor polymerase chain reacton (TCR ...   \n",
      "              chp4     Subcutaneous panniculitis-like T-cell lymphoma...   \n",
      "              chp4     The clinically aggressive cytotoxic CTCLs are:...   \n",
      "9781910797495 chp7     Pharmacotherapy, based on only a small number ...   \n",
      "9781910797617 chp3     Enasidenib inhibits aberrant isocitrate dehydr...   \n",
      "              chp6     A wide range of targeted agencies for the trea...   \n",
      "9781910797723 chp1     In cellular immunity, T cells recognize their ...   \n",
      "              chp4     Immune checkpoint inhibitors have been approve...   \n",
      "9781910797815 chp9     Myeloproliferative neoplasm (MPN) may progress...   \n",
      "9781912776726 ch6      Novel therapeutic management approaches for pa...   \n",
      "9783318067095 ch9      Validation ensures that the technology is meas...   \n",
      "\n",
      "                                                                    text  \\\n",
      "book          chapter                                                      \n",
      "9781908541024 ch_6     Chemotherapy. The role of adjuvant chemotherap...   \n",
      "              ch_6     Management. Anaplastic oligodendrogliomas have...   \n",
      "              ch_6     Management. Anaplastic oligodendrogliomas have...   \n",
      "9781908541062 ch_10    IL-1 is thought to play a major pro-inflammato...   \n",
      "9781908541086 ch_5     Depression is one of the most salient psychiat...   \n",
      "              ch_11    Other eating disorders. Eating disorders not o...   \n",
      "9781908541727 ch07     Iris disease. The second most common cause of ...   \n",
      "              ch09     Herpes zoster ophthalmicus (HZO) is caused by ...   \n",
      "              ch10     Most infants and children with 'watery' eyes h...   \n",
      "              ch10     Young children are unable to complain of poor ...   \n",
      "              ch11     corneal abrasion with no sign of penetrating e...   \n",
      "9781908541901 ch_4     The GRACE risk score. In the GRACE risk model,...   \n",
      "9781910797273 chp5     Treatment escalation strategy. Until the mid-2...   \n",
      "9781910797297 chp3     T-cell receptor polymerase chain reaction. To ...   \n",
      "              chp4     Type B (mycosis fungoides-like). As suggested ...   \n",
      "              chp4     Because of the clinically aggressive nature of...   \n",
      "9781910797495 chp7     The use of cognitive behavioral therapy (CBT) ...   \n",
      "9781910797617 chp3     Enasidenib is an oral inhibitor of isocitrate ...   \n",
      "              chp6     Quizartinib (AC220). A non-randomized Phase II...   \n",
      "9781910797723 chp1     Cellular immunity. Surface T cell receptors (T...   \n",
      "              chp4     Immune checkpoint molecules are cell surface r...   \n",
      "9781910797815 chp9     Management of myeloproliferative neoplasm blas...   \n",
      "9781912776726 ch6      Glioblastoma is the most common primary brain ...   \n",
      "9783318067095 ch9      The process of verification evaluates the capt...   \n",
      "\n",
      "                       para_num_tokens  bullets_num_tokens  compression_ratio  \n",
      "book          chapter                                                          \n",
      "9781908541024 ch_6                 684                 134           0.195906  \n",
      "              ch_6                 532                  75           0.140977  \n",
      "              ch_6                 642                  92           0.143302  \n",
      "9781908541062 ch_10                546                  60           0.109890  \n",
      "9781908541086 ch_5                 514                 102           0.198444  \n",
      "              ch_11                520                  61           0.117308  \n",
      "9781908541727 ch07                 523                 130           0.248566  \n",
      "              ch09                 532                 181           0.340226  \n",
      "              ch10                 522                 249           0.477011  \n",
      "              ch10                 592                 149           0.251689  \n",
      "              ch11                 523                 280           0.535373  \n",
      "9781908541901 ch_4                 536                 104           0.194030  \n",
      "9781910797273 chp5                 577                  54           0.093588  \n",
      "9781910797297 chp3                 582                  93           0.159794  \n",
      "              chp4                 550                 127           0.230909  \n",
      "              chp4                 525                 130           0.247619  \n",
      "9781910797495 chp7                 556                 142           0.255396  \n",
      "9781910797617 chp3                 550                 103           0.187273  \n",
      "              chp6                 634                 122           0.192429  \n",
      "9781910797723 chp1                 599                 152           0.253756  \n",
      "              chp4                 555                 145           0.261261  \n",
      "9781910797815 chp9                 519                 111           0.213873  \n",
      "9781912776726 ch6                  539                  73           0.135436  \n",
      "9783318067095 ch9                  586                 197           0.336177  \n"
     ]
    }
   ],
   "source": [
    "print_stats_after_merge(df_w2v_merge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count     24.000000\n",
       "mean     559.916667\n",
       "std       44.426702\n",
       "min      514.000000\n",
       "25%      524.500000\n",
       "50%      548.000000\n",
       "75%      583.000000\n",
       "max      684.000000\n",
       "Name: para_num_tokens, dtype: float64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_w2v_merge[df_w2v_merge['para_num_tokens'] > tokenizer.model_max_length].para_num_tokens.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_w2v_merge.to_csv(op+'df.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create train, test, validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_w2v_merge = df_w2v_merge.groupby(level=[0, 1], sort=False).agg({\n",
    "    'bullets': lambda b: list(b),\n",
    "    'text': lambda t: list(t),\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "361 408\n"
     ]
    }
   ],
   "source": [
    "df_w2v_merge = df_w2v_merge.sample(frac=1, random_state=config.SEED)\n",
    "df_w2v_merge['num_bulls'] = df_w2v_merge.bullets.map(len).cumsum()\n",
    "tot_bulls = df_w2v_merge.num_bulls.iloc[-1]\n",
    "split1 = np.where(df_w2v_merge.num_bulls > int(tot_bulls*0.8))[0][0]+1\n",
    "split2 = np.where(df_w2v_merge.num_bulls > int(tot_bulls*0.9))[0][0]+1\n",
    "print(split1, split2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, val, test =\\\n",
    "    df_w2v_merge.iloc[:split1].explode('bullets'),\\\n",
    "    df_w2v_merge.iloc[split1:split2].explode('bullets'),\\\n",
    "    df_w2v_merge.iloc[split2:].explode('bullets')\n",
    "\n",
    "train['text'] = df_w2v_merge.iloc[:split1].explode('text')['text']\n",
    "val['text'] = df_w2v_merge.iloc[split1:split2].explode('text')['text']\n",
    "test['text'] = df_w2v_merge.iloc[split2:].explode('text')['text']\n",
    "\n",
    "train.to_csv(op+'train.csv')\n",
    "val.to_csv(op+'val.csv')\n",
    "test.to_csv(op+'test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(op+'train.source', 'w') as tr_s,\\\n",
    "    open(op+'train.target', 'w') as tr_t,\\\n",
    "    open(op+'train.index', 'w') as tr_i:\n",
    "    for idx, row in train[['text', 'bullets']].iterrows():\n",
    "        tr_i.write(str(idx) + '\\n')\n",
    "        tr_s.write(row.text + '\\n')\n",
    "        tr_t.write(row.bullets + '\\n')\n",
    "        \n",
    "with open(op+'val.source', 'w') as va_s,\\\n",
    "    open(op+'val.target', 'w') as va_t,\\\n",
    "    open(op+'val.index', 'w') as va_i:\n",
    "    for idx, row in val[['text', 'bullets']].iterrows():\n",
    "        va_i.write(str(idx) + '\\n')\n",
    "        va_s.write(row.text + '\\n')\n",
    "        va_t.write(row.bullets + '\\n')\n",
    "        \n",
    "with open(op+'test.source', 'w') as te_s,\\\n",
    "    open(op+'test.target', 'w') as te_t,\\\n",
    "    open(op+'test.index', 'w') as te_i:\n",
    "    for idx, row in test[['text', 'bullets']].iterrows():\n",
    "        te_i.write(str(idx) + '\\n')\n",
    "        te_s.write(row.text + '\\n')\n",
    "        te_t.write(row.bullets + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Doc2Vec Book Level**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Doc Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "op = OUTPUT_PATH + 'd2v/'\n",
    "if not os.path.exists(op):\n",
    "    os.makedirs(op)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_d2v = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_d2v_book = df_d2v.groupby('book', sort=False).agg({\n",
    "    'para_proc': lambda pp: list(pp),\n",
    "    'bullets_proc': lambda bp: list(bp)[0]\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_d2v_book['corpus'] = df_d2v_book.para_proc + df_d2v_book.bullets_proc\n",
    "df_d2v_book['tagged_corpus'] = df_d2v_book.corpus.map(lambda c:\n",
    "    [gensim.models.doc2vec.TaggedDocument(para, [i]) for i, para in enumerate(c)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 53/53 [00:40<00:00,  1.30it/s]\n"
     ]
    }
   ],
   "source": [
    "df_d2v_book['d2v'] = df_d2v_book.tagged_corpus.progress_map(lambda tc:\\\n",
    "    gensim.models.Doc2Vec(\n",
    "        tc,\n",
    "        dm=1, # 1 for PV-DM; otherwise PV-DBOW\n",
    "        #vector_size=128,\n",
    "        #window=3,\n",
    "        #epochs=5,\n",
    "        min_count=1,\n",
    "        seed = config.SEED))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Explode and preprocess bullets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 114277/114277 [00:08<00:00, 14204.95it/s]\n",
      "100%|██████████| 114277/114277 [00:05<00:00, 19101.35it/s]\n"
     ]
    }
   ],
   "source": [
    "df_d2v = df_d2v.explode('bullets')\n",
    "\n",
    "df_d2v['bullets_proc'] = df_d2v.bullets.progress_map(para2words)\n",
    "df_d2v.bullets_proc = df_d2v.bullets_proc.progress_map(lambda b:\n",
    "    [w for w in b if w not in stop_words])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 114277/114277 [00:48<00:00, 2342.25it/s]\n",
      "100%|██████████| 114277/114277 [00:46<00:00, 2439.71it/s]\n"
     ]
    }
   ],
   "source": [
    "df_d2v['para_num_tokens'] = df_d2v.para.progress_map(lambda p: len(tokenizer.tokenize(p)))\n",
    "df_d2v['bullets_num_tokens'] = df_d2v.bullets.progress_map(lambda b: len(tokenizer.tokenize(b)))\n",
    "\n",
    "df_d2v['compression_ratio'] = df_d2v.bullets_num_tokens / df_d2v.para_num_tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculate similarity between each couple bullet-para"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 114277/114277 [03:21<00:00, 566.75it/s]\n"
     ]
    }
   ],
   "source": [
    "def cosine_sim(a, b):\n",
    "    return np.dot(a, b) / (np.linalg.norm(a)*np.linalg.norm(b))\n",
    "\n",
    "def d2v_similarity(r):\n",
    "    book = r.name[0]\n",
    "    d2v = df_d2v_book.loc[book, 'd2v']\n",
    "    dv_para = d2v.infer_vector(r.para_proc)\n",
    "    dv_bullets = d2v.infer_vector(r.bullets_proc)\n",
    "    \n",
    "    return cosine_sim(dv_para, dv_bullets)\n",
    "    \n",
    "df_d2v['d2v_sim'] = df_d2v.progress_apply(lambda row: d2v_similarity(row), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Find Best Match and Expand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2556/2556 [00:01<00:00, 1306.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of paragraphs which are too short to be summarized: 54.85 %\n"
     ]
    }
   ],
   "source": [
    "# find best match bullet-para for each bullet\n",
    "df_d2v = assign_best_metric_para(df_d2v, 'd2v_sim')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2556/2556 [01:42<00:00, 25.03it/s]\n"
     ]
    }
   ],
   "source": [
    "df_d2v_expand = expand_up_down(df_d2v, 'd2v_sim')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4013 out of 18822 paragraphs are considered using this method. Thus, 21.32 %\n",
      "\n",
      "428408 out of 1493612 tokens are considered using this method. Thus, 28.68 %\n"
     ]
    }
   ],
   "source": [
    "print_stats(df_d2v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_d2v_merge = df_d2v[df_d2v['best_match']].reset_index().groupby(['book', 'chapter', 'bullets'], sort=False)\\\n",
    ".agg({\n",
    "    'para': lambda p: ' '.join(list(p)),\n",
    "    'para_num_tokens': sum,\n",
    "    'bullets_num_tokens': lambda bnt: list(bnt)[0]\n",
    "}).reset_index(level='bullets')\n",
    "df_d2v_merge = df_d2v_merge.rename(columns={'para': 'text'})\n",
    "\n",
    "df_d2v_merge['compression_ratio'] = df_d2v_merge.bullets_num_tokens / df_d2v_merge.para_num_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of paragraphs which are too short to be summarized: 0.35 %\n",
      "\n",
      "Paragraphs which are too long to fit into the model: 26 paragraphs.\n",
      "                                                                 bullets  \\\n",
      "book          chapter                                                      \n",
      "9781908541024 ch_6     Concurrent and adjuvant temozolomide chemother...   \n",
      "9781908541277 ch_11    Oral contraceptives containing at least 50 µg ...   \n",
      "9781908541406 ch_4     Specific inquiry should be made about oral ant...   \n",
      "              ch_15    The direct factor Xa and thrombin inhibitors c...   \n",
      "9781908541727 ch07     Urgently refer patients who present with any o...   \n",
      "              ch09     Refer urgently (the same day), patients with o...   \n",
      "              ch10     Refer urgently, to be seen the same day, if yo...   \n",
      "              ch10     Refer within 1 week, any child with:- squint (...   \n",
      "              ch11     Refer urgently, to be seen by an ophthalmologi...   \n",
      "9781910797006 ch01     Centriacinar (centrilobular) emphysema is the ...   \n",
      "9781910797211 ch02     At present, there are no guidelines for geneti...   \n",
      "9781910797297 chp4     The clinically aggressive cytotoxic CTCLs are:...   \n",
      "              chp4     Subcutaneous panniculitis-like T-cell lymphoma...   \n",
      "              chp4     Primary cutaneous anaplastic large cell lympho...   \n",
      "9781910797495 chp7     Pharmacotherapy, based on only a small number ...   \n",
      "              chp12    In chronic headache:- use a headache diary to ...   \n",
      "9781910797617 chp3     Midostaurin inhibits several tyrosine kinases,...   \n",
      "              chp3     Historically, treatment of acute myeloid leuke...   \n",
      "              chp3     Enasidenib inhibits aberrant isocitrate dehydr...   \n",
      "              chp6     A wide range of targeted agencies for the trea...   \n",
      "9781910797723 chp1     In cellular immunity, T cells recognize their ...   \n",
      "              chp4     Immune checkpoint inhibitors have been approve...   \n",
      "9781910797815 chp9     Myeloproliferative neoplasm (MPN) may progress...   \n",
      "9781912776139 ch3      UMN disease causes slowness, stiffness, clumsi...   \n",
      "9781912776207 ch1      Thymocytes do not express CD4 or CD8 initially...   \n",
      "9783318067095 ch9      Validation ensures that the technology is meas...   \n",
      "\n",
      "                                                                    text  \\\n",
      "book          chapter                                                      \n",
      "9781908541024 ch_6     Management. Anaplastic oligodendrogliomas have...   \n",
      "9781908541277 ch_11    Menstruation. Up to 20% of women with epilepsy...   \n",
      "9781908541406 ch_4     Bleeding scores are being developed and evalua...   \n",
      "              ch_15    The inhibitors are either antibodies or parapr...   \n",
      "9781908541727 ch07     Iris disease. The second most common cause of ...   \n",
      "              ch09     Blepharospasm is an intermittent or constant e...   \n",
      "              ch10     Young children are unable to complain of poor ...   \n",
      "              ch10     The normal red reflex seen with a direct ophth...   \n",
      "              ch11     Penetrating eye injury. It is important to sus...   \n",
      "9781910797006 ch01     Pulmonary emphysema is defined in structural a...   \n",
      "9781910797211 ch02     Large kindred studies. Several families with P...   \n",
      "9781910797297 chp4     Type E (angiotropic/angiodestructive) is chara...   \n",
      "              chp4     Like LyP, the immunophenotype of PC-ALCL is ge...   \n",
      "              chp4     Subcutaneous panniculitis-like T-cell lymphoma...   \n",
      "9781910797495 chp7     Post-stroke pain is usually located within the...   \n",
      "              chp12    Transform headache, often called rebound heada...   \n",
      "9781910797617 chp3     The aim of induction chemotherapy is complete ...   \n",
      "              chp3     Gemtuzumab ozogamicin (GO) is an antibody-toxi...   \n",
      "              chp3     Enasidenib is an oral inhibitor of isocitrate ...   \n",
      "              chp6     Recent experience with enasidenib, approved on...   \n",
      "9781910797723 chp1     In addition to the physical barrier of skin an...   \n",
      "              chp4     Immune checkpoint molecules are cell surface r...   \n",
      "9781910797815 chp9     MPN-BP is associated with a poor prognosis: me...   \n",
      "9781912776139 ch3      In lower motor neuron bulbar disease, the dysa...   \n",
      "9781912776207 ch1      T-cell receptors (TCRs) are analogous to the i...   \n",
      "9783318067095 ch9      Separating the sensor and the measure is the m...   \n",
      "\n",
      "                       para_num_tokens  bullets_num_tokens  compression_ratio  \n",
      "book          chapter                                                          \n",
      "9781908541024 ch_6                 532                 134           0.251880  \n",
      "9781908541277 ch_11                515                 108           0.209709  \n",
      "9781908541406 ch_4                 547                  65           0.118830  \n",
      "              ch_15                515                  56           0.108738  \n",
      "9781908541727 ch07                 523                 130           0.248566  \n",
      "              ch09                 587                 181           0.308348  \n",
      "              ch10                 592                 249           0.420608  \n",
      "              ch10                 561                 149           0.265597  \n",
      "              ch11                 517                 280           0.541586  \n",
      "9781910797006 ch01                 569                 115           0.202109  \n",
      "9781910797211 ch02                 617                 115           0.186386  \n",
      "9781910797297 chp4                 608                 130           0.213816  \n",
      "              chp4                 579                 127           0.219344  \n",
      "              chp4                 513                  93           0.181287  \n",
      "9781910797495 chp7                 525                 142           0.270476  \n",
      "              chp12                514                 117           0.227626  \n",
      "9781910797617 chp3                 589                  84           0.142615  \n",
      "              chp3                 603                  92           0.152570  \n",
      "              chp3                 550                 103           0.187273  \n",
      "              chp6                 548                 122           0.222628  \n",
      "9781910797723 chp1                 570                 152           0.266667  \n",
      "              chp4                 555                 145           0.261261  \n",
      "9781910797815 chp9                 555                 111           0.200000  \n",
      "9781912776139 ch3                  532                 102           0.191729  \n",
      "9781912776207 ch1                  532                 108           0.203008  \n",
      "9783318067095 ch9                  543                 197           0.362799  \n"
     ]
    }
   ],
   "source": [
    "print_stats_after_merge(df_d2v_merge)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_d2v_merge.to_csv(op+'df.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create train, test, validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_d2v_merge = df_d2v_merge.groupby(level=[0, 1], sort=False).agg({\n",
    "    'bullets': lambda b: list(b),\n",
    "    'text': lambda t: list(t),\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "361 408\n"
     ]
    }
   ],
   "source": [
    "df_d2v_merge = df_d2v_merge.sample(frac=1, random_state=config.SEED)\n",
    "df_d2v_merge['num_bulls'] = df_d2v_merge.bullets.map(len).cumsum()\n",
    "tot_bulls = df_d2v_merge.num_bulls.iloc[-1]\n",
    "split1 = np.where(df_d2v_merge.num_bulls > int(tot_bulls*0.8))[0][0]+1\n",
    "split2 = np.where(df_d2v_merge.num_bulls > int(tot_bulls*0.9))[0][0]+1\n",
    "print(split1, split2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, val, test =\\\n",
    "    df_d2v_merge.iloc[:split1].explode('bullets'),\\\n",
    "    df_d2v_merge.iloc[split1:split2].explode('bullets'),\\\n",
    "    df_d2v_merge.iloc[split2:].explode('bullets')\n",
    "\n",
    "train['text'] = df_d2v_merge.iloc[:split1].explode('text')['text']\n",
    "val['text'] = df_d2v_merge.iloc[split1:split2].explode('text')['text']\n",
    "test['text'] = df_d2v_merge.iloc[split2:].explode('text')['text']\n",
    "\n",
    "train.to_csv(op+'train.csv')\n",
    "val.to_csv(op+'val.csv')\n",
    "test.to_csv(op+'test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(op+'train.source', 'w') as tr_s,\\\n",
    "    open(op+'train.target', 'w') as tr_t,\\\n",
    "    open(op+'train.index', 'w') as tr_i:\n",
    "    for idx, row in train[['text', 'bullets']].iterrows():\n",
    "        tr_i.write(str(idx) + '\\n')\n",
    "        tr_s.write(row.text + '\\n')\n",
    "        tr_t.write(row.bullets + '\\n')\n",
    "        \n",
    "with open(op+'val.source', 'w') as va_s,\\\n",
    "    open(op+'val.target', 'w') as va_t,\\\n",
    "    open(op+'val.index', 'w') as va_i:\n",
    "    for idx, row in val[['text', 'bullets']].iterrows():\n",
    "        va_i.write(str(idx) + '\\n')\n",
    "        va_s.write(row.text + '\\n')\n",
    "        va_t.write(row.bullets + '\\n')\n",
    "        \n",
    "with open(op+'test.source', 'w') as te_s,\\\n",
    "    open(op+'test.target', 'w') as te_t,\\\n",
    "    open(op+'test.index', 'w') as te_i:\n",
    "    for idx, row in test[['text', 'bullets']].iterrows():\n",
    "        te_i.write(str(idx) + '\\n')\n",
    "        te_s.write(row.text + '\\n')\n",
    "        te_t.write(row.bullets + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Sentence-Transformers Book Level**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "op = OUTPUT_PATH + 'st/'\n",
    "if not os.path.exists(op):\n",
    "    os.makedirs(op)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_st = df.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create embedding vectors for para"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 18773/18773 [23:30<00:00, 13.31it/s]\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# might want to try 'msmarco-distilbert-base-v2' too\n",
    "model = SentenceTransformer('paraphrase-distilroberta-base-v1')\n",
    "\n",
    "df_st['para_enc'] = df_st.para.progress_map(model.encode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Explode bullets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_st = df_st.explode('bullets')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 114277/114277 [00:51<00:00, 2225.06it/s]\n",
      "100%|██████████| 114277/114277 [00:42<00:00, 2699.42it/s]\n"
     ]
    }
   ],
   "source": [
    "df_st['para_num_tokens'] = df_st.para.progress_map(lambda p: len(tokenizer.tokenize(p)))\n",
    "df_st['bullets_num_tokens'] = df_st.bullets.progress_map(lambda b: len(tokenizer.tokenize(b)))\n",
    "\n",
    "df_st['compression_ratio'] = df_st.bullets_num_tokens / df_st.para_num_tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create embedding vectors for bullets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2556/2556 [01:53<00:00, 22.60it/s]\n"
     ]
    }
   ],
   "source": [
    "bull_to_embed = df_st.groupby(['book', 'chapter'], sort=False).agg({\n",
    "    'bullets': lambda b: list(set(b))\n",
    "}).explode('bullets')\n",
    "\n",
    "bull_to_embed['bullets_enc'] = bull_to_embed.bullets.progress_map(model.encode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculate similarity between each couple bullet-para"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 114277/114277 [01:29<00:00, 1274.74it/s]\n"
     ]
    }
   ],
   "source": [
    "def cosine_sim(a, b):\n",
    "    return np.dot(a, b) / (np.linalg.norm(a)*np.linalg.norm(b))\n",
    "\n",
    "def sentence_transformers_sim(r):\n",
    "    book = r.name[0]\n",
    "    b2e = bull_to_embed.loc[book]\n",
    "    para_enc = r.para_enc\n",
    "    bullets_enc = b2e.loc[(b2e.bullets == r.bullets), 'bullets_enc']\n",
    "    assert len(bullets_enc) == 1\n",
    "    bullets_enc = bullets_enc[0]\n",
    "    \n",
    "    return cosine_sim(para_enc, bullets_enc)\n",
    "    \n",
    "df_st['st_sim'] = df_st.progress_apply(sentence_transformers_sim, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Find Best Match and Expand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2556/2556 [00:01<00:00, 2179.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of paragraphs which are too short to be summarized: 64.01 %\n"
     ]
    }
   ],
   "source": [
    "# find best match bullet-para for each bullet\n",
    "df_st = assign_best_metric_para(df_st, 'st_sim')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2556/2556 [01:52<00:00, 22.69it/s]\n"
     ]
    }
   ],
   "source": [
    "df_st = expand_up_down(df_st, 'st_sim')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4560 out of 18822 paragraphs are considered using this method. Thus, 24.23 %\n",
      "\n",
      "430587 out of 1493612 tokens are considered using this method. Thus, 28.83 %\n"
     ]
    }
   ],
   "source": [
    "print_stats(df_st)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_st_merge = df_st[df_st['best_match']].reset_index().groupby(['book', 'chapter', 'bullets'], sort=False)\\\n",
    ".agg({\n",
    "    'para': lambda p: ' '.join(list(p)),\n",
    "    'para_num_tokens': sum,\n",
    "    'bullets_num_tokens': lambda bnt: list(bnt)[0]\n",
    "}).reset_index(level='bullets')\n",
    "df_st_merge = df_st_merge.rename(columns={'para': 'text'})\n",
    "\n",
    "df_st_merge['compression_ratio'] = df_st_merge.bullets_num_tokens / df_st_merge.para_num_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of paragraphs which are too short to be summarized: 0.27 %\n",
      "\n",
      "Paragraphs which are too long to fit into the model: 26 paragraphs.\n",
      "                                                                 bullets  \\\n",
      "book          chapter                                                      \n",
      "9781908541024 ch_6     Concurrent and adjuvant temozolomide chemother...   \n",
      "              ch_6     Observation may be an appropriate initial stra...   \n",
      "9781908541086 ch_11    Eating disorders not otherwise specified is th...   \n",
      "9781908541277 ch_11    Oral contraceptives containing at least 50 µg ...   \n",
      "9781908541420 ch_6     Drugs used in the management of asthma can be ...   \n",
      "9781908541727 ch07     Urgently refer patients who present with any o...   \n",
      "              ch09     Refer urgently (the same day), patients with o...   \n",
      "              ch10     Refer urgently, to be seen the same day, if yo...   \n",
      "              ch10     Refer within 1 week, any child with:- squint (...   \n",
      "              ch11     Refer urgently, to be seen by an ophthalmologi...   \n",
      "9781910797211 ch02     At present, there are no guidelines for geneti...   \n",
      "9781910797273 chp5     Newer DMTs, such as natalizumab, alemtuzumab a...   \n",
      "9781910797297 chp4     Subcutaneous panniculitis-like T-cell lymphoma...   \n",
      "              chp4     The clinically aggressive cytotoxic CTCLs are:...   \n",
      "9781910797495 chp1     After nerve injury there may be a loss of spin...   \n",
      "              chp7     Pharmacotherapy, based on only a small number ...   \n",
      "              chp12    In chronic headache:- use a headache diary to ...   \n",
      "9781910797617 chp3     Enasidenib inhibits aberrant isocitrate dehydr...   \n",
      "              chp6     A wide range of targeted agencies for the trea...   \n",
      "9781910797723 chp1     In cellular immunity, T cells recognize their ...   \n",
      "              chp4     Immune checkpoint inhibitors have been approve...   \n",
      "9781910797815 chp9     Myeloproliferative neoplasm (MPN) may progress...   \n",
      "9781912776139 ch3      UMN disease causes slowness, stiffness, clumsi...   \n",
      "9781912776726 ch4      The current standard of care is surgery follow...   \n",
      "              ch6      Novel therapeutic management approaches for pa...   \n",
      "9783318067095 ch9      Validation ensures that the technology is meas...   \n",
      "\n",
      "                                                                    text  \\\n",
      "book          chapter                                                      \n",
      "9781908541024 ch_6     Management. Anaplastic oligodendrogliomas have...   \n",
      "              ch_6     Management. Anaplastic oligodendrogliomas have...   \n",
      "9781908541086 ch_11    Other eating disorders. Eating disorders not o...   \n",
      "9781908541277 ch_11    Contraception. Carbamazepine (CBZ), eslicarbaz...   \n",
      "9781908541420 ch_6     Combination therapy. A series of clinical tria...   \n",
      "9781908541727 ch07     double vision due to tightening of the swollen...   \n",
      "              ch09     It is essential to differentiate orbital cellu...   \n",
      "              ch10     Most infants and children with 'watery' eyes h...   \n",
      "              ch10     Suspected poor vision. Young children are unab...   \n",
      "              ch11     Eye trauma. Minor eye trauma is common and rar...   \n",
      "9781910797211 ch02     Previously identified genes have been pivotal ...   \n",
      "9781910797273 chp5     Treatment escalation strategy. Until the mid-2...   \n",
      "9781910797297 chp4     Pathology illustrates a dense, diffuse dermal ...   \n",
      "              chp4     Because of the clinically aggressive nature of...   \n",
      "9781910797495 chp1     The processes shown in Figure 1.8 can become p...   \n",
      "              chp7     Antidepressants. A reduction in central post-s...   \n",
      "              chp12    For intractable migraine and occipital neuralg...   \n",
      "9781910797617 chp3     Enasidenib is an oral inhibitor of isocitrate ...   \n",
      "              chp6     The expanded genetic characterization of acute...   \n",
      "9781910797723 chp1     Cellular immunity. Surface T cell receptors (T...   \n",
      "              chp4     Ipilimumab (Yevoy ®, BMS) and tremelimumab (As...   \n",
      "9781910797815 chp9     Management of myeloproliferative neoplasm blas...   \n",
      "9781912776139 ch3      In lower motor neuron bulbar disease, the dysa...   \n",
      "9781912776726 ch4      Radiotherapy. Postoperative radiotherapy alone...   \n",
      "              ch6      Emerging research and treatment. Glioblastoma ...   \n",
      "9783318067095 ch9      Once you have arrived at a construct to measur...   \n",
      "\n",
      "                       para_num_tokens  bullets_num_tokens  compression_ratio  \n",
      "book          chapter                                                          \n",
      "9781908541024 ch_6                 642                 134           0.208723  \n",
      "              ch_6                 642                  92           0.143302  \n",
      "9781908541086 ch_11                520                  61           0.117308  \n",
      "9781908541277 ch_11                582                 108           0.185567  \n",
      "9781908541420 ch_6                 647                  63           0.097372  \n",
      "9781908541727 ch07                 514                 130           0.252918  \n",
      "              ch09                 515                 181           0.351456  \n",
      "              ch10                 522                 249           0.477011  \n",
      "              ch10                 598                 149           0.249164  \n",
      "              ch11                 533                 280           0.525328  \n",
      "9781910797211 ch02                 544                 115           0.211397  \n",
      "9781910797273 chp5                 577                  54           0.093588  \n",
      "9781910797297 chp4                 640                 127           0.198437  \n",
      "              chp4                 525                 130           0.247619  \n",
      "9781910797495 chp1                 580                  81           0.139655  \n",
      "              chp7                 548                 142           0.259124  \n",
      "              chp12                554                 117           0.211191  \n",
      "9781910797617 chp3                 550                 103           0.187273  \n",
      "              chp6                 552                 122           0.221014  \n",
      "9781910797723 chp1                 599                 152           0.253756  \n",
      "              chp4                 618                 145           0.234628  \n",
      "9781910797815 chp9                 519                 111           0.213873  \n",
      "9781912776139 ch3                  532                 102           0.191729  \n",
      "9781912776726 ch4                  544                  71           0.130515  \n",
      "              ch6                  545                  73           0.133945  \n",
      "9783318067095 ch9                  529                 197           0.372401  \n"
     ]
    }
   ],
   "source": [
    "print_stats_after_merge(df_st_merge)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_st_merge.to_csv(op+'df.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create train, test, validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_st_merge = df_st_merge.groupby(level=[0, 1], sort=False).agg({\n",
    "    'bullets': lambda b: list(b),\n",
    "    'text': lambda t: list(t),\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "361 408\n"
     ]
    }
   ],
   "source": [
    "df_st_merge = df_st_merge.sample(frac=1, random_state=config.SEED)\n",
    "df_st_merge['num_bulls'] = df_st_merge.bullets.map(len).cumsum()\n",
    "tot_bulls = df_st_merge.num_bulls.iloc[-1]\n",
    "split1 = np.where(df_st_merge.num_bulls > int(tot_bulls*0.8))[0][0]+1\n",
    "split2 = np.where(df_st_merge.num_bulls > int(tot_bulls*0.9))[0][0]+1\n",
    "print(split1, split2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, val, test =\\\n",
    "    df_st_merge.iloc[:split1].explode('bullets'),\\\n",
    "    df_st_merge.iloc[split1:split2].explode('bullets'),\\\n",
    "    df_st_merge.iloc[split2:].explode('bullets')\n",
    "\n",
    "train['text'] = df_st_merge.iloc[:split1].explode('text')['text']\n",
    "val['text'] = df_st_merge.iloc[split1:split2].explode('text')['text']\n",
    "test['text'] = df_st_merge.iloc[split2:].explode('text')['text']\n",
    "\n",
    "train.to_csv(op+'train.csv')\n",
    "val.to_csv(op+'val.csv')\n",
    "test.to_csv(op+'test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(op+'train.source', 'w') as tr_s,\\\n",
    "    open(op+'train.target', 'w') as tr_t,\\\n",
    "    open(op+'train.index', 'w') as tr_i:\n",
    "    for idx, row in train[['text', 'bullets']].iterrows():\n",
    "        tr_i.write(str(idx) + '\\n')\n",
    "        tr_s.write(row.text + '\\n')\n",
    "        tr_t.write(row.bullets + '\\n')\n",
    "        \n",
    "with open(op+'val.source', 'w') as va_s,\\\n",
    "    open(op+'val.target', 'w') as va_t,\\\n",
    "    open(op+'val.index', 'w') as va_i:\n",
    "    for idx, row in val[['text', 'bullets']].iterrows():\n",
    "        va_i.write(str(idx) + '\\n')\n",
    "        va_s.write(row.text + '\\n')\n",
    "        va_t.write(row.bullets + '\\n')\n",
    "        \n",
    "with open(op+'test.source', 'w') as te_s,\\\n",
    "    open(op+'test.target', 'w') as te_t,\\\n",
    "    open(op+'test.index', 'w') as te_i:\n",
    "    for idx, row in test[['text', 'bullets']].iterrows():\n",
    "        te_i.write(str(idx) + '\\n')\n",
    "        te_s.write(row.text + '\\n')\n",
    "        te_t.write(row.bullets + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HO7BPitFH8Th"
   },
   "source": [
    "### **Print Some Examples**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nice_print(idx, bull, list_text, list_text_num_tok, list_method):\n",
    "    print(idx)\n",
    "    print()\n",
    "    print('Bullet:')\n",
    "    print(fill(bull, 100))\n",
    "    print()\n",
    "    for t, tok, m in zip(list_text, list_text_num_tok, list_method):\n",
    "        print(m+' (' +str(tok)+'):')\n",
    "        print(fill(t, 100))\n",
    "        print()\n",
    "    \n",
    "    print(''.join(['#']*100))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### W2V vs D2V vs Sentence-Transformers vs Rouge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 579,
     "status": "ok",
     "timestamp": 1610463902969,
     "user": {
      "displayName": "Marco Pietro Abrate",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gjh-8YF-8BlnrkN9mLZ0xfVOWfOh7kYncpYRv-Y=s64",
      "userId": "15422244832836998434"
     },
     "user_tz": -60
    },
    "id": "tvWJmbjVH-qN",
    "outputId": "861d6b76-0978-4aec-bb7a-86609006f34e",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Pregnant women with significant renal impairment are likely to have hypertension, pre-eclampsia and premature labor.', 'Neuronal tumors are uncommon brain neoplasms typically diagnosed in children and young adults.', 'The prevention of nausea has been much less successful with currently approved agents.', 'Lung transplantation in patients with very advanced COPD improves health status and functional capacity, though it does not convey a survival benefit.', 'Acne scarring is a very common sequel to acne.', 'Decreased waist circumference in the absence of weight loss can keep a patient motivated.', 'Causes of acute asthma include viral respiratory infections, acute allergen exposure, food allergies and some medications such as acetylsalicylic acid (aspirin) and non-steroidal anti-inflammatory drugs.', 'Biosimilars are highly similar, but not identical, to their reference (originator) biologic.', 'FXI concentrates should be used with caution, because they predispose to arterial and venous thromboembolism. Fresh frozen plasma is often effective therapy, but exposure to normal FXI in plasma or concentrates carries a risk of inhibitor development in those with type 2 disease.', 'Abdominal imaging is useful for confirming the diagnosis of AP in atypical cases, ruling out other conditions.']\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "df_w2v = pd.read_csv(OUTPUT_PATH+'w2v/df.csv').set_index(['book', 'chapter'])\n",
    "df_d2v = pd.read_csv(OUTPUT_PATH+'d2v/df.csv').set_index(['book', 'chapter'])\n",
    "df_st = pd.read_csv(OUTPUT_PATH+'st/df.csv').set_index(['book', 'chapter'])\n",
    "df_rouge = pd.read_csv(magma_dir+'datasets/karger_books_para/'+MODEL+'/df.csv').set_index(['book', 'chapter'])\n",
    "\n",
    "random.seed(config.SEED)\n",
    "\n",
    "bullet_examples = random.sample(df_w2v.bullets.tolist(), 10)\n",
    "print(bullet_examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9781908541468, 'ch_7')\n",
      "\n",
      "Bullet:\n",
      "Pregnant women with significant renal impairment are likely to have hypertension, pre-eclampsia and\n",
      "premature labor.\n",
      "\n",
      "W2V (229):\n",
      "Renovascular disease is a remediable form of hypertension and should be excluded in high-risk\n",
      "patients, such as elderly hypertensives with evidence of diffuse atherosclerosis, in refractory or\n",
      "malignant hypertension, in those with 'flash' pulmonary edema and in individuals with an abdominal\n",
      "bruit. In young women with hypertension of recent onset, fibromuscular renal artery disease should\n",
      "be excluded. The preferred diagnostic tests include magnetic resonance angiography and ACE-inhibitor\n",
      "renography. Duplex ultrasonography with Doppler flow measurements can be a useful screening test but\n",
      "is rather operator dependent, and in many patients the renal arteries cannot be visualized. The\n",
      "definitive diagnostic tests in almost all patients are still digital subtraction angiography or\n",
      "arteriography (Figure 5.3), but both carry a risk of contrast nephropathy and cholesterol\n",
      "embolization. Magnetic resonance angiography with gadolinium is not recommended in patients with an\n",
      "estimated glomerular filtration rate (GFR) of less than 60 mL/min/1.73m because of the risk of\n",
      "gadolinium-associated nephrogenic skin fibrosis, although the risk is very small and possibly\n",
      "dependent on the type of gadolinium used.\n",
      "\n",
      "D2V (90):\n",
      "Antihypertensive agents must be reviewed in women with renal disease who wish to get pregnant.\n",
      "Methyldopa, labetalol, hydralazine and nifedipine are all safe drugs for treating hypertension in\n",
      "pregnancy, but diuretics should be avoided. ACE inhibitors are contraindicated from the second\n",
      "trimester, but may be important in controlling the progression of CKD. Women may therefore continue\n",
      "to take these as they plan a pregnancy but must stop when pregnant.\n",
      "\n",
      "Sentence-Transformers (202):\n",
      "The degree of albuminuria varies quite significantly, but not uncommonly reaches nephrotic levels (>\n",
      "3.5 g/24 hours). Once clinical albuminuria has developed, the GFR often declines relentlessly by\n",
      "5-15 mL/minute/year. The mortality of patients with diabetic nephropathy is higher than in other\n",
      "patients because of a four- to eightfold increase in the rate of cardiovascular complications. In\n",
      "patients with both type 1 and type 2 diabetes, the onset of microalbuminuria is a major risk factor\n",
      "for both cardiovascular disease and mortality, and is also associated with retinopathy, left\n",
      "ventricular cardiac dysfunction and dyslipidemia, as well as hypertension. In all patients with\n",
      "microalbuminuria, other cardiovascular risk factors should be managed by, for example, lowering low-\n",
      "density lipoprotein (LDL) cholesterol, the use of antihypertensive therapy, cessation of smoking and\n",
      "taking exercise. Diabetic nephropathy in pregnancy can lead to worse hypertension, an increased risk\n",
      "of pre-eclampsia and an accelerated decline in kidney function.\n",
      "\n",
      "ROUGE (226):\n",
      "Hypertension during pregnancy is defined as any rise in systolic blood pressure of more than 30 mmHg\n",
      "or a rise in diastolic blood pressure of more than 15 mmHg above baseline, or the use of\n",
      "antihypertensive agents. It is classified according to its presentation (Table 5.5). Chronic\n",
      "hypertension is more common in multiparous women, and is present at the first antenatal visit. On\n",
      "the other hand, pre-eclampsia is more common in primigravidas (in 10% of first pregnancies), and\n",
      "represents an important cause of maternal and perinatal mortality. It usually presents only after 20\n",
      "weeks of gestation, with or without proteinuria and a raised serum urate. Elevated levels of soluble\n",
      "fms-like tyrosine kinase-1 (sFlt-1 or sVEGFR-1) and endoglin have been reported in pre-eclampsia and\n",
      "have been implicated in disease pathogenesis. Pre-eclampsia may progress to full-blown eclampsia,\n",
      "which is characterized by seizures and also associated with acute kidney injury (AKI). Management of\n",
      "eclampsia comprises immediate delivery, and magnesium sulfate, anticonvulsant and antihypertensive\n",
      "therapy.\n",
      "\n",
      "####################################################################################################\n",
      "\n",
      "(9781908541024, 'ch_8')\n",
      "\n",
      "Bullet:\n",
      "Neuronal tumors are uncommon brain neoplasms typically diagnosed in children and young adults.\n",
      "\n",
      "W2V (92):\n",
      "Neuronal tumors are very uncommon brain neoplasms that tend to affect children and young adults\n",
      "(Table 7.1). There are often few signs and symptoms other than intractable epilepsy. The rarity of\n",
      "these neoplasms has been a source of considerable confusion and controversy, and it is only over the\n",
      "past two decades that many of these neoplasms have been recognized as distinct clinicopathological\n",
      "entities. General management guidelines are shown in Figure 7.1, and specific treatment issues are\n",
      "discussed below.\n",
      "\n",
      "D2V (88):\n",
      "Central neurocytomas constitute approximately 0.25% of all primary brain tumors. They are usually\n",
      "located between the hemispheres, attached either to the septum pellucidum or wall of the lateral\n",
      "ventricle. Rarely, they arise within the third ventricle or intraparenchymally. These tumors usually\n",
      "present in individuals aged 20-40 years. Symptoms are typically due to hydrocephalus, and include\n",
      "headaches, nausea and vomiting, and diplopia.\n",
      "\n",
      "Sentence-Transformers (92):\n",
      "Neuronal tumors are very uncommon brain neoplasms that tend to affect children and young adults\n",
      "(Table 7.1). There are often few signs and symptoms other than intractable epilepsy. The rarity of\n",
      "these neoplasms has been a source of considerable confusion and controversy, and it is only over the\n",
      "past two decades that many of these neoplasms have been recognized as distinct clinicopathological\n",
      "entities. General management guidelines are shown in Figure 7.1, and specific treatment issues are\n",
      "discussed below.\n",
      "\n",
      "ROUGE (92):\n",
      "Neuronal tumors are very uncommon brain neoplasms that tend to affect children and young adults\n",
      "(Table 7.1). There are often few signs and symptoms other than intractable epilepsy. The rarity of\n",
      "these neoplasms has been a source of considerable confusion and controversy, and it is only over the\n",
      "past two decades that many of these neoplasms have been recognized as distinct clinicopathological\n",
      "entities. General management guidelines are shown in Figure 7.1, and specific treatment issues are\n",
      "discussed below.\n",
      "\n",
      "####################################################################################################\n",
      "\n",
      "(9781910797150, 'ch02')\n",
      "\n",
      "Bullet:\n",
      "The prevention of nausea has been much less successful with currently approved agents.\n",
      "\n",
      "W2V (70):\n",
      "The use of antiemetic agents, as recommended by international guidelines, has been shown to prevent\n",
      "emesis in approximately 50-70% of patients receiving either highly or moderately emetogenic\n",
      "chemotherapy. - The prevention of nausea has been much less successful with currently approved\n",
      "agents., New agents and new combinations of agents are necessary to adequately prevent chemotherapy-\n",
      "induced nausea.\n",
      "\n",
      "D2V (67):\n",
      "Patient characteristics also influence the potential for CINV (Table 2.2). Young women with a\n",
      "history of motion sickness, emesis during pregnancy and no history of alcohol consumption have the\n",
      "highest risk of developing significant CINV. These patients should receive the most effective\n",
      "prophylactic antiemetic regimen available based on the international antiemetic guidelines (see\n",
      "Chapter 4).\n",
      "\n",
      "Sentence-Transformers (70):\n",
      "The use of antiemetic agents, as recommended by international guidelines, has been shown to prevent\n",
      "emesis in approximately 50-70% of patients receiving either highly or moderately emetogenic\n",
      "chemotherapy. - The prevention of nausea has been much less successful with currently approved\n",
      "agents., New agents and new combinations of agents are necessary to adequately prevent chemotherapy-\n",
      "induced nausea.\n",
      "\n",
      "ROUGE (70):\n",
      "The use of antiemetic agents, as recommended by international guidelines, has been shown to prevent\n",
      "emesis in approximately 50-70% of patients receiving either highly or moderately emetogenic\n",
      "chemotherapy. - The prevention of nausea has been much less successful with currently approved\n",
      "agents., New agents and new combinations of agents are necessary to adequately prevent chemotherapy-\n",
      "induced nausea.\n",
      "\n",
      "####################################################################################################\n",
      "\n",
      "(9781910797006, 'ch07')\n",
      "\n",
      "Bullet:\n",
      "Lung transplantation in patients with very advanced COPD improves health status and functional\n",
      "capacity, though it does not convey a survival benefit.\n",
      "\n",
      "W2V (222):\n",
      "Lung volume reduction surgery has been shown to improve FEV, decrease total lung capacity, and\n",
      "improve exercise tolerance and quality of life; these effects may last for more than 2 years. In\n",
      "addition, longer-term follow-up has shown that lung volume reduction surgery leads to an improvement\n",
      "in maximal work capacity and health-related quality of life, a reduction in exacerbation frequency\n",
      "and improved survival. These beneficial effects are largely seen in those patients with predominant\n",
      "upper-zone emphysema and poor exercise tolerance. The efficacy of surgical and bronchoscopic lung\n",
      "volume reduction also depends on the presence of collateral ventilation to the diseased lobe\n",
      "(detected by the presence of an incomplete fissure between the lung lobes on CT scanning). Lung\n",
      "volume reduction surgery is expensive and should be reserved for carefully selected patients. Lung\n",
      "transplantation. In patients with very advanced COPD, lung transplantation has been shown to improve\n",
      "health status and functional capacity, though it does not convey a survival benefit. The main\n",
      "criteria for lung transplantation are a Bode index (Body mass index, Obstruction, Dyspnea, Exercise;\n",
      "see Table 4.2) of 7-10 and one of the following.\n",
      "\n",
      "D2V (204):\n",
      "Clinical monitoring. In view of the above, all patients with COPD should be treated initially and\n",
      "aggressively with bronchodilators to control symptoms. Their response should be monitored with\n",
      "objective measures of airflow and on the basis of clinical outcomes, such as symptoms and\n",
      "performance. Adequate assessment of clinical response may require exercise challenge. It is common\n",
      "for patients with COPD to restrict their level of activity progressively as the disease worsens.\n",
      "This reduces dyspnea, but at the cost of an increasingly sedentary existence. Treatment with\n",
      "bronchodilators alone is often insufficient to treat such patients. Usually, improvements in\n",
      "physiological function can benefit the patient only if the bronchodilator treatment is used together\n",
      "with an aggressive rehabilitation program (see pages 113 -). Thus, though bronchodilators form\n",
      "first-line therapy in COPD, for their use to be successful they must be integrated into an\n",
      "appropriate management plan, such as that suggested in the GOLD strategy document (see Table 7.2) or\n",
      "the COPD Foundation Guide (see Table 7.1).\n",
      "\n",
      "Sentence-Transformers (222):\n",
      "Lung volume reduction surgery has been shown to improve FEV, decrease total lung capacity, and\n",
      "improve exercise tolerance and quality of life; these effects may last for more than 2 years. In\n",
      "addition, longer-term follow-up has shown that lung volume reduction surgery leads to an improvement\n",
      "in maximal work capacity and health-related quality of life, a reduction in exacerbation frequency\n",
      "and improved survival. These beneficial effects are largely seen in those patients with predominant\n",
      "upper-zone emphysema and poor exercise tolerance. The efficacy of surgical and bronchoscopic lung\n",
      "volume reduction also depends on the presence of collateral ventilation to the diseased lobe\n",
      "(detected by the presence of an incomplete fissure between the lung lobes on CT scanning). Lung\n",
      "volume reduction surgery is expensive and should be reserved for carefully selected patients. Lung\n",
      "transplantation. In patients with very advanced COPD, lung transplantation has been shown to improve\n",
      "health status and functional capacity, though it does not convey a survival benefit. The main\n",
      "criteria for lung transplantation are a Bode index (Body mass index, Obstruction, Dyspnea, Exercise;\n",
      "see Table 4.2) of 7-10 and one of the following.\n",
      "\n",
      "ROUGE (222):\n",
      "Lung volume reduction surgery has been shown to improve FEV, decrease total lung capacity, and\n",
      "improve exercise tolerance and quality of life; these effects may last for more than 2 years. In\n",
      "addition, longer-term follow-up has shown that lung volume reduction surgery leads to an improvement\n",
      "in maximal work capacity and health-related quality of life, a reduction in exacerbation frequency\n",
      "and improved survival. These beneficial effects are largely seen in those patients with predominant\n",
      "upper-zone emphysema and poor exercise tolerance. The efficacy of surgical and bronchoscopic lung\n",
      "volume reduction also depends on the presence of collateral ventilation to the diseased lobe\n",
      "(detected by the presence of an incomplete fissure between the lung lobes on CT scanning). Lung\n",
      "volume reduction surgery is expensive and should be reserved for carefully selected patients. Lung\n",
      "transplantation. In patients with very advanced COPD, lung transplantation has been shown to improve\n",
      "health status and functional capacity, though it does not convey a survival benefit. The main\n",
      "criteria for lung transplantation are a Bode index (Body mass index, Obstruction, Dyspnea, Exercise;\n",
      "see Table 4.2) of 7-10 and one of the following.\n",
      "\n",
      "####################################################################################################\n",
      "\n",
      "(9781908541994, 'ch03')\n",
      "\n",
      "Bullet:\n",
      "Acne scarring is a very common sequel to acne.\n",
      "\n",
      "W2V (41):\n",
      "Table 3.1 outlines the key elements in developing an accurate acne history. Acne vulgaris. Acne\n",
      "vulgaris is the most common type of acne. The individual lesions of acne vulgaris (Figure 3.1) can\n",
      "be characterized as.\n",
      "\n",
      "D2V (45):\n",
      "Inflammatory lesions may be superficial (papules, pustules) or deep (deep pustules or nodules).\n",
      "Papules are small raised red spots (< 5 mm) that persist for 7-10 days (Figure 3.4).\n",
      "\n",
      "Sentence-Transformers (96):\n",
      "Acne mechanica. Repetitive rubbing or friction can sometimes exacerbate acne. This is most commonly\n",
      "observed with sports equipment such as football helmets, shoulder pads and chin straps. It can also\n",
      "occur in response to habits of rubbing the face or resting the head on the hands. Acne mechanica\n",
      "tends to occur in cases of moderate-to-severe inflammatory acne and less often in cases of mild\n",
      "acne. Treatment is aimed at controlling the underlying acne and minimizing the mechanical stress on\n",
      "the skin.\n",
      "\n",
      "ROUGE (162):\n",
      "Acne fulminans is a very severe form of inflammatory acne associated with systemic signs and\n",
      "symptoms, including fever, arthralgias and/or osteolytic lesions of the clavicles or ribs. It\n",
      "usually occurs in boys aged 13-18 years and can be very acute in its onset. Investigations\n",
      "frequently demonstrate leukocytosis, elevated erythrocyte sedimentation rate and/or proteinuria.\n",
      "Clinically, acne fulminans is characterized by multiple intensely inflamed nodules, cysts and\n",
      "plaques (Figure 3.9). Large nodules can ulcerate, drain and become necrotic. Hemorrhagic crusting is\n",
      "common. A polyarthritis of large joints such as the sacroiliac, hips, knees, shoulders, elbows and\n",
      "ankles may be present. The etiology of acne fulminans is unknown.\n",
      "\n",
      "####################################################################################################\n",
      "\n",
      "(9781908541680, 'ch_2')\n",
      "\n",
      "Bullet:\n",
      "Decreased waist circumference in the absence of weight loss can keep a patient motivated.\n",
      "\n",
      "W2V (69):\n",
      "Waist circumference is also a useful and tangible marker of weight loss (or gain) for patients. An\n",
      "individual who has increased their physical activity and maintained their dietary intake will lose\n",
      "centimeters around the waist even though they may gain weight as muscle mass increases. Monitoring\n",
      "waist circumference will therefore keep them motivated when lack of change in bodyweight might prove\n",
      "demoralizing.\n",
      "\n",
      "D2V (121):\n",
      "The examination should include measurement of height, weight and waist circumference (see Assessment\n",
      "of body fat). Body fat analysis is optional but is useful for identifying patients with a normal\n",
      "body mass index (BMI) but high percentage of fat and for monitoring progress, in particular\n",
      "providing encouragement to patients who are improving their health by increased activity but who\n",
      "fail to lose weight. A general visual assessment of a person's fat distribution and body morphology\n",
      "is useful to define a central, peripheral or mixed pattern of fat distribution. The presence of any\n",
      "dysmorphic features should be noted, as these may suggest the presence of an obesity syndrome.\n",
      "\n",
      "Sentence-Transformers (69):\n",
      "Waist circumference is also a useful and tangible marker of weight loss (or gain) for patients. An\n",
      "individual who has increased their physical activity and maintained their dietary intake will lose\n",
      "centimeters around the waist even though they may gain weight as muscle mass increases. Monitoring\n",
      "waist circumference will therefore keep them motivated when lack of change in bodyweight might prove\n",
      "demoralizing.\n",
      "\n",
      "ROUGE (91):\n",
      "A patient attending a diabetes or cardiovascular clinic can be asked whether they have lost or\n",
      "gained weight recently. Any patient can be offered a 'well patient check' during a consultation,\n",
      "which will include measurement of weight, height and waist circumference. 'Best practice in weight\n",
      "management' can be performed in the last 2 minutes of any consultation, provided that appropriate\n",
      "follow-up is offered. These 2 minutes are the most important part of the entire weight-loss program.\n",
      "\n",
      "####################################################################################################\n",
      "\n",
      "(9781908541420, 'ch_8')\n",
      "\n",
      "Bullet:\n",
      "Causes of acute asthma include viral respiratory infections, acute allergen exposure, food allergies\n",
      "and some medications such as acetylsalicylic acid (aspirin) and non-steroidal anti-inflammatory\n",
      "drugs.\n",
      "\n",
      "W2V (366):\n",
      "Other causes of acute asthma include acute allergen exposure, when an allergic person is exposed to\n",
      "an allergen not usually encountered in the environment. Examples of this include 'thunderstorm\n",
      "asthma' in people who usually have allergic rhinitis due to grass pollens, or individuals with\n",
      "allergy to molds. Inhalation of small allergen particles into the lower respiratory tract can cause\n",
      "a severe asthma episode and weather patterns can lead to epidemics of asthma in such circumstances.\n",
      "Similarly, severe food allergies (exempli gratia to peanuts or shellfish) may trigger asthma. While\n",
      "individuals with such a food allergy often present with signs of anaphylaxis, acute asthma is a\n",
      "major component of a severe food reaction for some and it requires recognition and treatment in its\n",
      "own right. Some medications, such as beta-blockers - even in eye drops - may also be responsible for\n",
      "an acute exacerbation of asthma. Individuals with acetylsalicylic acid (ASA; aspirin)-sensitive\n",
      "asthma may have severe asthma after taking ASA or other non-steroidal anti-inflammatory drug (NSAID)\n",
      "that has cyclooxygenase (COX)-1 activity such as indometacin, ibuprofen, naproxen, piroxicam, and\n",
      "nabumetone. The mechanism probably relates to inhibition of formation of protective prostaglandins\n",
      "such as prostaglandin E (PGE). COX-2 inhibitors such as celecoxib are much less likely to cause\n",
      "reactions. NSAID reactions are most often described in individuals with non-allergic asthma who have\n",
      "nasal polyposis. Individuals with this type of asthma should avoid ASA and preferably all NSAIDs,\n",
      "although if absolutely necessary (exempli gratia a patient with severe rheumatoid arthritis and\n",
      "asthma), a supervised trial of a COX-2 inhibitor might be considered. It is important to be aware of\n",
      "other preventable causes of exacerbations such as occupational and sometimes unusual allergen\n",
      "exposures.\n",
      "\n",
      "D2V (188):\n",
      "For less severe attacks that do not require hospital presentation, the first step is to increase\n",
      "regular bronchodilator therapy (however, frequent symptoms and frequent requirement for\n",
      "bronchodilator suggest that further treatment is needed). Less severe asthma attacks are diagnosed\n",
      "by frequent requirement for bronchodilator (up to once every 4 hours), night waking with asthma and\n",
      "breathlessness. As a rule, the PEF will be 50-80% of predicted, with the range depending on the\n",
      "person's asthma history. Oral corticosteroids, that is prednisolone, 1 mg/kg or 50 mg daily for\n",
      "adults, may be initiated by the patient in consultation with a primary care practitioner. For those\n",
      "with more severe asthma, prompt access to a supply of oral corticosteroids is important to prevent\n",
      "severe exacerbations, and such patients may keep a store of these medications at home. Once started,\n",
      "oral corticosteroid therapy should be continued for at least 5 days.\n",
      "\n",
      "Sentence-Transformers (366):\n",
      "Other causes of acute asthma include acute allergen exposure, when an allergic person is exposed to\n",
      "an allergen not usually encountered in the environment. Examples of this include 'thunderstorm\n",
      "asthma' in people who usually have allergic rhinitis due to grass pollens, or individuals with\n",
      "allergy to molds. Inhalation of small allergen particles into the lower respiratory tract can cause\n",
      "a severe asthma episode and weather patterns can lead to epidemics of asthma in such circumstances.\n",
      "Similarly, severe food allergies (exempli gratia to peanuts or shellfish) may trigger asthma. While\n",
      "individuals with such a food allergy often present with signs of anaphylaxis, acute asthma is a\n",
      "major component of a severe food reaction for some and it requires recognition and treatment in its\n",
      "own right. Some medications, such as beta-blockers - even in eye drops - may also be responsible for\n",
      "an acute exacerbation of asthma. Individuals with acetylsalicylic acid (ASA; aspirin)-sensitive\n",
      "asthma may have severe asthma after taking ASA or other non-steroidal anti-inflammatory drug (NSAID)\n",
      "that has cyclooxygenase (COX)-1 activity such as indometacin, ibuprofen, naproxen, piroxicam, and\n",
      "nabumetone. The mechanism probably relates to inhibition of formation of protective prostaglandins\n",
      "such as prostaglandin E (PGE). COX-2 inhibitors such as celecoxib are much less likely to cause\n",
      "reactions. NSAID reactions are most often described in individuals with non-allergic asthma who have\n",
      "nasal polyposis. Individuals with this type of asthma should avoid ASA and preferably all NSAIDs,\n",
      "although if absolutely necessary (exempli gratia a patient with severe rheumatoid arthritis and\n",
      "asthma), a supervised trial of a COX-2 inhibitor might be considered. It is important to be aware of\n",
      "other preventable causes of exacerbations such as occupational and sometimes unusual allergen\n",
      "exposures.\n",
      "\n",
      "ROUGE (366):\n",
      "Other causes of acute asthma include acute allergen exposure, when an allergic person is exposed to\n",
      "an allergen not usually encountered in the environment. Examples of this include 'thunderstorm\n",
      "asthma' in people who usually have allergic rhinitis due to grass pollens, or individuals with\n",
      "allergy to molds. Inhalation of small allergen particles into the lower respiratory tract can cause\n",
      "a severe asthma episode and weather patterns can lead to epidemics of asthma in such circumstances.\n",
      "Similarly, severe food allergies (exempli gratia to peanuts or shellfish) may trigger asthma. While\n",
      "individuals with such a food allergy often present with signs of anaphylaxis, acute asthma is a\n",
      "major component of a severe food reaction for some and it requires recognition and treatment in its\n",
      "own right. Some medications, such as beta-blockers - even in eye drops - may also be responsible for\n",
      "an acute exacerbation of asthma. Individuals with acetylsalicylic acid (ASA; aspirin)-sensitive\n",
      "asthma may have severe asthma after taking ASA or other non-steroidal anti-inflammatory drug (NSAID)\n",
      "that has cyclooxygenase (COX)-1 activity such as indometacin, ibuprofen, naproxen, piroxicam, and\n",
      "nabumetone. The mechanism probably relates to inhibition of formation of protective prostaglandins\n",
      "such as prostaglandin E (PGE). COX-2 inhibitors such as celecoxib are much less likely to cause\n",
      "reactions. NSAID reactions are most often described in individuals with non-allergic asthma who have\n",
      "nasal polyposis. Individuals with this type of asthma should avoid ASA and preferably all NSAIDs,\n",
      "although if absolutely necessary (exempli gratia a patient with severe rheumatoid arthritis and\n",
      "asthma), a supervised trial of a COX-2 inhibitor might be considered. It is important to be aware of\n",
      "other preventable causes of exacerbations such as occupational and sometimes unusual allergen\n",
      "exposures.\n",
      "\n",
      "####################################################################################################\n",
      "\n",
      "(9781912776238, 'ch1')\n",
      "\n",
      "Bullet:\n",
      "Biosimilars are highly similar, but not identical, to their reference (originator) biologic.\n",
      "\n",
      "W2V (117):\n",
      "The manufacturing process can affect important aspects of the structure of a biological drug; a\n",
      "copied biologic can never therefore be entirely identical to the original reference product. Thus,\n",
      "the active substance of a biosimilar and its reference medicine is almost the same biological\n",
      "substance, but there may be minor differences as a result of their complex nature and production\n",
      "methods. Like the reference (originator) biologic, the biosimilar has a degree of natural\n",
      "variability. For a biosimilar to be approved, this variability, and any differences between the\n",
      "biosimilar and the reference biologic, have to have been shown not to affect safety or\n",
      "effectiveness.\n",
      "\n",
      "D2V (117):\n",
      "The manufacturing process can affect important aspects of the structure of a biological drug; a\n",
      "copied biologic can never therefore be entirely identical to the original reference product. Thus,\n",
      "the active substance of a biosimilar and its reference medicine is almost the same biological\n",
      "substance, but there may be minor differences as a result of their complex nature and production\n",
      "methods. Like the reference (originator) biologic, the biosimilar has a degree of natural\n",
      "variability. For a biosimilar to be approved, this variability, and any differences between the\n",
      "biosimilar and the reference biologic, have to have been shown not to affect safety or\n",
      "effectiveness.\n",
      "\n",
      "Sentence-Transformers (117):\n",
      "The manufacturing process can affect important aspects of the structure of a biological drug; a\n",
      "copied biologic can never therefore be entirely identical to the original reference product. Thus,\n",
      "the active substance of a biosimilar and its reference medicine is almost the same biological\n",
      "substance, but there may be minor differences as a result of their complex nature and production\n",
      "methods. Like the reference (originator) biologic, the biosimilar has a degree of natural\n",
      "variability. For a biosimilar to be approved, this variability, and any differences between the\n",
      "biosimilar and the reference biologic, have to have been shown not to affect safety or\n",
      "effectiveness.\n",
      "\n",
      "ROUGE (117):\n",
      "The manufacturing process can affect important aspects of the structure of a biological drug; a\n",
      "copied biologic can never therefore be entirely identical to the original reference product. Thus,\n",
      "the active substance of a biosimilar and its reference medicine is almost the same biological\n",
      "substance, but there may be minor differences as a result of their complex nature and production\n",
      "methods. Like the reference (originator) biologic, the biosimilar has a degree of natural\n",
      "variability. For a biosimilar to be approved, this variability, and any differences between the\n",
      "biosimilar and the reference biologic, have to have been shown not to affect safety or\n",
      "effectiveness.\n",
      "\n",
      "####################################################################################################\n",
      "\n",
      "(9781908541406, 'ch_10')\n",
      "\n",
      "Bullet:\n",
      "FXI concentrates should be used with caution, because they predispose to arterial and venous\n",
      "thromboembolism. Fresh frozen plasma is often effective therapy, but exposure to normal FXI in\n",
      "plasma or concentrates carries a risk of inhibitor development in those with type 2 disease.\n",
      "\n",
      "W2V (275):\n",
      "For those with a partial deficiency it may be appropriate to undertake surgery with only careful\n",
      "attention to hemostasis and to use tranexamic acid for dental extractions. The FXI level may need to\n",
      "be raised in those with a severe deficiency who are undergoing major surgery. As the half-life of\n",
      "FXI is approximately 45 hours, therapeutic infusions of plasma or concentrate should be given daily\n",
      "or on alternate days. Virally inactivated fresh frozen plasma can be used but solvent/detergent-\n",
      "treated plasma has a lower FXI content and is therefore relatively ineffective. FXI concentrates can\n",
      "be used, but these have been associated with both arterial and venous thromboembolism. They are\n",
      "therefore contraindicated in individuals with clinical atherosclerosis and in patients whose\n",
      "hemostatic mechanisms are activated, such as pregnant women and those with liver disease.\n",
      "Concentrates should not normally be used in doses above 30 IU/kg and the plasma level of FXI should\n",
      "not exceed 50-70 IU/dL. Fibrinolytic inhibitors should never be given concomitantly with a FXI\n",
      "concentrate, because of their propensity to predispose to thrombosis and DIC. Patients with the type\n",
      "2 defect often develop inhibitory antibodies when exposed to normal FXI. Such antibodies may induce\n",
      "resistance to further treatment with FXI, in which case activated prothrombin complex concentrate or\n",
      "recombinant activated human FVIIa should be used to control bleeding.\n",
      "\n",
      "D2V (275):\n",
      "For those with a partial deficiency it may be appropriate to undertake surgery with only careful\n",
      "attention to hemostasis and to use tranexamic acid for dental extractions. The FXI level may need to\n",
      "be raised in those with a severe deficiency who are undergoing major surgery. As the half-life of\n",
      "FXI is approximately 45 hours, therapeutic infusions of plasma or concentrate should be given daily\n",
      "or on alternate days. Virally inactivated fresh frozen plasma can be used but solvent/detergent-\n",
      "treated plasma has a lower FXI content and is therefore relatively ineffective. FXI concentrates can\n",
      "be used, but these have been associated with both arterial and venous thromboembolism. They are\n",
      "therefore contraindicated in individuals with clinical atherosclerosis and in patients whose\n",
      "hemostatic mechanisms are activated, such as pregnant women and those with liver disease.\n",
      "Concentrates should not normally be used in doses above 30 IU/kg and the plasma level of FXI should\n",
      "not exceed 50-70 IU/dL. Fibrinolytic inhibitors should never be given concomitantly with a FXI\n",
      "concentrate, because of their propensity to predispose to thrombosis and DIC. Patients with the type\n",
      "2 defect often develop inhibitory antibodies when exposed to normal FXI. Such antibodies may induce\n",
      "resistance to further treatment with FXI, in which case activated prothrombin complex concentrate or\n",
      "recombinant activated human FVIIa should be used to control bleeding.\n",
      "\n",
      "Sentence-Transformers (275):\n",
      "For those with a partial deficiency it may be appropriate to undertake surgery with only careful\n",
      "attention to hemostasis and to use tranexamic acid for dental extractions. The FXI level may need to\n",
      "be raised in those with a severe deficiency who are undergoing major surgery. As the half-life of\n",
      "FXI is approximately 45 hours, therapeutic infusions of plasma or concentrate should be given daily\n",
      "or on alternate days. Virally inactivated fresh frozen plasma can be used but solvent/detergent-\n",
      "treated plasma has a lower FXI content and is therefore relatively ineffective. FXI concentrates can\n",
      "be used, but these have been associated with both arterial and venous thromboembolism. They are\n",
      "therefore contraindicated in individuals with clinical atherosclerosis and in patients whose\n",
      "hemostatic mechanisms are activated, such as pregnant women and those with liver disease.\n",
      "Concentrates should not normally be used in doses above 30 IU/kg and the plasma level of FXI should\n",
      "not exceed 50-70 IU/dL. Fibrinolytic inhibitors should never be given concomitantly with a FXI\n",
      "concentrate, because of their propensity to predispose to thrombosis and DIC. Patients with the type\n",
      "2 defect often develop inhibitory antibodies when exposed to normal FXI. Such antibodies may induce\n",
      "resistance to further treatment with FXI, in which case activated prothrombin complex concentrate or\n",
      "recombinant activated human FVIIa should be used to control bleeding.\n",
      "\n",
      "ROUGE (275):\n",
      "For those with a partial deficiency it may be appropriate to undertake surgery with only careful\n",
      "attention to hemostasis and to use tranexamic acid for dental extractions. The FXI level may need to\n",
      "be raised in those with a severe deficiency who are undergoing major surgery. As the half-life of\n",
      "FXI is approximately 45 hours, therapeutic infusions of plasma or concentrate should be given daily\n",
      "or on alternate days. Virally inactivated fresh frozen plasma can be used but solvent/detergent-\n",
      "treated plasma has a lower FXI content and is therefore relatively ineffective. FXI concentrates can\n",
      "be used, but these have been associated with both arterial and venous thromboembolism. They are\n",
      "therefore contraindicated in individuals with clinical atherosclerosis and in patients whose\n",
      "hemostatic mechanisms are activated, such as pregnant women and those with liver disease.\n",
      "Concentrates should not normally be used in doses above 30 IU/kg and the plasma level of FXI should\n",
      "not exceed 50-70 IU/dL. Fibrinolytic inhibitors should never be given concomitantly with a FXI\n",
      "concentrate, because of their propensity to predispose to thrombosis and DIC. Patients with the type\n",
      "2 defect often develop inhibitory antibodies when exposed to normal FXI. Such antibodies may induce\n",
      "resistance to further treatment with FXI, in which case activated prothrombin complex concentrate or\n",
      "recombinant activated human FVIIa should be used to control bleeding.\n",
      "\n",
      "####################################################################################################\n",
      "\n",
      "(9783318066241, 'ch3')\n",
      "\n",
      "Bullet:\n",
      "Abdominal imaging is useful for confirming the diagnosis of AP in atypical cases, ruling out other\n",
      "conditions.\n",
      "\n",
      "W2V (111):\n",
      "Most patients with AP have a severe epigastric pain radiating to the flanks and/or back, together\n",
      "with nausea and vomiting. Exceptions are patients under immunosuppression or sedation and patients\n",
      "with dementia, in whom the diagnosis may be challenging. Jaundice is frequently seen in cases of\n",
      "persistent choledocholithiasis, or more infrequently in patients with compression of the bile duct\n",
      "due to inflammation and/or collections (in these cases the jaundice usually develops days or weeks\n",
      "after presentation). Chills and high-grade fever associated with jaundice suggest acute cholangitis.\n",
      "\n",
      "D2V (80):\n",
      "Hypertriglyceridemia (> 500 mg/mL) may be associated with falsely low levels of amylase and lipase\n",
      "activity. This is likely to be due to interference with the assay and so, in patients with lipemic\n",
      "plasma and typical symptoms of AP but unexpectedly low levels of pancreatic enzyme activity, the\n",
      "plasma can be serially diluted and the enzymes measured again, or imaging should be performed.\n",
      "\n",
      "Sentence-Transformers (151):\n",
      "In the emergency room, a CT scan is the most useful imaging test for diagnosing AP, followed by MRI;\n",
      "conventional ultrasonography is less reliable. CT/MRI to confirm the diagnosis of AP should be\n",
      "reserved for cases with atypical symptoms and/or those rare cases without an increase in pancreatic\n",
      "enzyme serum levels. Contrast enhancement is useful for differential diagnosis (especially to rule\n",
      "out acute mesenteric ischemia) and to detect necrosis (although an early CT scan may be falsely\n",
      "negative for pancreatic necrosis); however, but in cases of kidney failure or allergy, a CT scan\n",
      "without contrast enhancement can detect peripancreatic fat stranding or peripancreatic collections\n",
      "typical of AP. AP may be present regardless of a normal CT scan, MRI or ultrasonography.\n",
      "\n",
      "ROUGE (151):\n",
      "In the emergency room, a CT scan is the most useful imaging test for diagnosing AP, followed by MRI;\n",
      "conventional ultrasonography is less reliable. CT/MRI to confirm the diagnosis of AP should be\n",
      "reserved for cases with atypical symptoms and/or those rare cases without an increase in pancreatic\n",
      "enzyme serum levels. Contrast enhancement is useful for differential diagnosis (especially to rule\n",
      "out acute mesenteric ischemia) and to detect necrosis (although an early CT scan may be falsely\n",
      "negative for pancreatic necrosis); however, but in cases of kidney failure or allergy, a CT scan\n",
      "without contrast enhancement can detect peripancreatic fat stranding or peripancreatic collections\n",
      "typical of AP. AP may be present regardless of a normal CT scan, MRI or ultrasonography.\n",
      "\n",
      "####################################################################################################\n",
      "\n"
     ]
    }
   ],
   "source": [
    "list_method = ['W2V', 'D2V', 'Sentence-Transformers', 'ROUGE']\n",
    "\n",
    "for bull in bullet_examples:\n",
    "    idx = df_w2v.loc[df_w2v.bullets == bull].index.tolist()[0]\n",
    "    \n",
    "    list_text = [df_w2v.loc[df_w2v.bullets == bull, 'text'].tolist()[0],\n",
    "        df_d2v.loc[df_d2v.bullets == bull, 'text'].tolist()[0],\n",
    "        df_st.loc[df_st.bullets == bull, 'text'].tolist()[0],\n",
    "        df_rouge.loc[df_rouge.bullets == bull, 'text'].tolist()[0]]\n",
    "    \n",
    "    list_text_num_tok = [df_w2v.loc[df_w2v.bullets == bull, 'para_num_tokens'].tolist()[0],\n",
    "        df_d2v.loc[df_d2v.bullets == bull, 'para_num_tokens'].tolist()[0],\n",
    "        df_st.loc[df_st.bullets == bull, 'para_num_tokens'].tolist()[0],\n",
    "        df_rouge.loc[df_rouge.bullets == bull, 'para_num_tokens'].tolist()[0]]\n",
    "    \n",
    "    nice_print(idx, bull, list_text, list_text_num_tok, list_method)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "P95DxvqWi_2Y",
    "mFAC31paODFl",
    "S0FByNNOIRvG",
    "tb7fAfzaK4es",
    "eQGq4WLu3Gei",
    "tSHT0mxuvkEp",
    "-eRnW74aH95b",
    "X2xp7jJNwB6b",
    "2Eb-_Ud3vxeY",
    "VndEUBoDjjkV",
    "8_li_hFKF_Ws"
   ],
   "name": "paragraph_assign_bullets.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S0FByNNOIRvG"
   },
   "source": [
    "### **Config**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 16184,
     "status": "ok",
     "timestamp": 1610463826089,
     "user": {
      "displayName": "Marco Pietro Abrate",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gjh-8YF-8BlnrkN9mLZ0xfVOWfOh7kYncpYRv-Y=s64",
      "userId": "15422244832836998434"
     },
     "user_tz": -60
    },
    "id": "ClE5D523OTZG"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "sys.path.insert(0, '/home/marco/epfl/magma/')\n",
    "import config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 16184,
     "status": "ok",
     "timestamp": 1610463826092,
     "user": {
      "displayName": "Marco Pietro Abrate",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gjh-8YF-8BlnrkN9mLZ0xfVOWfOh7kYncpYRv-Y=s64",
      "userId": "15422244832836998434"
     },
     "user_tz": -60
    },
    "id": "82WSp6khIcua"
   },
   "outputs": [],
   "source": [
    "MODEL = 'pegasus'\n",
    "\n",
    "RE_SPLITTER = '\\n'              # do we split sentences of paragraphs?\n",
    "                                # use '\\.(?!\\d)|\\n' or '\\n', respectively\n",
    "\n",
    "# Output path\n",
    "OUTPUT_PATH = config.MAGMA_DIR+'datasets/bullet_paragraph_rouge/'+MODEL+'/'\n",
    "if not os.path.exists(OUTPUT_PATH):\n",
    "    os.makedirs(OUTPUT_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tb7fAfzaK4es"
   },
   "source": [
    "### **Init**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 16443,
     "status": "ok",
     "timestamp": 1610463826354,
     "user": {
      "displayName": "Marco Pietro Abrate",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gjh-8YF-8BlnrkN9mLZ0xfVOWfOh7kYncpYRv-Y=s64",
      "userId": "15422244832836998434"
     },
     "user_tz": -60
    },
    "id": "wvbMlPBxk45S"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import re\n",
    "import pandas as pd\n",
    "import gensim\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "\n",
    "if 'pegasus' in MODEL:\n",
    "    from transformers import PegasusTokenizer\n",
    "    tokenizer =\\\n",
    "        PegasusTokenizer.from_pretrained('google/pegasus-large')\n",
    "elif 'bart' in MODEL:\n",
    "    from transformers import BartTokenizer\n",
    "    tokenizer =\\\n",
    "        BartTokenizer.from_pretrained('facebook/bart-large-cnn')\n",
    "elif 't5' in MODEL:\n",
    "    from transformers import T5Tokenizer\n",
    "    tokenizer=\\\n",
    "        T5Tokenizer.from_pretrained('t5-large')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "id": "eQGq4WLu3Gei"
   },
   "source": [
    "### **Karger Books Base Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "hidden": true,
    "id": "Z0lbkScg0a7j"
   },
   "outputs": [],
   "source": [
    "base_dataset = config.MAGMA_DIR+'datasets/karger_books_base/df.csv'\n",
    "df = pd.read_csv(base_dataset)\n",
    "df = df.set_index(['book', 'chapter', 'section', 'subsection'])\n",
    "df.bullets = df.bullets.map(eval, na_action='ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "id": "tSHT0mxuvkEp"
   },
   "source": [
    "### **Preprocessing**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true,
    "id": "-eRnW74aH95b"
   },
   "source": [
    "#### Preprocessing\n",
    "\n",
    "* Split based on RE_SPLITTER\n",
    "* Explode the dataset\n",
    "* Remove unwanted chars at beginning or end of sentence\n",
    "* Remove multiple spaces\n",
    "* Remove long words (> config.TOKEN_MAX_LEN chars)\n",
    "* Remove short sentences / paragraphs (< config.PARA_MIN_LEN tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "hidden": true,
    "id": "CDsT33j-wPCw"
   },
   "outputs": [],
   "source": [
    "# Split in sentences / paragraphs based on RE_SPLITTER\n",
    "df.text =\\\n",
    "    df.text.map(lambda x: [p.strip() for p in re.split(RE_SPLITTER, x) if p!=''],\n",
    "                na_action='ignore')\n",
    "    \n",
    "# explode to get one row for each paragraph /sentence\n",
    "df = df.explode('text')\n",
    "df = df.rename(columns={'text': 'para'})\n",
    "df = df.dropna()\n",
    "\n",
    "# Remove unwanted chars at beginning or end of sentence\n",
    "df.para = df.para.map(lambda p: p.lstrip('.,;:-)] \\n'))\n",
    "df.para = df.para.map(lambda p: p.rstrip('.,;:-([ \\n'))\n",
    "\n",
    "# Remove multiple spaces\n",
    "df.para = df.para.map(lambda p:\n",
    "    re.sub('\\s+', ' ', p).strip())\n",
    "\n",
    "# Remove long words (> config.TOKEN_MAX_LEN chars)\n",
    "def para2words(para):\n",
    "    return gensim.utils.simple_preprocess(\n",
    "        para, deacc=True, max_len=config.TOKEN_MAX_LEN)\n",
    "df['para_proc'] = df.para.map(para2words)\n",
    "\n",
    "# Remove short sentences / paragraphs (< config.PARA_MIN_LEN tokens)\n",
    "df.loc[df.para_proc.map(len) <\\\n",
    "    config.PARA_MIN_LEN, 'para_proc'] = np.nan\n",
    "\n",
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### **Assign Bullets to Best Para and Expand Functions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def assign_best_metric_para(df, col_metric):\n",
    "    df['best_match'] = False\n",
    "\n",
    "    for idx, para  in df.groupby('bullets').progress_apply(\n",
    "        lambda g: g.iloc[g[col_metric].argmax()]).para.iteritems():\n",
    "        \n",
    "        df.loc[\\\n",
    "            (df['bullets'] == idx) &\\\n",
    "            (df['para'] == para), 'best_match'] = True\n",
    "    \n",
    "    para_too_short =\\\n",
    "        df[(df['compression_ratio'] >= config.MAX_RATIO) & df['best_match']]\n",
    "    print('Percentage of paragraphs which are too short to be summarized: %.2f %%'\\\n",
    "        %(len(para_too_short)/len(df[df['best_match']])*100))\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def expand_up_down(df, col_metric):\n",
    "    # for each bullet\n",
    "    for bul in tqdm(set(df.bullets.tolist())):\n",
    "        df_bul = df[df['bullets'] == bul]\n",
    "        \n",
    "        # get book and chapter where this bullet is\n",
    "        book = df_bul.index.get_level_values(0)[0]\n",
    "        cpt = df_bul.index.get_level_values(1)[0]\n",
    "\n",
    "        df_bul = df_bul.reset_index()\n",
    "        # get best match index\n",
    "        best_match_idx = np.where(df_bul['best_match'])[0][0]\n",
    "        merged_para_idx = [best_match_idx]\n",
    "\n",
    "        bul_num_tok = df_bul.loc[best_match_idx, 'bullets_num_tokens']\n",
    "        merged_para_num_tok = df_bul.loc[best_match_idx, 'para_num_tokens']\n",
    "        comp_ratio = df_bul.loc[best_match_idx, 'compression_ratio']\n",
    "        num_bul_cpt = len(set(df.loc[book, cpt].bullets.tolist()))\n",
    "        max_idx = len(df_bul)-1\n",
    "        \n",
    "        while comp_ratio > config.MAX_RATIO and\\\n",
    "            merged_para_num_tok < tokenizer.model_max_length:\n",
    "            \n",
    "            # if we already merged all possible paragraphs\n",
    "            if (0 in merged_para_idx) and (max_idx in merged_para_idx):\n",
    "                break\n",
    "                \n",
    "            # if we already merged the first paragraph\n",
    "            elif 0 in merged_para_idx:\n",
    "                new_para_idx = max(merged_para_idx)+1\n",
    "                \n",
    "            # if we already merged the last paragraph\n",
    "            elif max_idx in merged_para_idx:\n",
    "                new_para_idx = min(merged_para_idx)-1\n",
    "                \n",
    "            # otherwise check for best metric inclusion\n",
    "            else:\n",
    "                if df_bul.loc[min(merged_para_idx)-1, col_metric] <\\\n",
    "                    df_bul.loc[max(merged_para_idx)+1, col_metric]:\n",
    "                    # merge down\n",
    "                    new_para_idx = max(merged_para_idx)+1\n",
    "                    \n",
    "                else: # merge up\n",
    "                    new_para_idx = min(merged_para_idx)-1       \n",
    "\n",
    "            df_bul.loc[new_para_idx, 'best_match'] = True\n",
    "            merged_para_idx.append(new_para_idx)\n",
    "            \n",
    "            merged_para_num_tok += df_bul.loc[new_para_idx, 'para_num_tokens']\n",
    "            comp_ratio = bul_num_tok / merged_para_num_tok\n",
    "\n",
    "        for p, b in zip(df_bul.loc[merged_para_idx]['para'].tolist(),\n",
    "            df_bul.loc[merged_para_idx]['bullets'].tolist()):\n",
    "            df.loc[(df['para'] == p) &\n",
    "                (df['bullets'] == b), 'best_match'] = True\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def print_stats(df):\n",
    "    num_para_tot = 18822\n",
    "    num_para_kept = np.sum(df.groupby('para')['best_match'].apply(np.any).tolist())\n",
    "    print('%d out of %d paragraphs are considered using this method.'%(num_para_kept, num_para_tot), end=' ')\n",
    "    print('Thus, %.2f %%'%(100*num_para_kept/num_para_tot))\n",
    "    \n",
    "    print()\n",
    "    df_count_tokens = df.groupby('para', sort=False).agg({\n",
    "        'best_match': lambda bm: np.any(list(bm)),\n",
    "        'para_num_tokens': lambda pnt: list(pnt)[0]})\n",
    "    num_tok_kept = df_count_tokens[df_count_tokens['best_match']].para_num_tokens.sum()\n",
    "    num_tok_tot = df_count_tokens.para_num_tokens.sum()\n",
    "\n",
    "    print('%d out of %d tokens are considered using this method.'%(num_tok_kept, num_tok_tot), end=' ')\n",
    "    print('Thus, %.2f %%'%(100*num_tok_kept/num_tok_tot))\n",
    "\n",
    "def print_stats_after_merge(df):\n",
    "    para_too_short = df[df['compression_ratio'] > config.MAX_RATIO]\n",
    "    print('Percentage of paragraphs which are too short to be summarized: %.2f %%'\\\n",
    "        %(len(para_too_short)/len(df)*100))\n",
    "    \n",
    "    print()\n",
    "    print('Paragraphs which are too long to fit into the model: %d paragraphs.'%\\\n",
    "          len(df[df['para_num_tokens'] > tokenizer.model_max_length]))\n",
    "    print(df[df['para_num_tokens'] > tokenizer.model_max_length])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "id": "X2xp7jJNwB6b"
   },
   "source": [
    "### **Prepare Paragraphs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "hidden": true,
    "id": "cK0T73OHSZoi"
   },
   "outputs": [],
   "source": [
    "df.para = df.para.map(lambda p: p+'.')\n",
    "df = df.drop(columns='para_proc')\n",
    "df = df.explode('bullets')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "hidden": true,
    "id": "CFone_j9_OuT"
   },
   "outputs": [],
   "source": [
    "df['para_num_tokens'] = df.para.map(lambda p: len(tokenizer.tokenize(p)))\n",
    "df['bullets_num_tokens'] = df.bullets.map(lambda b: len(tokenizer.tokenize(b)))\n",
    "\n",
    "df['compression_ratio'] = df.bullets_num_tokens / df.para_num_tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A7f4mPrku4vq"
   },
   "source": [
    "### **Evaluate ROUGE recall**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 411448,
     "status": "ok",
     "timestamp": 1610460590311,
     "user": {
      "displayName": "Marco Pietro Abrate",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gjh-8YF-8BlnrkN9mLZ0xfVOWfOh7kYncpYRv-Y=s64",
      "userId": "15422244832836998434"
     },
     "user_tz": -60
    },
    "id": "3jjv1V1FVoSW",
    "outputId": "63e21863-1579-4383-d6f7-2e20d3b16862"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 114574/114574 [06:33<00:00, 291.18it/s]\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_metric\n",
    "metric = load_metric(\"rouge\")\n",
    "\n",
    "rouge_res =\\\n",
    "    df[['para', 'bullets']]\\\n",
    "    .progress_apply(lambda row:\n",
    "    metric.compute(\n",
    "        predictions = [row[0]],\n",
    "        references = [row[1]],\n",
    "        rouge_types = config.ROUGE_TYPES,\n",
    "        use_agregator = False), axis=1)\n",
    "    \n",
    "for r in config.ROUGE_TYPES:\n",
    "    df[r+'_recall'] =\\\n",
    "        rouge_res.map(lambda score: score[r][0][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CCVlkVk2YttA"
   },
   "source": [
    "### **Assign Bullets to ONE Paragraph and Expand**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "FAt15ei4shOY"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2556/2556 [00:01<00:00, 1457.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of paragraphs which are too short to be summarized: 46.01 %\n"
     ]
    }
   ],
   "source": [
    "df_one_para = assign_best_metric_para(df, config.ROUGE_TYPE_RECALL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oEVi9s4JvxeJ"
   },
   "source": [
    "#### Expand: Merge Up or Down\n",
    "\n",
    "Take one chapter into consideration, one bullet at a time. For each bullet, one paragraph is already assigned. For paragraphs which are too short compared to the bullet, merge up or down based on rouge recall of previous / next paragraph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2556 [00:00<?, ?it/s]/home/marco/miniconda3/envs/magma/lib/python3.6/site-packages/ipykernel_launcher.py:18: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "100%|██████████| 2556/2556 [01:35<00:00, 26.64it/s]\n"
     ]
    }
   ],
   "source": [
    "df_one_para = expand_up_down(df_one_para, 'rougeL_recall')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3361,
     "status": "ok",
     "timestamp": 1610459902641,
     "user": {
      "displayName": "Marco Pietro Abrate",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gjh-8YF-8BlnrkN9mLZ0xfVOWfOh7kYncpYRv-Y=s64",
      "userId": "15422244832836998434"
     },
     "user_tz": -60
    },
    "id": "T6mMBqVA2Umm",
    "outputId": "0758bde6-06ba-4dae-9cca-a0722ab3966d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3720 out of 18822 paragraphs are considered using this method. Thus, 19.76 %\n",
      "\n",
      "347364 out of 1229874 tokens are considered using this method. Thus, 28.24 %\n"
     ]
    }
   ],
   "source": [
    "print_stats(df_one_para)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "RctLPHCymgfH"
   },
   "outputs": [],
   "source": [
    "df_one_para = df_one_para[df_one_para['best_match']].reset_index().groupby(['book', 'chapter', 'bullets'], sort=False).agg({\n",
    "    'para': lambda p: ' '.join(list(p)),\n",
    "    'para_num_tokens': sum,\n",
    "    'bullets_num_tokens': lambda bnt: list(bnt)[0]\n",
    "}).reset_index(level='bullets')\n",
    "df_one_para = df_one_para.rename(columns={'para': 'text'})\n",
    "\n",
    "df_one_para['compression_ratio'] = df_one_para.bullets_num_tokens / df_one_para.para_num_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 81
    },
    "executionInfo": {
     "elapsed": 516,
     "status": "ok",
     "timestamp": 1610460064479,
     "user": {
      "displayName": "Marco Pietro Abrate",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gjh-8YF-8BlnrkN9mLZ0xfVOWfOh7kYncpYRv-Y=s64",
      "userId": "15422244832836998434"
     },
     "user_tz": -60
    },
    "id": "W39OWoAw5v4q",
    "outputId": "f4c0f94d-4eac-41af-d413-96fb0324ad41"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>bullets</th>\n",
       "      <th>text</th>\n",
       "      <th>para_num_tokens</th>\n",
       "      <th>bullets_num_tokens</th>\n",
       "      <th>compression_ratio</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>book</th>\n",
       "      <th>chapter</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [bullets, text, para_num_tokens, bullets_num_tokens, compression_ratio]\n",
       "Index: []"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_one_para[df_one_para['compression_ratio'] > config.MAX_RATIO]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 386,
     "status": "ok",
     "timestamp": 1610460065605,
     "user": {
      "displayName": "Marco Pietro Abrate",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gjh-8YF-8BlnrkN9mLZ0xfVOWfOh7kYncpYRv-Y=s64",
      "userId": "15422244832836998434"
     },
     "user_tz": -60
    },
    "id": "eelD6EPwCu2L",
    "outputId": "aa4c47dc-d31a-4aae-a251-dda07d81f4d9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of paragraphs which are too short to be summarized: 0.00 %\n"
     ]
    }
   ],
   "source": [
    "para_too_short = df_one_para[df_one_para['compression_ratio'] > config.MAX_RATIO]\n",
    "print('Percentage of paragraphs which are too short to be summarized: %.2f %%'\\\n",
    "    %(len(para_too_short)/len(df_one_para)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1231,
     "status": "ok",
     "timestamp": 1610460067753,
     "user": {
      "displayName": "Marco Pietro Abrate",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gjh-8YF-8BlnrkN9mLZ0xfVOWfOh7kYncpYRv-Y=s64",
      "userId": "15422244832836998434"
     },
     "user_tz": -60
    },
    "id": "xAY7f8lL6Nby",
    "outputId": "1e314854-9fde-4451-c7d0-1c02a1601b18",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [bullets, text, para_num_tokens, bullets_num_tokens, compression_ratio]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "print(df_one_para[df_one_para['para_num_tokens'] > tokenizer.model_max_length])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2Eb-_Ud3vxeY"
   },
   "source": [
    "#### Save dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "PxHejePmvxeZ"
   },
   "outputs": [],
   "source": [
    "df_one_para.to_csv(OUTPUT_PATH+'df.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VndEUBoDjjkV"
   },
   "source": [
    "#### Create train, test, validation (CC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "PjL63EfJVa9s"
   },
   "outputs": [],
   "source": [
    "df_one_para = df_one_para.groupby(level=[0, 1], sort=False).agg({\n",
    "    'bullets': lambda b: list(b),\n",
    "    'text': lambda t: list(t),\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 946,
     "status": "ok",
     "timestamp": 1610360198918,
     "user": {
      "displayName": "Marco Pietro Abrate",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gjh-8YF-8BlnrkN9mLZ0xfVOWfOh7kYncpYRv-Y=s64",
      "userId": "15422244832836998434"
     },
     "user_tz": -60
    },
    "id": "Y1OtL194VouK",
    "outputId": "6b83bf6f-8bab-4633-b62d-08ce1c9bbdbe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "361 408\n"
     ]
    }
   ],
   "source": [
    "df_one_para = df_one_para.sample(frac=1, random_state=config.SEED)\n",
    "df_one_para['num_bulls'] = df_one_para.bullets.map(len).cumsum()\n",
    "tot_bulls = df_one_para.num_bulls.iloc[-1]\n",
    "split1 = np.where(df_one_para.num_bulls > int(tot_bulls*0.8))[0][0]+1\n",
    "split2 = np.where(df_one_para.num_bulls > int(tot_bulls*0.9))[0][0]+1\n",
    "print(split1, split2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "RVuRQ5y4mJmb"
   },
   "outputs": [],
   "source": [
    "train, val, test =\\\n",
    "    df_one_para.iloc[:split1].explode('bullets'),\\\n",
    "    df_one_para.iloc[split1:split2].explode('bullets'),\\\n",
    "    df_one_para.iloc[split2:].explode('bullets')\n",
    "\n",
    "train['text'] = df_one_para.iloc[:split1].explode('text')['text']\n",
    "val['text'] = df_one_para.iloc[split1:split2].explode('text')['text']\n",
    "test['text'] = df_one_para.iloc[split2:].explode('text')['text']\n",
    "\n",
    "train.to_csv(OUTPUT_PATH+'train.csv')\n",
    "val.to_csv(OUTPUT_PATH+'val.csv')\n",
    "test.to_csv(OUTPUT_PATH+'test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "UpURrGPHjjkV"
   },
   "outputs": [],
   "source": [
    "with open(OUTPUT_PATH+'train.source', 'w') as tr_s,\\\n",
    "    open(OUTPUT_PATH+'train.target', 'w') as tr_t,\\\n",
    "    open(OUTPUT_PATH+'train.index', 'w') as tr_i:\n",
    "    for idx, row in train[['text', 'bullets']].iterrows():\n",
    "        tr_i.write(str(idx) + '\\n')\n",
    "        tr_s.write(row.text + '\\n')\n",
    "        tr_t.write(row.bullets + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "TrDrO4UOpvui"
   },
   "outputs": [],
   "source": [
    "with open(OUTPUT_PATH+'val.source', 'w') as va_s,\\\n",
    "    open(OUTPUT_PATH+'val.target', 'w') as va_t,\\\n",
    "    open(OUTPUT_PATH+'val.index', 'w') as va_i:\n",
    "    for idx, row in val[['text', 'bullets']].iterrows():\n",
    "        va_i.write(str(idx) + '\\n')\n",
    "        va_s.write(row.text + '\\n')\n",
    "        va_t.write(row.bullets + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "2qLdJ3vJp5MX"
   },
   "outputs": [],
   "source": [
    "with open(OUTPUT_PATH+'test.source', 'w') as te_s,\\\n",
    "    open(OUTPUT_PATH+'test.target', 'w') as te_t,\\\n",
    "    open(OUTPUT_PATH+'test.index', 'w') as te_i:\n",
    "    for idx, row in test[['text', 'bullets']].iterrows():\n",
    "        te_i.write(str(idx) + '\\n')\n",
    "        te_s.write(row.text + '\\n')\n",
    "        te_t.write(row.bullets + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mFacPjA4IIq3"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "P95DxvqWi_2Y",
    "mFAC31paODFl",
    "S0FByNNOIRvG",
    "tb7fAfzaK4es",
    "eQGq4WLu3Gei",
    "tSHT0mxuvkEp",
    "-eRnW74aH95b",
    "X2xp7jJNwB6b",
    "2Eb-_Ud3vxeY",
    "VndEUBoDjjkV",
    "8_li_hFKF_Ws"
   ],
   "name": "paragraph_assign_bullets.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

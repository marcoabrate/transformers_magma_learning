The immune system has evolved to protect the host against infectious agents such as bacteria, viruses and fungi, and to detect and eliminate potentially harmful foreign material. A hallmark of cancer is that tumor cells - which would normally be recognized by the immune system as abnormal - acquire the ability to evade the immune system. Immuno-oncology is a new, multi-faceted and rapidly evolving collection of treatment strategies aimed at harnessing immune processes to target and destroy tumor cells and prolong survival. An understanding of the basic elements of the normal and tumor-altered immune system is therefore key to understanding potential immuno-oncology therapies. The immune system consists of two components: innate immunity and adaptive immunity. Innate immunity is conferred by mechanisms that are present throughout life, such as the physical barriers to infection provided by the skin and mucous membranes, white blood cells that remove foreign material, and serum proteins such as lysozymes and kinins. Adaptive (acquired) immunity is conferred by the formation of antibodies following exposure to foreign material (antigens), and is specific to the particular antigen.
In addition to the physical barrier of skin and membranes, innate immunity is primarily conferred by phagocytic cells derived from stem cells in the bone marrow. The most important of these include macrophages, monocytes and neutrophils, although other cell types, such as natural killer (NK) cells, also play important roles (Table 1.1). Phagocytosis. Phagocytes are attracted to foreign material, such as a pathogen, and engulf it in a process known as phagocytosis. The foreign material is then contained inside an endosome, and digested by enzymes and acids contained in organelles known as lysosomes.
T reg cells mainly regulate and suppress the immune response of naive and effector T cells through a variety of cytokine and signaling mechanisms, including transforming growth factor (TGF)-beta and IL-10. T reg cells regulate the immune response to common environmental allergens and prevent the development of atopy or undesirable inflammation. However, their role in maintenance of peripheral tolerance is also used by cancers to evade the immune system. CD8+ cytotoxic T cells (also known as killer T cells) are activated by antigens from intracellular pathogens presented on MHC class I molecules. Activation of these cells triggers a process known as clonal selection, during which the T cells proliferate to produce a population of effector T cells (Teff). These cells recognize cells with a unique MHC class I-antigen complex, and release enzymes and toxins that lyse the cell membrane and induce programmed cell death (apoptosis). To prevent extensive tissue damage during an infection, activation of CD8+ cells requires three signals (Figure 1.4). binding of the antigen to the TCR. binding of the MHC class I or II molecules to accessory CD8 or CD4 molecules, respectively, on the T cell. co-regulatory (co-stimulatory and co-inhibitory) signals resulting from binding of CD80 (B7-1) and CD28 on the APC and T cell: binding of CD80 (B7-1) on the APC to T cell CD28 leads to a positive signal, causing the T cell to kill cells bearing the relevant antigen, whereas binding of CD80 (B7-1) on the APC to CTLA-4 (cytotoxic T-lymphocyte-associated protein 4) on the T cell results in a negative signal, preventing the T cell from killing antigen-bearing cells. Humoral immunity involves the production in B cells of antibodies (immunoglobulins) against specific antigens. In contrast to T cells, where the antigen is processed intracellularly before being expressed on the cell surface in association with MHC molecules, B cells recognize the native, unprocessed, form of the antigen. The B cell receptor (BCR) consists of an antibody that recognizes a specific antigen. Upon activation by binding of the antigen to the BCR, B cells differentiate into short-lived antibody-producing cells (plasma cells) (Figure 1.5). The antibodies bind to the antigen, rendering it more susceptible to phagocytosis and triggering the complement system. Once the antigen has been cleared, the plasma cells are eliminated via programmed cell death (apoptosis). However, approximately 10% of activated B cells differentiate into long-lived antigen-specific memory B cells (see Figure 1.5); this allows a rapid immune response to be mounted in the event of re-exposure to the antigen.
Humoral immunity involves the production in B cells of antibodies (immunoglobulins) against specific antigens. In contrast to T cells, where the antigen is processed intracellularly before being expressed on the cell surface in association with MHC molecules, B cells recognize the native, unprocessed, form of the antigen.
Immune tolerance is a state in which the immune system is unresponsive to a stimulus that would normally provoke an immune response. It is an important mechanism by which tumor cells evade the immune system. Immune tolerance may be central or peripheral, depending on where it is induced. central tolerance is induced in the thymus and bone marrow. peripheral tolerance is induced in lymph nodes or other tissues. Central tolerance is the principal mechanism by which the immune system learns to distinguish between 'self' and 'non-self'. Maturing T and B lymphocytes in the thymus and bone marrow, respectively, are presented with self-antigens; cells bearing receptors for these antigens are removed by apoptosis or by induction of an inactive state known as anergy. Some autoreactive B cells may be retained in a state in which they do not respond to stimulation of their receptors. Conversely, some weakly autoreactive T cells may differentiate into natural regulatory T cells (nT reg), which act in the periphery to diminish potential T cell autoreactivity (see below).
Central tolerance is the principal mechanism by which the immune system learns to distinguish between 'self' and 'non-self'. Maturing T and B lymphocytes in the thymus and bone marrow, respectively, are presented with self-antigens; cells bearing receptors for these antigens are removed by apoptosis or by induction of an inactive state known as anergy. Some autoreactive B cells may be retained in a state in which they do not respond to stimulation of their receptors. Conversely, some weakly autoreactive T cells may differentiate into natural regulatory T cells (nT reg), which act in the periphery to diminish potential T cell autoreactivity (see below). Peripheral tolerance plays a key role in preventing hyperreactivity of the immune system in response to environmental agents such as allergens or gut microbes. A number of mechanisms contribute to peripheral tolerance, primarily involving regulation of T-cell populations, particularly CD4+ T h cells.
Paul Kabuubi MBChB MRCP FRCR and Merina Ahmed BSc MBBS MRCP FRCR MD(Res), The Royal Marsden NHS Foundation Trust, London, UK. Radiotherapy has a role in the management of most patients with non-small-cell lung cancer (NSCLC). While it can be used as sole treatment, it is often integrated in a multimodal strategy with surgery and chemotherapy. Overall, treatment options vary according to the stage of the tumor (see Chapter 3) but also depend on the individual patient's lung function, volume of disease and performance status. Patient selection. To be eligible for radical radiotherapy, patients must have adequate lung function (forced expiratory volume in 1 second [FEV ] >= 1 liter or >= 40% predicted; transfer factor >= 40%), good performance status (Eastern Cooperative Oncology Group [ECOG] score 0-1) and disease that can be encompassed in a radiotherapy treatment volume without undue risk of damaging normal tissue. Patients with interstitial lung disease are rarely suitable. Patients with poor lung function may still be eligible provided they have been adequately counseled about the long-term risks of breathlessness. Unsuitable candidates for radical radiotherapy should be offered other palliative options.
To be eligible for radical radiotherapy, patients must have adequate lung function (forced expiratory volume in 1 second [FEV ] >= 1 liter or >= 40% predicted; transfer factor >= 40%), good performance status (Eastern Cooperative Oncology Group [ECOG] score 0-1) and disease that can be encompassed in a radiotherapy treatment volume without undue risk of damaging normal tissue. Patients with interstitial lung disease are rarely suitable. Patients with poor lung function may still be eligible provided they have been adequately counseled about the long-term risks of breathlessness. Unsuitable candidates for radical radiotherapy should be offered other palliative options.
Stereotactic body radiotherapy (SBRT) or stereotactic ablative radiotherapy is the delivery of an extremely high dose of radiotherapy to a small target using hypofractionation. The fraction sizes are typically greater than 8 Gy per fraction. It is used for the treatment of stage I disease, and more recently for the treatment of oligometastatic disease. Methods of delivery are shown in Table 4.2. Image-guided radiotherapy (IGRT) refers to the use of imaging to reduce the uncertainty of tumor position during treatment.
Stereotactic body radiotherapy (SBRT) or stereotactic ablative radiotherapy is the delivery of an extremely high dose of radiotherapy to a small target using hypofractionation. The fraction sizes are typically greater than 8 Gy per fraction. It is used for the treatment of stage I disease, and more recently for the treatment of oligometastatic disease. Methods of delivery are shown in Table 4.2. Image-guided radiotherapy (IGRT) refers to the use of imaging to reduce the uncertainty of tumor position during treatment. It has been estimated that a dose greater than 84 Gy is needed to provide 50% tumor control at 3 years. A meta-analysis in stage I patients has confirmed equivalent survival to surgery at 2 years. Local failures occur in less than 10% of patients but these failure rates can increase as tumor volume increases, with T2 disease or as the dose falls.
Radiotherapy provides effective palliation of symptomatic advanced intrathoracic disease and metastases. Three randomized trials conducted by the UK's Medical Research Council (MRC) have assessed fractionation for palliation of intrathoracic symptoms. - Even when a single fraction is used, radiotherapy can produce complete resolution of symptoms in around 50% of cases. When considering palliation of cough, chest pain and hemoptysis in those with moderate or poor performance status, 17 Gy in 2 fractions is equivalent to longer schedules (exempli gratia 30 Gy in 10 or 27 Gy in 6 fractions) with no difference in survival. One of the MRC trials established that 10 Gy in 1 fraction was equally effective as the 2-fraction schedule with substantially less dysphagia and no risk to the spinal cord.
Nicotine hunger. A second likely mechanism is the development of a kind of 'nicotine hunger'. Repeated intake of nicotine from cigarettes over a period of months or years changes the way that the pathway described above operates, so that if nicotine concentrations in the brain fall below a certain level, the activity in the pathway falls to abnormally low levels; this creates a kind of 'acquired drive', a hunger for nicotine, that is often experienced as craving. Like hunger for food, at low levels this feeling does not reach consciousness until something reminds us of its presence. At higher levels it is persistent and insistent, trying in some sense to motivate the smoker to do something to relieve it. It is a need. Withdrawal symptoms. A third mechanism involves learning that smoking a cigarette helps to alleviate feelings of anxiety, depression, irritability, restlessness, and difficulty concentrating. These are all withdrawal symptoms resulting from physiological adaptation to repeated nicotine intake. Thus, nicotine does not alleviate these problems in people who do not smoke. Unfortunately, such discomfort can occur for all kinds of reasons, and the smoker's brain is not good at discriminating adverse mood states that arise from nicotine withdrawal from those arising from other causes. This means that smokers learn to associate adverse mood states and difficulty concentrating with smoking, and come to believe that smoking helps them to cope, even though it does so only because they are experiencing the problem because they have not smoked for a while. Unfortunately, as long as they believe that smoking helps to relieve adverse mood and other symptoms, smokers will be at risk of relapse when they try to stop.
Withdrawal symptoms. A third mechanism involves learning that smoking a cigarette helps to alleviate feelings of anxiety, depression, irritability, restlessness, and difficulty concentrating. These are all withdrawal symptoms resulting from physiological adaptation to repeated nicotine intake. Thus, nicotine does not alleviate these problems in people who do not smoke. Unfortunately, such discomfort can occur for all kinds of reasons, and the smoker's brain is not good at discriminating adverse mood states that arise from nicotine withdrawal from those arising from other causes. This means that smokers learn to associate adverse mood states and difficulty concentrating with smoking, and come to believe that smoking helps them to cope, even though it does so only because they are experiencing the problem because they have not smoked for a while. Unfortunately, as long as they believe that smoking helps to relieve adverse mood and other symptoms, smokers will be at risk of relapse when they try to stop.
The sum of motivations. Putting all this together, we can see that there are probably at least three ways in which repeated ultra-rapid intake of nicotine from cigarettes creates powerful motivations to smoke, which undermine and overwhelm the resolve not to. Different smokers probably experience each of these three elements of nicotine dependence to differing degrees. Thus, some smokers clearly have a strong nicotine hunger and smoke as soon as they wake up in the morning and whenever the opportunity arises during the day. Others may not need to smoke for much of the day but experience powerful urges to smoke in particular situations, such as when socializing; this is particularly true of non-daily smokers. For some smokers the nicotine withdrawal syndrome is relatively mild, while others experience severe adverse mood states when not smoking.
Combining time to first cigarette of the day and number of cigarettes smoked provides what is known as the Heaviness of Smoking Index (HSI), which is probably the measure of choice for very quickly assessing cigarette addiction (Table 5.1). The diagnosis can also be made based on clinical evidence. If a patient has tried to stop smoking and failed because the urge to smoke is too strong, the need for a cigarette is overwhelming, or the withdrawal symptoms are too much to bear, that patient is addicted to cigarettes. Equally, if a patient has never tried to stop smoking because the prospect of going without cigarettes is too much to contemplate, even though he or she is concerned about the damage that smoking is doing to his or her health, that patient is addicted.
Parkinson's disease is one of the most common neurodegenerative diseases, but estimating its incidence and prevalence is problematic as there is no 'in-life' marker for idiopathic Parkinson's disease; the diagnosis can only be made with certainty if Lewy bodies (intracytoplasmic aggregations of misfolded protein in the brain) are found in the substantia nigra and other brain regions after death (see pages 19 -). Case ascertainment in community studies is difficult, and often other parkinsonian syndromes may be included.
Age, sex and ethnicity. Both the incidence and prevalence of Parkinson's disease increase with age, and the prevalence may be as high as 1 in 50 for patients over the age of 80 years. The disease is estimated to affect 1% of 70-year-olds, but is also seen in younger people, with 10% of cases occurring before the age of 50.
Age, sex and ethnicity. Both the incidence and prevalence of Parkinson's disease increase with age, and the prevalence may be as high as 1 in 50 for patients over the age of 80 years. The disease is estimated to affect 1% of 70-year-olds, but is also seen in younger people, with 10% of cases occurring before the age of 50. Men are 1.5 times more likely than women to develop the condition.
The confusion regarding mortality in Parkinson's disease may be partly because the disease itself is not a primary or direct cause of death. In the USA, the average annual age-adjusted Parkinson's disease mortality between 1962 and 1984 was estimated as 2 deaths per 100 000 for white men and 1 death per 100 000 for non-white men, 1 death per 100 000 for white women and less than 1 death per 100 000 for non-white women. Mortality increased for persons aged 75 years and older, but declined for those younger than 70 years. Overall, published evidence suggests that mortality for Parkinson's disease increases in the older age groups but decreases for younger ages. The cause of death in Parkinson's disease is most commonly a secondary comorbid disorder. A Japanese study showed that the most common cause of death for all patients, regardless of age, was pneumonia. Economic burden. Studies suggest that Parkinson's disease adversely affects the health-related quality of life of patients and imposes a significant economic burden on society comparable with that of other chronic conditions such as congestive heart failure, diabetes and stroke. Although it is difficult to measure the specific economic cost of Parkinson's disease, in the UK the annual direct cost of managing patients with Parkinson's disease at home is estimated at around £4189; the cost rises to £19 338 for full-time institutionalization. Furthermore, the total direct cost of Parkinson's disease in patients in 'good health' is three times lower than for those in 'poor health'. These figures do not take into account hidden indirect costs such as loss of income from premature retirement, for both the patient and carer. The main pathological feature of Parkinson's disease is the degeneration of neuromelanin-containing neurons in the pars compacta of the substantia nigra (Figure 2.1). Examination with the naked eye reveals pallor of this area, which is confirmed microscopically by a marked decrease in the number of neuromelanin-containing cells and the presence of Lewy bodies in the remaining nigral neurons.
After examining a large number of brains, both clinically normal and with Parkinson's disease, Braak et al. suggested that stage 1 of the disease begins at induction sites in the olfactory system and the dorsal vagal nucleus, with degeneration of the olfactory bulb and the anterior olfactory nucleus. This presents clinically as olfactory dysfunction. Stage 2 reflects progression of the pathological process to the nuclei of the caudal brainstem (the locus ceruleus and other nuclei). The lower brainstem nuclei are key areas mediating a myriad of non-motor symptoms such as sleep homeostasis, depression, fatigue, cognitive problems, pain, constipation and a reduction in central autonomic vagal control. Several of these symptoms are now recognized as possible prodromal features of Parkinson's disease. However, clinical Parkinson's disease tends to be recognized by healthcare professionals only when the condition reaches stage 3, which involves the substantia nigra. Stages 4 to 6 represent further pathological progression to the cortex (Figure 2.3).
Neuronal degeneration. The cause of neuronal degeneration in Parkinson's disease is unknown. The susceptible neurons are located in astroglial-poor regions such as the ventral tier. Glia may offer neuroprotection by providing neurotrophic factors that prevent cell death. Several hypotheses for neuronal degeneration have been proposed, including.
Latest thinking. It is now widely believed that the clinical symptoms of Parkinson's disease are not only due to the loss of a single monoamine neurotransmitter, dopamine, but also the effects of widespread Lewy body disease. This results in a convergence of deficits in multiple transmitter pathways, including the cholinergic, noradrenergic and serotonergic systems, which underpin many of the non-motor symptoms that are integral to Parkinson's disease (Figure 2.7). In addition, glial pathology, neuroimmune responses and proinflammatory cytokines are likely to play a key pathogenic role. Non-motor symptoms that become evident in the prodromal phase of the disease, such as late-onset hyposmia, RBD, constipation and depression, are all risk factors for Parkinson's disease. Forebrain cholinergic system dysfunction is present in non-demented Parkinson's disease and worsens with dementia.
However, the SNCA and PARK3 mutations have not been found in many families with autosomal-dominant Parkinson's disease or sporadic Parkinson's disease. Other mutations are being discovered elsewhere (see Table 2.2); mutation in PARK7 is linked to autosomal-recessive early-onset Parkinson's disease, and was identified in a Dutch and an Italian family, while leucine-rich repeat kinase (LRRK2; also known as PARK8), with a locus on chromosome 12, was identified in a Japanese family (see below). Autosomal-recessive juvenile parkinsonism has been studied mainly in Japan. The gene associated with juvenile parkinsonism, PARK2, has been mapped to chromosome 6q. The same genetic mutation has been found in European families in individuals with juvenile or young-onset Parkinson's disease. PARK2 has a 30% homology with the gene that encodes ubiquitin, and is expressed in various regions of the brain (including the substantia nigra) and in liver, heart, testis and skeletal muscle. PARK2 encodes parkinson protein 2, E3 ubiquitin protein ligase (parkin), which is involved in protein degradation. The PARK2 mutation appears to lead to defective protein ubiquination, leading to protein aggregation and cell death. Recent findings in the genetics of Parkinson's disease include the identification of mutations in LRRK2, which is involved in mitochondrial functioning, the powerhouse of cells. LRRK2 is part of the Roco family of genes. Mutation in LRRK2 has been associated with familial late-onset Parkinson's disease and a few cases of sporadic late-onset Parkinson's disease. The phenotype appears to be identical to sporadic Parkinson's disease, but is associated with behavioral disorders, leg tremor, sleep disturbances and slight cognitive decline. One case of an Ile1371Val substitution in LRRK2 has been reported, with the typical Lewy body pathology that stained positive for ubiquitin and alpha-synuclein and symptoms identical to idiopathic sporadic Parkinson's disease. The most common LRRK2 substitution is Gly2019Ser, which accounts for 2% of sporadic and 5% of familial cases. This substitution is identified more frequently in North African Arabs and Ashkenazi Jews, while a Gly2385Arg mutation has been described in the Chinese/Taiwanese population.
At the normal neuromuscular junction (NMJ), acetylcholine (ACh) is released from the motor neuron terminal, diffuses across the synaptic space and binds to ACh receptors (AChR), which are densely clustered on the folded endplate membrane of the muscle fiber. The high concentration of AChRs is crucial for efficient neuromuscular transmission. The ACh depolarizes the muscle endplate region, ultimately causing the muscle to contract (Figure 2.1). Myasthenia gravis (MG) is the best characterized autoimmune disorder of the nervous system. The immune-mediated nature of MG was suspected as early as the 1960s when it was speculated to be caused by a dysregulated immune response, with antibodies directed against skeletal muscle. Acetylcholine receptor antibodies. A series of animal and human experiments in the 1970s confirmed the above hypothesis, and elevated titers of antibodies against the acetylcholine receptor (AChR) were ultimately discovered in the serum of patients with MG. Loss of AChRs results in impaired neuromuscular transmission and muscle weakness.
Complement-mediated lysis is thought to be the most important mode of loss of AChR, but the actual process that initiates the aberrant immune attack on the AChR is unknown. Both the immunoglobulin (Ig) G antibody and complement have been localized to the motor endplate in myasthenia models, indicating that circulating IgG antibodies directed against the AChR bind to the postsynaptic membrane and activate the terminal complement sequence (C5b-9), or membrane attack complex (MAC). This results in lysis of the postsynaptic membrane, causing loss of the AChR (Figure 2.2). In fact, elevated MAC levels have been demonstrated in the plasma of patients with MG. 'Binding' antibodies are the most common type found in patients with MG. Accelerated internalization and degradation of acetylcholine receptors. A key mechanism of disease pathology in MG is the modulation, internalization and eventual destruction of AChRs at the NMJ by the crosslinking of AChR-specific autoantibodies (Figure 2.3). This process is known as antigenic modulation.
Antibodies to AChR. As noted above, MG is most often caused by antibodies to the AChR. This is the case for 85% of cases of generalized disease and approximately 50% of cases of purely ocular MG. Antibodies to AChR may be of the binding, blocking or modulating type, with binding being the most common. AChR antibodies are highly specific for the diagnosis of MG, although the degree of elevation in titers has never been found to correlate with the severity of disease. Antibody titers may decline with immunosuppressive treatment within an individual, although the reliability of determining treatment effect is less robust. Antibodies to muscle receptor tyrosine kinase (MuSK) occur in about 7% of cases of generalized MG but are rarely reported in isolated ocular disease. MuSK-antibody-positive MG is a distinct clinical subset of the disease, almost always seen in adults, more frequently in women, and never in conjunction with thymic disease. There is predominant involvement of the bulbar muscles, often with concurrent neck and respiratory muscle weakness. Ocular and limb muscle weakness is less common than in AChR-antibody-related disease but is certainly seen in this population. Most patients can actually worsen on treatment with acetylcholinesterase inhibitors such as pyridostigmine.
Antibodies to muscle receptor tyrosine kinase (MuSK) occur in about 7% of cases of generalized MG but are rarely reported in isolated ocular disease. MuSK-antibody-positive MG is a distinct clinical subset of the disease, almost always seen in adults, more frequently in women, and never in conjunction with thymic disease. There is predominant involvement of the bulbar muscles, often with concurrent neck and respiratory muscle weakness. Ocular and limb muscle weakness is less common than in AChR-antibody-related disease but is certainly seen in this population. Most patients can actually worsen on treatment with acetylcholinesterase inhibitors such as pyridostigmine.
When assessing gliomas, it must be borne in mind that some tumors with the molecular profile of a glioblastoma (see below) may not have all high-grade features. It is increasingly apparent that diffuse infiltrating gliomas may not have high-grade features when diagnosed early. Likewise, the histone H3.3 K27M-mutant gliomas may not have any histological high-grade features but are defined as WHO grade IV. This is why a multidisciplinary approach is so important for the optimal diagnosis of patients with glioblastoma - the molecular analysis ensures a more robust classification.
Epigenetic changes. Many high-grade gliomas can be classified by a selection of the markers described above. However, some remain unclassifiable because of a lack of distinctive mutation patterns. Thus, a method has been developed that looks at epigenetic changes caused by a combination of mutations and the cell of origin. These epigenetic changes are identified from methylation patterns (which are a result of driver mutations), using a publicly accessible algorithm (www.molecularneuropathology.org). This method is widely used in the diagnosis of brain tumors with unusual or ambiguous histology and when conventional molecular testing is not diagnostically informative. A diagnostically useful copy number profile is also generated, which elucidates chromosomal changes and gene amplifications or losses (see Figure 1.3).
The typical post-contrast appearance of glioblastoma on MRI is that of a (usually large) nodular rim-enhancing mass surrounding a central necrotic core. However, the diagnosis of glioblastoma can be complex, as any type of enhancement pattern can occur, including solid-patchy enhancement, thin rim enhancement resembling a cyst or, indeed, a total lack of enhancement (Figure 3.2). Because the early stages of primary glioblastoma are frequently non-enhancing, radiological descriptions of non-enhancing gliomas as 'low grade' can be misleading and are best avoided given that the WHO 2016 classification is now based on an integrated diagnosis.
As mentioned in previous chapters, the location of the tumor can support the diagnosis, as it indicates the likelihood of certain genotypes. For example, multifocality is thought to be more common in IDH wild-type gliomas than IDH -mutant low-grade gliomas. Given the propensity of glioblastoma for rapid spread along white matter tracts, it is often considered to be a multifocal disease, even though this is not consistently visible on imaging. Distant metastases, however, are virtually non-existent, so staging can be achieved from brain imaging only. Although spinal dissemination of glioblastoma is uncommon, if spinal drop metastases are suspected (exempli gratia on discovery of intracranial leptomeningeal disease), post-gadolinium spine imaging from the skull base to the sacrum (id est along the entire vertebral canal) should be considered as part of the diagnostic work-up.
Distinguishing glioblastoma from other diseases is often, but not always, straightforward (Figure 3.3). Anatomic MRI is essential for the diagnosis of glioblastoma, but it has limited sensitivity and specificity for the characterization of morphologically atypical lesions; for example, CNS lymphoma with central necrosis or with solitary metastases. In these cases, body imaging is usually requested before brain biopsy. Perfusion imaging techniques. The recommendations for performing advanced imaging techniques are less prescriptive than anatomic MRI, as there is a lack of high-level evidence for many of the more complex modalities. However, to improve the identification of malignant gliomas, recent European guidance recommends the addition of perfusion imaging for newly diagnosed non-gadolinium-enhancing masses. Perfusion MRI aims to identify neovascularization in brain tumors by analyzing (contrast-enhanced) blood flow through a volume of tissue over time. Several perfusion methods exist (Table 3.1).
Lower ADC values have been shown to correlate with higher glioma grades, corresponding to an increase in proliferative indices. Numerous studies have observed lower ADC values in IDH wild-type gliomas than IDH -mutant WHO grade II/III gliomas, specifically IDH -mutant 1p19q intact astrocytomas, which may show markedly increased ADC values ('facilitated diffusion'). To a limited extent, ADC measurements may also be valuable for differential diagnosis; for example, primary central nervous system lymphoma typically has lower ADC values than glioblastoma, but results can overlap for individual tumors. Other diffusion techniques. It remains unclear whether more elaborate diffusion techniques (exempli gratia diffusion kurtosis imaging, and multiexponential and compartmental diffusion models) could offer a diagnostic advantage over standard DWI for radiomic predictions.
Symptoms and signs of pancreatic cancer are shown in Table 11.2. In the case of tumors of the head of the pancreas, painless obstructive jaundice (jaundice with dark urine and pale stools) commonly occurs but the presentation is usually insidious. Weight loss, nausea, vomiting, and abdominal and back pain can also be suggestive of pancreatic head cancer, although they are more frequently encountered in body and tail tumors. As a result of the location, symptoms appear earlier in the head of the pancreas, while the evolution is often insidious until late stages in body and tail lesions. Pancreatic cancer should be suspected in any patient (over 40 years of age) with unresolving epigastric symptoms.
Contrast-enhanced computed tomography is the examination of choice for diagnosis and staging for resectability, provided that dedicated pancreatic protocols and latest state-of-the-art multidetector scanners are used (Figure 11.2). Enlargement of lymph nodes per se is a poor prognostic indicator. Portal or splenic venous involvement has become less relevant for surgical resection, while arterial encasement or involvement of the celiac artery and/or superior mesenteric artery is a very important factor in determining resectability. Although dynamic contrast-enhanced CT has less accuracy than endoscopic ultrasonography (EUS) for detecting small tumors (less than 2 cm), for staging purposes CT is still recommended. CT may be supplemented by EUS, MRI and laparoscopy.
Contrast-enhanced computed tomography is the examination of choice for diagnosis and staging for resectability, provided that dedicated pancreatic protocols and latest state-of-the-art multidetector scanners are used (Figure 11.2). Enlargement of lymph nodes per se is a poor prognostic indicator. Portal or splenic venous involvement has become less relevant for surgical resection, while arterial encasement or involvement of the celiac artery and/or superior mesenteric artery is a very important factor in determining resectability. Although dynamic contrast-enhanced CT has less accuracy than endoscopic ultrasonography (EUS) for detecting small tumors (less than 2 cm), for staging purposes CT is still recommended. CT may be supplemented by EUS, MRI and laparoscopy.
Positron-emission tomography (PET) is not routinely used in the diagnosis and staging of pancreatic cancer. However, PET in combination with CT or MRI may play an important role in the future for the staging of pancreatic cancer and patient stratification. Tissue diagnosis may be obtained by brushings during ERCP or fine needle aspirations (FNA) obtained percutaneously or by EUS. However, EUS-guided FNA is the preferred method for tissue diagnosis and has a higher accuracy than ERCP with brush cytology. Preoperative tissue diagnosis may not always be needed in a resectable pancreatic mass if the symptoms, signs, laboratory data and imaging are classic for pancreatic cancer in an otherwise surgically fit patient. However, when a preoperative tissue diagnosis is required in a potentially resectable pancreatic mass, EUS-guided FNA should be the preferred route on account of the lower potential risk of peritoneal seeding, the shorter needle tract and the inclusion of the needle track in the resection specimen (in pancreatic head tumors). Tissue diagnosis may be needed in borderline resectable pancreatic tumors if the patient is to undergo preoperative neoadjuvant chemotherapy or chemoradiation therapy before surgery.
Tissue diagnosis may be obtained by brushings during ERCP or fine needle aspirations (FNA) obtained percutaneously or by EUS. However, EUS-guided FNA is the preferred method for tissue diagnosis and has a higher accuracy than ERCP with brush cytology. Preoperative tissue diagnosis may not always be needed in a resectable pancreatic mass if the symptoms, signs, laboratory data and imaging are classic for pancreatic cancer in an otherwise surgically fit patient. However, when a preoperative tissue diagnosis is required in a potentially resectable pancreatic mass, EUS-guided FNA should be the preferred route on account of the lower potential risk of peritoneal seeding, the shorter needle tract and the inclusion of the needle track in the resection specimen (in pancreatic head tumors). Tissue diagnosis may be needed in borderline resectable pancreatic tumors if the patient is to undergo preoperative neoadjuvant chemotherapy or chemoradiation therapy before surgery.
The majority of patients present with advanced disease and have an overall median survival of less than 6 months, and a 5-year survival rate of up to 5%. Up to 10-20% of patients undergo pancreatic resection, with an overall median survival of 11-20 months, and a 5-year survival rate of 7-25%; virtually all patients die within 7 years of surgery. According to published guidelines, all patients with pancreatic cancer must be treated in a specialist high-volume center by a multidisciplinary team (Figure 11.5). Once the diagnosis is made or strongly suspected, the next objective is to stage the disease. If the tumor is resectable and there are no metastases then resection should be undertaken. If resection is not possible then non-surgical treatment should be undertaken.
Because of past harms associated with research involving human participants, there is an expectation and, in many cases, a regulatory requirement that an ethics committee review will take place in advance of the research commencing. In research supported by the US Department of Health and Human Services (HHS) or under US Food and Drug Administration (FDA) oversight, this is carried out by an institutional review board (IRB) registered with the federal Office for Human Research Protections (OHRP). These regulations were initiated in 1974 as part of the National Research Act. The involvement of an IRB in behavioral and biomedical research is common globally, though often by other names, such as a research ethics board (REB) or 'research ethics committee'. An IRB can be a part of the organization conducting the research (id est medical center or university) or operate as an independent fee-for-service entity. In the US, an IRB is required to have a minimum of five people, including scientists, non-scientists and someone who is unaffiliated with the organization. This membership convention has been adopted globally for organizations conducting FDA-regulated research under the International Council for Harmonisation of Technical Requirements for Pharmaceuticals for Human Use (ICH) Good Clinical Practice guidelines. ,3.
The IRB is responsible for reviewing research that involves human participants to evaluate compliance with federal regulations and application of ethical principles. This review includes evaluating the probability and magnitude of potential harms to research participants and weighing these risks against the potential benefits of knowledge to be gained. The IRB also reviews the proposed research to make sure that participants selected to participate represent those most likely to benefit from its results. Moreover, the IRB wants to make sure that people who are invited to participate in research have a good understanding of the study purpose and what they will be asked to do. This process of sharing study information with a prospective participant is called informed consent and is a central tenet of biomedical research. Federal regulations and accepted ethical principles are in place to guide the conduct of research so that the science is rigorous and the participants are protected. In any research, an important step is to determine if people involved in the testing phase are considered to be human participants in the research. The federal regulations include definitions for what qualifies as 'research' and 'human subject' and address the responsibilities of the organization and research team.
IRB application. Once the type of review is known, an IRB application is developed by the research team that includes a detailed research protocol and a draft of the informed consent document. The protocol will briefly describe the scientific literature that the study is building from, as well as the study aims, procedures, participant inclusion criteria, risks, benefits, risk management, data management, investigator qualifications and informed consent details. The IRB will review this protocol application to evaluate whether the risks are appropriate in relation to the potential contribution to science and benefits to people like those who participate in the study. Application of ethical principles. Researchers have applied these principles and relied on IRBs to help shape ethical research practices for nearly half a century. However, as digital products are increasingly used in health research and clinical care, all relevant stakeholders have a collective responsibility to think proactively about how to conduct digital health research ethically and responsibly. While IRB approval is an important step in the process for identifying and mitigating risk in studies, it is truly the responsibility of developers, researchers and clinicians to be a part of the ethical decision-making process. Simply stated, we cannot outsource ethics and hope for the best.
Of course, these regulations and ethical principles are sometimes difficult to put into practice. Because the use of digital methods is relatively new, accessing resources at the protocol development phase is important. Over the past few years, several initiatives have begun to address the ethical, legal and social implications (ELSI) of emerging technologies. A few focus specifically on artificial intelligence (AI) broadly (exempli gratia autonomous vehicles, facial recognition, city planning, future of work). AI initiatives presently underway (exempli gratia AI Now, A-100) are well-funded and global collaborative programs. Others addressing digital medicine technologies more specifically include the Connected and Open Research Ethics (CORE) initiative, MobileELSI research project, Sage Bionetworks and the Clinical Trials Transformation Initiative (CTTI), which are described in the following paragraphs.
The takeaway message here is that ToS and end user license agreements (EULAs) are not a substitute for informed consent. People want the right to opt-in to being involved in biomedical research, and that is a clear call for respecting the ethical principle of 'respect for persons'. Yet, when we are doing work that is technically not research, what is our ethical obligation? In software development, the way user data have been treated has an emerging history of malfeasance. This practice likely results from the lack of universally agreed guidelines and standards. We strongly recommend the adoption of ethical principles to guide responsible practice when guidelines are lacking.
In response to the lack of guidelines and exploitation of consumer data, new regulations have emerged that speak to consent and privacy concerns. The General Data Protection Regulations (GDPR) were passed by the European Parliament in 2016 and took effect in April 2018. The GDPR were designed to harmonize European Union (EU) privacy laws, protect EU citizens' data privacy and change how organizations, regardless of where they are located, process and manage EU citizen data. An important change that the GDPR introduced was the need for companies to obtain explicit informed consent separate from a ToS or EULA. This shift from consumers being helpless data subjects to empowered actors in the digital data economy is moving to the US. In 2018, California passed the California Consumer Privacy Act (CCPA) which, when implemented in 2020, gives consumers control over their data and requires that companies like Facebook and Google explain what data they collect, what they do with the data, and who the data are shared with.
Patients with glioblastoma should be cared for by a multidisciplinary team that includes a neurosurgeon, neuropathologist, neuroradiologist, medical and radiation oncologists, and possibly a neurologist, together with allied health professionals such as physiotherapists, occupational therapists and social workers. Involvement of a supportive care team including specialist nursing care is also mandatory in the palliative setting.
Surgery is the initial therapeutic approach for tumor debulking and to obtain tissue for diagnosis. The aim of surgery is maximum tumor resection while maintaining neurological function. Risk versus benefit. The neurosurgeon's preoperative assessment of the patient's prognosis - which will depend, among other things, on the location of the glioblastoma and the patient's performance status - will determine the extent of resection. For example, if the tumor is near or involves eloquent (exempli gratia language, motor, vision) areas of the brain, a subtotal resection or tissue biopsy only may be considered a more appropriate option than aggressive total resection. The consequences of surgically acquired neurological deficits (exempli gratia language, cognitive, motor, coordination and visual deficits) can be significant. If surgical resection is not safe because of the tumor location or impaired performance status, a biopsy should be obtained if feasible.
Risk versus benefit. The neurosurgeon's preoperative assessment of the patient's prognosis - which will depend, among other things, on the location of the glioblastoma and the patient's performance status - will determine the extent of resection. For example, if the tumor is near or involves eloquent (exempli gratia language, motor, vision) areas of the brain, a subtotal resection or tissue biopsy only may be considered a more appropriate option than aggressive total resection. The consequences of surgically acquired neurological deficits (exempli gratia language, cognitive, motor, coordination and visual deficits) can be significant. If surgical resection is not safe because of the tumor location or impaired performance status, a biopsy should be obtained if feasible. Surgical planning. MRI helps to estimate the operability of tumors and facilitates surgical planning. High-resolution 3D volumetric imaging sequences can help to assess tumor resectability and the optimal operative trajectory. Anatomic MRI can be integrated into surgical navigation software, where appropriate, together with functional and tractography sequences.
Chemotherapy. Temozolomide is an imidazotetrazine-derived alkylating agent that is 100% bioavailable when taken orally, reaching peak plasma concentrations within 1 hour. Because of its small size and lipophilic properties, it can cross the blood-brain barrier. Temozolomide is administered orally at 75 mg/m daily during radiotherapy. After a duration of approximately 1 month, this is followed by six cycles of adjuvant temozolomide at 150-200 mg/m on days 1-5 of every 28-day cycle. Temozolomide acts by preventing DNA replication through alkyl group-mediated crosslinking of DNA. Clinical data. The standard of care described above is based on the results of the 2005 European Organisation for Research and Treatment of Cancer (EORTC) 26981-22981/National Cancer Institute of Canada (NCIC) Clinical Trials Group CE3 randomized Phase III trial of radiotherapy with concomitant and adjuvant temozolomide versus radiotherapy alone in 573 patients with glioblastoma. In this trial, median OS was 14.6 months with radiotherapy plus temozolomide, and 12.1 months with radiotherapy alone. The unadjusted hazard ratio (HR) for death in the radiotherapy/temozolomide group was 0.63 (95% CI 0.52-0.75, p < 0.001). In patients whose tumors contained a methylated MGMT promoter (see page 18), median OS was significantly longer with temozolomide and radiotherapy than with radiotherapy alone (21.7 [95% CI 17.4-30.4] versus 15.3 [13.0-20.9] months; p > 0.007). The survival benefit in patients who received adjuvant temozolomide with radiotherapy continued to the 5-year follow-up, including in patients aged 60-70 years.
Clinical data. The standard of care described above is based on the results of the 2005 European Organisation for Research and Treatment of Cancer (EORTC) 26981-22981/National Cancer Institute of Canada (NCIC) Clinical Trials Group CE3 randomized Phase III trial of radiotherapy with concomitant and adjuvant temozolomide versus radiotherapy alone in 573 patients with glioblastoma. In this trial, median OS was 14.6 months with radiotherapy plus temozolomide, and 12.1 months with radiotherapy alone. The unadjusted hazard ratio (HR) for death in the radiotherapy/temozolomide group was 0.63 (95% CI 0.52-0.75, p < 0.001). In patients whose tumors contained a methylated MGMT promoter (see page 18), median OS was significantly longer with temozolomide and radiotherapy than with radiotherapy alone (21.7 [95% CI 17.4-30.4] versus 15.3 [13.0-20.9] months; p > 0.007). The survival benefit in patients who received adjuvant temozolomide with radiotherapy continued to the 5-year follow-up, including in patients aged 60-70 years.
MGMT methylation status. In 2019, Hegi and colleagues reported a study that examined the optimal cut-off for definition of MGMT methylation based on four randomized trials involving 1725 patients with newly diagnosed glioblastoma who received standard radiotherapy and temozolomide. A cut-off of greater than 1.27 was identified as high MGMT methylation that would render a tumor more sensitive to temozolomide. The cut-off for 'truly unmethylated' tumors was -0.28 or lower; approximately 10% of tumors were in the 'gray zone' (< −0.28, <= 1.27). The authors concluded that low MGMT methylation status within the 'gray zone' may confer some sensitivity to temozolomide therapy and recommended that the lower safety margin should be used to select patients with unmethylated tumors for inclusion in trials that do not include temozolomide. At present, clinicians form their own opinions as to how to apply this in clinical practice. Other prognostic factors associated with improved survival in patients with glioblastoma receiving radiotherapy with concomitant and adjuvant temozolomide are younger age, better performance status, Mini-Mental State Examination score of 27 or higher and no steroid treatment at baseline.
Serial magnetic resonance imaging is the preferred method of response assessment and long-term monitoring after surgery and/or adjuvant therapy. MRI scans are commonly performed every 3-4 months unless the clinical status of the patient (exempli gratia deteriorating symptoms) dictates more frequent monitoring. Conversely, some clinicians may wait several months longer to image (well patients) to minimize any confusion with the transient worsening associated with pseudoprogression or radiation necrosis or, indeed, the misleading improvement of a pseudoresponse to therapy. This process of imaging is fraught with complexity. Many technical parameters such as scanner hardware, multiple software settings, patient positioning, contrast dose and timing all may influence lesion conspicuity over time. Serial tumor measurements can vary according to scan angle and slice selection. For this reason, the technical parameters of serial MRI scans should be kept as constant as practicable to avoid missing or overestimating tumor changes over time. Volumetric (3D) imaging can be useful in support of serial tumor measurements, as this provides image reconstructions in all planes.
This process of imaging is fraught with complexity. Many technical parameters such as scanner hardware, multiple software settings, patient positioning, contrast dose and timing all may influence lesion conspicuity over time. Serial tumor measurements can vary according to scan angle and slice selection. For this reason, the technical parameters of serial MRI scans should be kept as constant as practicable to avoid missing or overestimating tumor changes over time. Volumetric (3D) imaging can be useful in support of serial tumor measurements, as this provides image reconstructions in all planes. Glioblastoma recurrence versus therapy effects. A problematic issue is the overlap that exists between structural and advanced imaging features of viable tumor and necrotic tissue. On conventional MRI sequences, the early (pseudoprogression; Figure 4.2) and late (radiation necrosis) effects of adjuvant therapy are often indistinguishable from a growing tumor, as both may appear as new or enlarging enhancing lesions due to breakdown of the blood-brain barrier. The true incidence of therapy effects is debatable, as it depends on the definition of a progressive lesion. This complexity is acknowledged in the Response Assessment in Neuro-Oncology (RANO) criteria, which take into consideration the timing of adjuvant therapy for glioblastoma serial monitoring. To date, the challenge of distinguishing between glioblastoma recurrence and therapy effects has not been completely resolved, not least because the two may coexist. However, several advanced imaging techniques are valuable in this context. Perfusion MRI can help to identify neovascular (viable) tumor (Figure 4.3), but difficulty may arise from intermediate values, and short-interval monitoring may be necessary unless a histological diagnosis is pursued.
Tumor recurrence after initial standard of care therapy is virtually inevitable. A standard of care has not been established for glioblastoma that progresses after chemotherapy. For patients who meet the inclusion criteria and are considered fit enough for further treatment, enrolment into clinical trials is recommended. Surgery may be considered, particularly if the tumor exerts a mass effect. Radiotherapy. Repeat radiotherapy may be considered for recurrent small tumors, although there is a lack of prospective comparative trials. The evidence supporting use of stereotactic radiotherapy in the recurrent setting is minimal. A Phase I multicenter dose-escalation study in 15 patients with recurrent glioblastoma or anaplastic astrocytoma showed that re-irradiation using hypofractionated stereotactic radiotherapy with concomitant bevacizumab (see below) was feasible and reasonably well tolerated; dose escalation up to 11 Gy x 3 was possible. Median OS was 13 months in the intent-to-treat population.
Management of glioblastoma in older patients (>= 65 years) can be challenging, given the poor prognosis, the likelihood of comorbidities and an increased risk of toxicity from radiotherapy on the aging brain. A recent trial in older patients (>= 65 years; n > 562) with newly diagnosed glioblastoma compared radiotherapy (40 Gy in 15 fractions) alone and with concomitant and adjuvant temozolomide (75 mg/m daily for 21 days, followed by 150-200 mg/m on days 1-5 of each 28-day cycle for up to 12 cycles or until disease progression). The addition of temozolomide to radiotherapy increased median OS from 7.6 to 9.3 months (HR for death 0.67 [95% CI 0.56-0.8]; p < 0.001), without compromising quality of life and with manageable chemotherapy-related side effects. Subgroup analysis showed that the benefit of chemoradiotherapy was particularly evident in patients with methylated MGMT status. Thus, combination therapy should be considered for fit elderly patients with glioblastoma.
Current therapy of osteoarthritis (OA) largely aims to treat existing disease by controlling its major symptom - pain - and maintain or improve joint and limb function and improve quality of life. While there are numerous therapies targeted against symptoms, at present no treatments have been definitively shown to modify the structural progression of OA. Currently, the best advice we can give on preventing OA relates to the following lifestyle modifications. avoid joint trauma. avoid high-impact loading of joints (through sport or occupation).
A healthy diet is important to aid weight control, but no diets or dietary supplements have been shown to prevent, or to modify the progression of, OA. Management of OA. There are many evidence-based guidelines from a variety of specialty societies for managing OA (see Key references, page 72). These guidelines agree on several main principles for the treatment of the disease. People with OA should be involved in their own management, and should receive education about their condition and the range and safety of treatment options available. Optimum treatment involves a combination of non-pharmacological and pharmacological approaches.
People with OA should be involved in their own management, and should receive education about their condition and the range and safety of treatment options available. Optimum treatment involves a combination of non-pharmacological and pharmacological approaches. Therapies, particularly pharmacological ones, need to be tailored according to an individual person's comorbidities and risk factors. Exercise and weight management should be recommended to all patients.
Management of myeloproliferative neoplasm blast phase. Most myeloproliferative neoplasms (MPNs) are chronic conditions that remain clinically stable for many years; however, the condition may progress to acute leukemia in a minority of patients, referred to as MPN blast phase (MPN-BP). This transformation most commonly occurs in patients with myelofibrosis, in whom transformation rates of 15-30% have been reported, compared with 1-4% for patients with essential thrombocythemia (ET) and 4-9% for those with polycythemia vera (PV)., Typically, patients with ET or PV initially develop post-ET or post-PV myelofibrosis, which may subsequently undergo transformation to MPN-BP, although in rare cases these conditions may transform directly into MPN-BP without an intermediate myelofibrotic stage., Risk factors for the development of MPN-BP include leukocytosis, thrombocytopenia and unfavorable karyotype (Table 9.1). There are no specific diagnostic criteria for MPN-BP. The principal criterion is the same as for de novo acute myeloid leukemia (AML): more than 20% blasts in bone marrow or peripheral blood. Persistence is also important if only peripheral blood blasts are considered. Importantly, acceleration or progression of myelofibrosis is usually apparent before the development of overt leukemia. Signs of this include. worsening cytopenia or anemia. worsening of constitutional symptoms. progressive and resistant splenomegaly. increasing numbers of blasts in bone marrow and peripheral blood. rising lactate dehydrogenase. new cytogenetic or molecular marker. In addition, recent evidence suggests that progression during treatment with Janus kinase inhibitors is associated with a risk of MPN-BP.
Most myeloproliferative neoplasms (MPNs) are chronic conditions that remain clinically stable for many years; however, the condition may progress to acute leukemia in a minority of patients, referred to as MPN blast phase (MPN-BP). This transformation most commonly occurs in patients with myelofibrosis, in whom transformation rates of 15-30% have been reported, compared with 1-4% for patients with essential thrombocythemia (ET) and 4-9% for those with polycythemia vera (PV)., Typically, patients with ET or PV initially develop post-ET or post-PV myelofibrosis, which may subsequently undergo transformation to MPN-BP, although in rare cases these conditions may transform directly into MPN-BP without an intermediate myelofibrotic stage., Risk factors for the development of MPN-BP include leukocytosis, thrombocytopenia and unfavorable karyotype (Table 9.1).
There are no specific diagnostic criteria for MPN-BP. The principal criterion is the same as for de novo acute myeloid leukemia (AML): more than 20% blasts in bone marrow or peripheral blood. Persistence is also important if only peripheral blood blasts are considered. Importantly, acceleration or progression of myelofibrosis is usually apparent before the development of overt leukemia. Signs of this include.
MPN-BP is associated with a poor prognosis: median survival is 2-6 months, although this may be prolonged by intensive treatment and prompt recourse to stem cell transplantation (SCT). There is no standard of care for MPN-BP, and many of the current treatment regimens (Table 9.2) are derived from experience in AML. Induction chemotherapy and SCT. In general, MPN-BP should only be treated with induction chemotherapy when allogeneic SCT is planned in eligible patients. The induction chemotherapy regimens are the same as those used in AML, and response rates are similar to those seen in poor-risk AML patients: typically, complete response (CR) and CR with incomplete count recovery (CRi) rates are 40-50%, although rates of approximately 70% have been reported with a combination of cytosine arabinoside and anthracycline., , However, these responses are not durable, having a median duration of approximately 5 months. Eligible patients should therefore undergo SCT as soon as possible. The importance of this is highlighted by a study in which median overall survival in patients who completed allogeneic SCT following CR/CRi with induction chemotherapy was 47 months, compared with 9.4 months in those who achieved a CR/CRi but did not go on to SCT. Two-year overall survival rates were 47% and 17%, respectively.
MPN-BP is associated with a poor prognosis: median survival is 2-6 months, although this may be prolonged by intensive treatment and prompt recourse to stem cell transplantation (SCT). There is no standard of care for MPN-BP, and many of the current treatment regimens (Table 9.2) are derived from experience in AML. Induction chemotherapy and SCT. In general, MPN-BP should only be treated with induction chemotherapy when allogeneic SCT is planned in eligible patients. The induction chemotherapy regimens are the same as those used in AML, and response rates are similar to those seen in poor-risk AML patients: typically, complete response (CR) and CR with incomplete count recovery (CRi) rates are 40-50%, although rates of approximately 70% have been reported with a combination of cytosine arabinoside and anthracycline., , However, these responses are not durable, having a median duration of approximately 5 months. Eligible patients should therefore undergo SCT as soon as possible. The importance of this is highlighted by a study in which median overall survival in patients who completed allogeneic SCT following CR/CRi with induction chemotherapy was 47 months, compared with 9.4 months in those who achieved a CR/CRi but did not go on to SCT. Two-year overall survival rates were 47% and 17%, respectively.
Achieving a CR is essential for successful SCT. In one study, 8 of 13 patients proceeded to SCT after induction chemotherapy and were followed for a median of 20 months. All five who achieved CR had returned to chronic MPN at the time of SCT but remained in remission, whereas 2 of 3 patients with persistent marrow or circulating blasts died. There is growing interest in post-transplant immunomodulation with donor lymphocyte infusion or drugs such as hypomethylating agents. Less-intensive chemotherapy. Patients with MPN-BP who are not eligible for induction chemotherapy or SCT may benefit from treatment with hypomethylating agents. In one study involving 54 patients with MPN-BP or a condition suggestive of myelodysplastic syndrome, treatment with azacitidine resulted in an overall response rate (CR + CRi + partial response) of 28% after a median of 20 months' follow-up, and median overall survival was 8 months in the MPN-BP group. However, support for this approach currently comes mainly from small case series.
Although there is a trend towards earlier detection of prostate cancer, many men worldwide still present with widespread metastatic disease. In countries where prostate-specific antigen (PSA) testing is not widely used, about 30% of patients present with localized disease, 40% with locally advanced disease and the remaining 30% with metastases. In contrast to localized or locally advanced disease, metastatic prostate cancer is associated with high mortality - approximately 70% within 5 years. Androgen deprivation, which has become the mainstay of treatment, effectively reduces the intratumoral dihydrotestosterone (DHT) concentration by 70-80%, reducing stimulation of androgen receptors and increasing apoptosis of prostate cancer cells (Table 7.1). Androgen deprivation can be achieved by orchidectomy (surgical removal of the testes) or treatment with luteinizing hormone-releasing hormone (LHRH) analogs/antagonists; the value of adding an antiandrogen (maximal androgen blockade; see page 90) is still debated.
Although there is a trend towards earlier detection of prostate cancer, many men worldwide still present with widespread metastatic disease. In countries where prostate-specific antigen (PSA) testing is not widely used, about 30% of patients present with localized disease, 40% with locally advanced disease and the remaining 30% with metastases. In contrast to localized or locally advanced disease, metastatic prostate cancer is associated with high mortality - approximately 70% within 5 years. Androgen deprivation, which has become the mainstay of treatment, effectively reduces the intratumoral dihydrotestosterone (DHT) concentration by 70-80%, reducing stimulation of androgen receptors and increasing apoptosis of prostate cancer cells (Table 7.1). Androgen deprivation can be achieved by orchidectomy (surgical removal of the testes) or treatment with luteinizing hormone-releasing hormone (LHRH) analogs/antagonists; the value of adding an antiandrogen (maximal androgen blockade; see page 90) is still debated.
Although there is a trend towards earlier detection of prostate cancer, many men worldwide still present with widespread metastatic disease. In countries where prostate-specific antigen (PSA) testing is not widely used, about 30% of patients present with localized disease, 40% with locally advanced disease and the remaining 30% with metastases. In contrast to localized or locally advanced disease, metastatic prostate cancer is associated with high mortality - approximately 70% within 5 years. Androgen deprivation, which has become the mainstay of treatment, effectively reduces the intratumoral dihydrotestosterone (DHT) concentration by 70-80%, reducing stimulation of androgen receptors and increasing apoptosis of prostate cancer cells (Table 7.1). Androgen deprivation can be achieved by orchidectomy (surgical removal of the testes) or treatment with luteinizing hormone-releasing hormone (LHRH) analogs/antagonists; the value of adding an antiandrogen (maximal androgen blockade; see page 90) is still debated.
Although there is a trend towards earlier detection of prostate cancer, many men worldwide still present with widespread metastatic disease. In countries where prostate-specific antigen (PSA) testing is not widely used, about 30% of patients present with localized disease, 40% with locally advanced disease and the remaining 30% with metastases. In contrast to localized or locally advanced disease, metastatic prostate cancer is associated with high mortality - approximately 70% within 5 years. Androgen deprivation, which has become the mainstay of treatment, effectively reduces the intratumoral dihydrotestosterone (DHT) concentration by 70-80%, reducing stimulation of androgen receptors and increasing apoptosis of prostate cancer cells (Table 7.1). Androgen deprivation can be achieved by orchidectomy (surgical removal of the testes) or treatment with luteinizing hormone-releasing hormone (LHRH) analogs/antagonists; the value of adding an antiandrogen (maximal androgen blockade; see page 90) is still debated.
Bilateral orchidectomy or bilateral subcapsular orchidectomy is performed through a midline scrotal incision (Figure 7.1) under local, regional or light general anesthesia. The procedure is simple and is associated with little morbidity. The principal adverse events are local complications such as hematoma and wound infections, together with the usual effects of androgen deprivation such as loss of libido, erectile dysfunction and hot flashes (Table 7.2). Clinical responses (decreased bone pain and reduced PSA concentration) are obtained in more than 75% of patients. Because of the psychological/cosmetic impact of orchidectomy and its irreversibility, however, most patients and their partners prefer non-surgical treatment with LHRH analogs/antagonists.
Although both orchidectomy and LHRH treatment produce dramatic initial responses in 70-80% of men, remission is not usually maintained in the long term. Androgen-independent cancer cell clones are selected out, and the mean time to tumor progression is less than 18 months and mean overall survival (OS) is 28-36 months. Persistent adrenal androgen secretion may contribute to this poor prognosis; there is evidence that adrenal androgens account for up to 15-20% of total androgen concentrations within the prostate. This has led to the concept of 'maximal androgen blockade', in which androgen deprivation by orchidectomy or LHRH treatment is accompanied by treatment with an antiandrogen to block the effects of adrenal androgens in the prostate.
The appropriate timing of hormonal therapy has been the subject of vigorous debate and the evidence now favors earlier therapy rather than waiting for symptoms. This evidence includes a re-analysis of the cooperative studies (USA) in which men receiving diethylstilbestrol (DES), 1 mg, had a survival advantage. The Medical Research Council (UK) study showed that men with locally advanced or metastatic disease treated with castration at diagnosis had better outcomes than those in whom therapy was deferred (Table 7.3), and a US trial reported by Messing et al. in 2006 found that delayed hormonal treatment in men with pelvic lymph node metastases was associated with a sevenfold increase in deaths from prostate cancer compared with those who had immediate androgen ablation therapy. A study that explored the timing of androgen deprivation therapy (ADT) in men who experienced a rising PSA after primary treatment of prostate cancer reported a 45% decrease in OS in those who delayed therapy (by >= 2 years) compared with those who had immediate treatment.
Conventional antiemetics are more successful at preventing emesis than nausea. Current data from multiple large studies suggest that neither first- nor second-generation 5-hydroxytryptamine-3 (5-HT) receptor antagonists (RAs) are effective in the control of nausea in patients receiving either moderately or highly emetogenic chemotherapy (MEC or HEC, respectively), despite marked improvement in the control of emesis. - Multiple large phase III trials have also shown that although the neurokinin (NK)-1 RA aprepitant is effective for the control of emesis, it is not effective in controling nausea in patients receiving MEC or HEC. Similarly, phase III clinical trial data indicate that the new neurokinin (NK)-1 RAs netupitant and rolapitant are not effective antinausea agents,, although rolapitant may have some effect in patients receiving cisplatin HEC. These studies suggest that the serotonin (5-HT) and substance P (NK-1) receptors may not be important in the mediation of nausea, despite their important role in chemotherapy-induced emesis (see page 11). - New studies using novel agents and using nausea as the primary endpoint need to be performed.
These studies suggest that the serotonin (5-HT) and substance P (NK-1) receptors may not be important in the mediation of nausea, despite their important role in chemotherapy-induced emesis (see page 11). - New studies using novel agents and using nausea as the primary endpoint need to be performed. Olanzapine appears to have high potential for the control of both emesis and nausea in patients receiving MEC or HEC (Table 6.1). Phase III studies suggest that olanzapine may be an important agent in the control of chemotherapy-induced nausea. - Olanzapine is known to affect a wide variety of receptors including dopamine D, 5-HT 2C, histaminic and muscarinic receptors. At present, there is still a substantial lack of understanding of the pathogenesis of chemotherapy-induced nausea, and any or all of these receptors may be important mediators.
Olanzapine appears to have high potential for the control of both emesis and nausea in patients receiving MEC or HEC (Table 6.1). Phase III studies suggest that olanzapine may be an important agent in the control of chemotherapy-induced nausea. - Olanzapine is known to affect a wide variety of receptors including dopamine D, 5-HT 2C, histaminic and muscarinic receptors. At present, there is still a substantial lack of understanding of the pathogenesis of chemotherapy-induced nausea, and any or all of these receptors may be important mediators. The addition of olanzapine to the 5-HT RA azasetron and dexamethasone has been shown to improve nausea and emesis compared with azasetron and dexamethasone alone in patients receiving MEC and HEC. Olanzapine, palonosetron and dexamethasone has been shown to improve the control of nausea compared with aprepitant, palonosetron and dexamethasone in patients receiving HEC. Breakthrough nausea and emesis was controlled with olanzapine in patients receiving HEC and guideline-directed prophylactic antiemetics. The addition of olanzapine to aprepitant, a 5-HT RA and dexamethasone significantly improved nausea and emesis compared with aprepitant, a 5-HT RA and dexamethasone alone in patients receiving HEC. Olanzapine is available as a generic.
The diagnosis of acne involves taking a history and physical examination to determine the type of acne (see clinical features of the different types of acne below), an assessment of severity (see page 38), and an assessment of psychosocial effect (see Chapter 4). Other investigations are not normally necessary; however, occasionally an underlying endocrinological disorder may necessitate further tests (see Adult female acne, pages 26-9). Table 3.1 outlines the key elements in developing an accurate acne history. Acne vulgaris. Acne vulgaris is the most common type of acne. The individual lesions of acne vulgaris (Figure 3.1) can be characterized as.
Postinflammatory erythema and/or pigmentary changes. In some patients, particularly those with skin of color and Fitzpatrick skin types IV-VI, hyper- (Figure 3.7) or hypopigmented macules may persist following resolution of inflammatory acne lesions. Patients may think that these resolving lesions are active acne lesions and may have the erroneous impression that their acne is not improving. It is important to reassure patients that these dark areas are healing lesions and not active acne.
Postinflammatory erythema and/or pigmentary changes. In some patients, particularly those with skin of color and Fitzpatrick skin types IV-VI, hyper- (Figure 3.7) or hypopigmented macules may persist following resolution of inflammatory acne lesions. Patients may think that these resolving lesions are active acne lesions and may have the erroneous impression that their acne is not improving. It is important to reassure patients that these dark areas are healing lesions and not active acne.
Acne conglobata is a very severe form of inflammatory acne characterized by grouped comedones, cysts, abscesses, draining sinus tracts and scars (Figure 3.8). The majority of affected patients are males who present with lesions on the back, buttocks, chest and face. The axilla and inguinal areas can also be involved. The grouped comedones often have multiple openings. The inflammatory lesions are large, tender and red to violaceous in color; they often drain a serous or purulent material. Deep-seated sinus tracts often develop, as does keloidal scarring. Secondary infection with staphylococci or streptococci can occur, although many lesions are colonized by Propionibacterium acnes (P. acnes) only.
Acne fulminans is a very severe form of inflammatory acne associated with systemic signs and symptoms, including fever, arthralgias and/or osteolytic lesions of the clavicles or ribs. It usually occurs in boys aged 13-18 years and can be very acute in its onset. Investigations frequently demonstrate leukocytosis, elevated erythrocyte sedimentation rate and/or proteinuria. Clinically, acne fulminans is characterized by multiple intensely inflamed nodules, cysts and plaques (Figure 3.9). Large nodules can ulcerate, drain and become necrotic. Hemorrhagic crusting is common. A polyarthritis of large joints such as the sacroiliac, hips, knees, shoulders, elbows and ankles may be present. The etiology of acne fulminans is unknown.
Hyperandrogenism. If an adult woman has sudden-onset severe acne, acne accompanied by signs of hyperandrogenism or acne that is refractory to conventional therapy, a medical history and physical examination directed towards eliciting symptoms or signs of hyperandrogenism should be performed. Investigations to rule out an underlying endocrine abnormality should also be carried out in these cases (Table 3.3); note, however, that most cases of adult female acne do not require an endocrine work-up. Screening tests for hyperandrogenism include serum dehydroepiandrosterone sulfate (DHEAS), total testosterone, free testosterone, and luteinizing hormone and follicle-stimulating hormone. These tests should be obtained in the luteal phase of the menstrual cycle. Women should be advised not to take oral contraceptives for at least 1 month before laboratory testing, as these drugs can mask an underlying endocrine abnormality.
The differential diagnosis of acne includes drug-induced acneiform eruptions, rosacea, pyoderma faciale, gram-negative folliculitis and perioral dermatitis. Drug-induced acne. A number of drugs cause or worsen acne or can induce an acneiform eruption (Table 3.5). The latter account for about 1% of all drug-induced skin eruptions. A diagnosis of acne vulgaris is defined by the presence of closed comedones, papules and pustules. In contrast, most drug-induced 'acnes' represent acne-like eruptions embracing monomorphic inflammatory lesions in the absence of comedones, often presenting abruptly outside the most frequent age range for acne and extending over areas not commonly affected by acne. The face and upper trunk are most frequently affected.
Perioral (periorificial) dermatitis (Figure 3.17) is characterized by erythema, scaling and small papules and pustules, most commonly around the mouth and on the chin. It often occurs in adult women, especially in the context of stress. Topical corticosteroids can cause or exacerbate the condition and should be avoided. Oral tetracycline is the treatment of choice. Assessing acne severity. Defining acne severity helps with the selection of the most suitable initial therapy and enables response to treatment to be monitored. There are many scales available for assessing the severity of acne, but no consensus on a gold standard. Severity can be determined according to the type, number, distribution or location of lesions, or a combination of each of these. Acne can be classified as comedonal, mild, moderate or severe based on the type of lesions (Table 3.6). Alternatively, an assessment tool such as the Leeds Revised Acne Grading System allows grading of severity based on photographic comparisons of acne on the face (Figure 3.18), back and chest.
Duration of pain is an important characteristic. Acute pain is a warning of acute injury. With acute injury, a specific array of prostaglandins, leukotrienes and other chemoattractants are released to alert the nervous system to damage and to initiate an inflammatory process to heal the traumatized structure. Therapies directed at control of acute pain, such as simple analgesics and NSAIDs, are effective. Importantly, the structure of the central nervous system has not been modified. When the injury has healed, the affected area returns to its usual status.
Any painful stimulus affecting the body is ultimately experienced in the central nervous system. There, it is modulated by genetically determined pain transmission and reception capabilities, familial and social conditioning, and increasingly by medicolegal and work-related socioeconomic factors and the possibility of malingering. All of these factors can be further modified by experiences of previous trauma, surgery and medication, as well as by general and specific health issues. Back pain occurs in an individual with a combination of physical, social and emotional concerns. All of these factors must be considered when evaluating the person who presents with the complaint of low back pain. Back pain is, in the truest sense, psychosomatic. Psychological issues must be addressed concurrently with the anatomic and pathological somatic aspects of low back pain-related disorders. Psychosocial issues must be prioritized, though they can often be readily handled by the patient and the practitioner. If this is not the case, they should be addressed promptly with appropriate psychiatric, psychological and/or social counseling according to need. Issues relating to drug habituation, depression, symptom amplification and chronic pain syndromes must be identified and addressed.
Many anatomic factors can play a primary or a secondary role in the development and progression of low back pain syndromes. The most common causes of low back pain are mechanical in origin. Mechanical disorders of the lumbar spine are related to injury, overuse or deformity of a spinal structure. The most important traumatic factors in low back pain relate to soft tissue structures. Precise identification of the injured tissue, and the role of that injury in the consequent pain and dysfunction, can be frustratingly difficult. Problems occur in muscles, intervertebral discs, facet joints, ligaments or spinal nerves. Aging causes modification of these structures over time, and different parts of the spine tend to be at greater risk for change or injury during different decades of life. Early in life, muscle injuries are more frequent, while joint problems occur in the sixth decade of life (Table 3.1).
The gluteal and piriformis muscles are shown in Figure 3.1. The primary functions of the gluteal muscles are to support, stabilize and mobilize the hips and lower extremities in relation to the pelvis and the trunk. Possibly the most common manifestation of lumbar and lumbosacral pain referral is to the mid-portion of the gluteal muscles (buttocks) that overlie the piriformis muscle. This is accompanied by a palpable localized region of deep, tender muscle induration. Because of the thickness of the overlying gluteus maximus muscle, the fibers of which are parallel to (and indistinguishable from) the piriformis muscle fibers, it is not possible to determine by palpation if the piriformis muscle per se is the source of the localized muscle tenderness. A 'piriformis syndrome' is therefore somewhat problematic to identify and must be carefully distinguished from the more common, spinal discogenic basis for sciatic radiculopathy. A piriformis syndrome may result from scarring after a fall on the buttocks or as a consequence of pelvic or hip surgeries. MRI can be used to visualize the tender area in the buttocks and help to identify selective piriformis entrapments of the sciatic nerve.
Facet (zygapophyseal) joints (Figure 3.5) are synovial-lined, cartilage-surfaced diarthrodial joints that are connected by a ligamentous joint capsule. Facet joint malalignments and associated degenerative osteoarthritic changes (Figure 3.6) are commonly noted radiographically with or without, and before and after, any accompanying low back pain disorders. This does not preclude an abnormal facet joint being a causal factor of a low back pain syndrome. This can be confirmed by a selective joint injection of hypertonic saline under fluoroscopic visualization to attempt to reproduce the pain, followed by a local anesthetic injection to provide specific relief of the induced pain. The facet joint pain referral pattern thus elicited may not be limited to the lumbar region, and may radiate into the buttock and/or down the leg, mimicking a sciatic nerve root pain (facet syndrome).
Although patients with spinal stenosis may complain of back discomfort and/or stiffness or pain with changing position or with activity, these are manifestations of associated lumbar or lumbosacral pathologies including facet arthritis, and are not due to the spinal stenosis per se. Examination of lower extremity pulses, particularly the dorsalis pedis and posterior tibial pulses, can help diagnose vascular claudication, but both spinal stenosis and arteriosclerosis can occur in the same patient. Spinal stenosis is most often a geriatric problem, and it can be symptomatically compounded by or confused with a number of conditions, including.
Long-term complications. Long-term complications develop in virtually all patients taking continued levodopa therapy. Although levodopa is the most effective drug for the treatment of Parkinson's disease, the initial benefit begins to diminish over time with dyskinesias and fluctuations in motor response (Figure 7.1). It is likely that two factors determine the development of fluctuations and dyskinesias. disease severity. chronic pulsatile stimulation of postsynaptic dopamine receptors by the use of dopaminergic drugs with a short half-life.
Dyskinesias may be related to 'off' or 'on' periods, but as the disease advances they become a continuum and difficult to classify. 'Peak-dose' dyskinesias are the most common. They involve choreic or ballistic movements, and may be associated with a variety of non-motor symptoms such as pain, mood alterations and cognitive changes. Dyskinesias may be socially unacceptable to carers, while patients may prefer to be dyskinetic when 'on'. Most dyskinesias progress and may lead to a reduced quality of life and weight loss. Reducing dopaminergic drugs will diminish dyskinesia, but may lead to a return of Parkinson's disease symptoms. Smaller doses of dopa given more frequently, or a combination of the drug with a dopamine agonist, may help, but problems are likely to reappear (see Table 7.4). The findings of a large number of preclinical and clinical studies indicate that continuous dopaminergic stimulation (CDS) may be the most desirable way to combat dyskinesias.
Dyskinesias may be socially unacceptable to carers, while patients may prefer to be dyskinetic when 'on'. Most dyskinesias progress and may lead to a reduced quality of life and weight loss. Reducing dopaminergic drugs will diminish dyskinesia, but may lead to a return of Parkinson's disease symptoms. Smaller doses of dopa given more frequently, or a combination of the drug with a dopamine agonist, may help, but problems are likely to reappear (see Table 7.4). The findings of a large number of preclinical and clinical studies indicate that continuous dopaminergic stimulation (CDS) may be the most desirable way to combat dyskinesias. Dementia is an important cause of comorbidity in parkinsonism; when cognition declines, mortality increases. Dementia is a bad sign and will often lead to the breakdown of support networks. Patients who are confused and hallucinating become difficult to manage at home and are frequently admitted to nursing homes. At this stage, life expectancy may be only 1-2 years.
Depression/anxiety is a marker for dementia in older patients. However, depression must not be mistaken for dementia. Pseudo-dementia can be mistaken for Parkinson's disease dementia. It is important to seek out depressive features and treat with antidepressants (tricyclic drugs or serotonin-reuptake inhibitors) if there is any suspicion of depression. The debate as to the advantages of the various antidepressants is ongoing (see Fast Facts: Depression).
Sleep problems in Parkinson's disease are common and may affect 60-98% of individuals at both early and late stages of the disease. Problems range from disease-related difficulties, such as rapid eye movement (REM) behavior disorder, sleep-maintenance insomnia, excessive daytime sleepiness and nocturia, to possibly drug-related problems, such as early-morning dystonia and night-time akinesia. The cause of restless legs syndrome in Parkinson's disease remains unclear, although it occurs around twice as commonly as in the general population. Sleep problems are a key determinant of quality of life in Parkinson's disease, and sleep scales specific to the disease such as the Parkinson's Disease Sleep Scale (PDSS) or the SCale for Outcomes in PArkinson's disease (SCOPA) are important for regular clinical assessments.
Sleep problems in Parkinson's disease are common and may affect 60-98% of individuals at both early and late stages of the disease. Problems range from disease-related difficulties, such as rapid eye movement (REM) behavior disorder, sleep-maintenance insomnia, excessive daytime sleepiness and nocturia, to possibly drug-related problems, such as early-morning dystonia and night-time akinesia. The cause of restless legs syndrome in Parkinson's disease remains unclear, although it occurs around twice as commonly as in the general population.
Do cognitive deficits predate the illness? The results of high-risk and large-scale birth cohort studies and studies of military inductees who have developed schizophrenia provide compelling evidence that people with schizophrenia exhibit subtle neurocognitive impairments prior to the onset of more florid psychotic symptoms (Table 7.2). Studies of IQ test scores obtained routinely during childhood show that those children who later develop schizophrenia, but not bipolar disorder, have significantly lower mean scores than either age- or social-class-matched children or siblings who do not develop schizophrenia. There is a dose-response relationship, such that for every point decrease in IQ, the risk of later schizophrenia increases by 4%. At the time of onset of positive psychotic symptoms, there is usually a further decline in IQ score.
How do deficits relate to symptoms and outcome? Patients with negative symptoms are more likely to exhibit clinically significant neurocognitive impairments than patients without these symptoms. Patients with negative symptoms have also exhibited the most impairment on tasks requiring self-generated, rather than stimulus-driven, activity. In contrast, disorganized patients are characterized by impaired performance on measures of distractibility, and they are also more likely to show an inability to inhibit inappropriate behavioral responses. Impairments of verbal memory, language, vigilance and executive function have been shown to be major determinants of poor social and community function in people with schizophrenia. Impairments of memory and executive and processing speed have been related to poor occupational outcome.
Negative symptoms, or the psychomotor poverty syndrome, correlate with decreased activity in the dorsolateral prefrontal cortex, particularly on the left. Interestingly, this pattern also appears in severe depressive illness with psychomotor retardation, thus indicating a final common cortical deficit underlying psychomotor poverty in schizophrenia and psychomotor retardation in depression. Positive psychotic symptoms correlate with hippocampal activation and with a distributed network of frontal, temporal and subcortical sites.
Negative symptoms, or the psychomotor poverty syndrome, correlate with decreased activity in the dorsolateral prefrontal cortex, particularly on the left. Interestingly, this pattern also appears in severe depressive illness with psychomotor retardation, thus indicating a final common cortical deficit underlying psychomotor poverty in schizophrenia and psychomotor retardation in depression.
In some cases, the link between a specific symptom and a functional abnormality emerges only under particular conditions. Compared with controls, patients with persecutory delusions show increased activation in the amygdala in situations of possible threat. Patients with auditory hallucinations show right-sided temporoparietal and parahippocampal deficits during inner speech tasks, which again suggest an internal monitoring problem. The disorganization syndrome correlates with increased activity in the dorsal anterior cingulate gyrus, a region involved in selective attention.
Symptoms. Patients with acute myeloid leukemia (AML) usually present with vague symptoms that are consequences of pancytopenia. Typically, the onset of symptoms is no more than 3 months before diagnosis. Fatigue is a common first symptom (Table 2.1), often accompanied by anorexia and weight loss. Fever or infection is the initial symptom in approximately 10% of patients, and 5% have signs of abnormal hemostasis (beyond minor bleeding and easy bruising). Bone pain, lymphadenopathy, non-specific cough, headache and diaphoresis (excessive sweating) may also occur. Bone pain, typically vaguely localized to the pelvis or back, is also a frequent symptom. Rarely, patients present with symptoms due to extramedullary leukemia (id est outside the blood and marrow), such as myeloid sarcoma (a tumor mass consisting of myeloid blasts); AML may infiltrate skin, lymph nodes, the gastrointestinal tract, soft tissue or testes. Patients who present with isolated myeloid sarcoma typically develop blood and/or marrow involvement quickly thereafter. Central nervous system (CNS) involvement is uncommon in AML (approximately 5% of cases, in contrast to acute lymphoblastic leukemia where CNS involvement is common).
On peripheral blood smears, the cytoplasm of the myeloid blast often contains primary (non-specific) granules, and the nucleus shows fine, lacy chromatin, with one or more nucleoli characteristic of immature cells. The presence of abnormal rod-shaped granules called Auer rods (Figure 2.1) on light microscopy of a blood smear or bone aspirate indicates a diagnosis of AML. Additionally, the morphology in some AML subsets is distinctly different and strongly suggests diagnosis of a particular subtype; however, this will need to be confirmed by a combination of additional diagnostic tests, such as cytochemistry, immunophenotyping, karyotype and molecular methods. For example, the myeloblasts in APL are classically hypergranular with clusters of Auer rods (called faggot cells) with a bi-lobed or reniform nucleus. While these features strongly suggest a diagnosis of APL, the final diagnosis will require demonstration of the appropriate molecular abnormality by either karyotyping or other molecular methods.
Once a diagnosis of AML is suspected, cytogenetic and genetic tests are required to aid rapid diagnosis, assess prognosis and to inform the best approach to treatment. Initial assessments should evaluate the functional integrity of the cardiovascular, pulmonary, hepatic and renal systems, and patients should also be evaluated for infection and DIC. Preparation for transfusion of blood or platelets requires blood type and crossmatch to be determined, and human leukocyte antigen (HLA) testing is required early in the treatment course (before chemotherapy) in consideration of future allogeneic hematopoietic cell transplantation. Cytogenetics has been a part of AML diagnosis for several decades, and typically requires bone marrow for successful testing (the increased number of proliferating cells in marrow yields better results than blood for karyotype analysis). Genetic testing (from blood or marrow) continues to evolve in both complexity and number of tests, and should include at least FLT3 (with allelic ratio), NPM1, CEBPA (bi-allelic), IDH1, IDH2 and TP53. Note that the European LeukemiaNet (ELN) recommendations do not include IDH1 and IDH2 (although this might be expected to change given the advent of treatments targeted at the encoded proteins); the World Health Organization (WHO) classification also recognizes RUNX1 - and ASXL1 -mutated AML as distinct entities.
Histology. The diagnosis of AML is based on a finding of 20% or more myeloid blasts by histology, cytochemistry or (more commonly) flow cytometry. However, this criterion is not required for diagnosis if any of the following recurrent cytogenetic abnormalities is present: t(15;17), t(8;21), inv(16) or t(16;16). Historically, the diagnosis and classification of AML was based on the French-American-British (FAB) criteria, which assigned patients to one of eight groups, designated M0-M7, based on morphologic and cytochemical features (Table 2.2). Essentially, M0-M5 describe stages of myeloid maturation; M6 and M7 describe erythroid leukemia and megakaryocytic leukemia, respectively. The FAB classification has been superseded by the WHO classification (Table 2.3) and the ELN risk stratification (Table 2.4), which include highly relevant cytogenetic and genetic aberrations. However, morphologic description using the FAB terminology is still a common feature of clinical discussion among clinicians and with patients.
Historically, the diagnosis and classification of AML was based on the French-American-British (FAB) criteria, which assigned patients to one of eight groups, designated M0-M7, based on morphologic and cytochemical features (Table 2.2). Essentially, M0-M5 describe stages of myeloid maturation; M6 and M7 describe erythroid leukemia and megakaryocytic leukemia, respectively. The FAB classification has been superseded by the WHO classification (Table 2.3) and the ELN risk stratification (Table 2.4), which include highly relevant cytogenetic and genetic aberrations. However, morphologic description using the FAB terminology is still a common feature of clinical discussion among clinicians and with patients. Cytogenetic analysis of leukemic cells provides important independent prognostic information and is a feature of both the WHO and ELN systems. The prognostic categories using cytogenetics are 'favorable', 'intermediate' and 'adverse' risk, based on the presence of structural and/or numeric chromosomal abnormalities. Patients with t(15;17), for example, have an excellent prognosis ( around 85% cured), and those with t(8;21) or inv(16) (inversion of chromosome 16) also have a favorable prognosis ( around 55% cured), at least when treated appropriately (see 'Treatment' chapter). Patients with no cytogenetic abnormalities (cytogenetically normal AML; CN-AML) have an intermediate risk ( around 40% cured). Patients with a complex karyotype such as t(6;9), inv(3) or -7 (absence of chromosome 7) have an adverse prognosis, with few cures, particularly for older patients.
Recurrent ovarian cancer. Despite initial treatment, ovarian cancer will recur in nearly two-thirds of women who originally presented with advanced disease. In this situation, the aims of treatment change from achieving cure to. extending survival. preserving quality of life by mitigating treatment-related adverse effects and ameliorating symptoms of the recurrent disease. Recurrent ovarian cancer may present in a number of ways, and may be asymptomatic or symptomatic. With asymptomatic (chemical) recurrence, disease may be minimal and the value of treatment in this situation has been challenged. The use of routine CA125 monitoring after front-line therapy varies globally, and is still common in the USA despite data questioning the value of such monitoring.
The choice of treatment in patients with recurrent ovarian cancer will depend on a number of patient-, drug- and tumor-related factors (Figure 7.1). Traditionally, the choice of treatment has been determined by the time that has elapsed since the last platinum-based chemotherapy: in practice, however, the treatment-free interval, irrespective of last platinum dose, may be even more valuable. In the near future, these somewhat restrictive determinants of treatment will be supplemented with more predictive factors such as BRCA status or tumor histology, and by gene- or pathway-based assessments that facilitate individualized therapy. Nevertheless, the traditional definitions of platinum resistance or sensitivity remain relevant in guiding treatment (Figure 7.2).
Patients in whom recurrence occurs more than 6 months after primary platinum treatment are often subdivided into two groups. highly platinum-sensitive patients, in whom recurrence occurs more than 12 months after primary platinum treatment. intermediately sensitive patients, in whom recurrence occurs 6-12 months after primary treatment. Platinum-resistant patients, in whom recurrence occurs within 6 months of primary platinum treatment, are generally treated with non-platinum options; these usually include single agent chemotherapies with or without bevacizumab. Some clinicians define patients who actually progress on front-line treatment as platinum-refractory. They are often treated similarly to platinum-resistant patients, although some clinicians recommend continuing the platinum backbone while substituting the taxane with an alternative chemotherapeutic. The prognosis and probability of response to subsequent treatment correlate directly with the time from the previous platinum or other treatment (Figure 7.3).
Chemotherapy for platinum-resistant disease. Patients with disease that recurs within 6 months of primary platinum treatment are generally treated with single agents, with or without bevacizumab. The most commonly used agents for retreatment include (usually weekly) paclitaxel, docetaxel, PLD, gemcitabine, topotecan and pemetrexed. Key clinical trials with these agents are summarized in Table 7.2. Unfortunately, the survival data and the objective response rates (less than 15%) are not impressive for any of the available single agents in the platinum-resistant setting; novel compounds and approaches are needed.
Sedentary behavior and obesity are closely linked but are not necessarily concurrent in the same individual and should be considered independent risk factors for disease. Inactivity, for example prolonged sitting, carries a risk irrespective of bodyweight. Lack of physical activity is a risk factor for stroke, coronary artery disease and type 2 diabetes mellitus and causes a twofold increase in risk for all-cause mortality, hard on the heels of smoking and hypertension in terms of damage done (Figure 6.1).
It is difficult to lose weight by physical activity alone but exercise reduces the adverse effects of overweight and obesity even if weight is not lost (Table 6.1). Increasing physical activity is as beneficial to general health as giving up smoking. Maximum benefits come from a combination of resistance and aerobic activity. An increase in muscle bulk at the expense of fat has multiple benefits: apart from reduction in cardiovascular disease and diabetes, it reduces the risk of cancer and loss of cognitive function, improves mood and sense of well-being, facilitates better sleep, and reduces the risk of frailty, falls and dependence in older age.
Maximum benefits come from a combination of resistance and aerobic activity. An increase in muscle bulk at the expense of fat has multiple benefits: apart from reduction in cardiovascular disease and diabetes, it reduces the risk of cancer and loss of cognitive function, improves mood and sense of well-being, facilitates better sleep, and reduces the risk of frailty, falls and dependence in older age. The waist circumference of someone who becomes fitter by increasing levels of activity will decrease, although their weight may change little. Encouraging patients who exercise. Individuals who attempt weight loss by physical activity alone should be congratulated on increased fitness, and should be encouraged to monitor their waist circumference; otherwise they may become frustrated and demoralized by lack of change in weight or body mass index (BMI).
Long-term medical conditions may affect a person's ability to achieve meaningful levels of activity, and appropriate advice must take this into account. For an obese person with chronic bronchitis, a few steps in the garden every hour may represent a significant increase in activity; a patient with asthma may need to be advised to use their salbutamol inhaler before exercising; a slow stroll on even ground may be appropriate for someone with severe vascular disease; advice to stand up while talking on the phone may be helpful for someone with severe physical limitations. The US Surgeon General's report recommends wheeling oneself in a wheelchair for 40 minutes as being a reasonable level of activity for health benefits, whereas a patient with lower-limb orthopedic problems may be advised to perform low-impact activities, or even arm exercises alone. Elderly patients often suffer from low muscle mass (sarcopenia), so increased physical activity of any degree and particularly with a resistance component should be vigorously promoted for anyone with severe physical limitations.
Long-term medical conditions may affect a person's ability to achieve meaningful levels of activity, and appropriate advice must take this into account. For an obese person with chronic bronchitis, a few steps in the garden every hour may represent a significant increase in activity; a patient with asthma may need to be advised to use their salbutamol inhaler before exercising; a slow stroll on even ground may be appropriate for someone with severe vascular disease; advice to stand up while talking on the phone may be helpful for someone with severe physical limitations. The US Surgeon General's report recommends wheeling oneself in a wheelchair for 40 minutes as being a reasonable level of activity for health benefits, whereas a patient with lower-limb orthopedic problems may be advised to perform low-impact activities, or even arm exercises alone. Elderly patients often suffer from low muscle mass (sarcopenia), so increased physical activity of any degree and particularly with a resistance component should be vigorously promoted for anyone with severe physical limitations.
Contraception. Carbamazepine (CBZ), eslicarbazepine acetate (ESL), felbamate (FBM), oxcarbazepine (OXC), phenobarbital (PB), phenytoin (PHT), primidone (PRM), rufinamide (RFN), and topiramate (TPM) at doses over 200 mg daily all induce the metabolism of female sex hormones. This metabolism can alter the menstrual cycle and increase turnover of the components of oral contraceptive pills and depot formulations of steroid hormones (Table 8.1). The risk of breakthrough pregnancy is not insignificant. An oral contraceptive formulation containing 50 µg of estrogen, with subsequent adjustment depending on the presence or absence of breakthrough bleeding, can provide secure contraception, as can barrier methods. Other birth control measures must be taken until the pattern of menstruation has been stable for at least 3 months. Lamotrigine (LTG) reduces levonorgestrel levels by about 20%, which is a potentially significant decrease. Levonorgestrel implants are contraindicated in women taking enzyme-inducing antiepileptic drugs (AEDs) as they have an unacceptably high failure rate. This is also likely to be the case with the progesterone-only pill. Medroxyprogesterone injections appear to be effective, though they need to be given more frequently than is usually recommended. The morning-after contraceptive pill can be used after unprotected intercourse. The effectiveness of the hormonal method of emergency contraception is reduced by enzyme-inducing drugs; a copper intrauterine device may be offered, or the dose of levonorgestrel should be increased.
Menstruation. Up to 20% of women with epilepsy have abnormal ovarian function, including anovulatory menstrual cycles and polycystic ovaries. These problems may be more common in patients treated with sodium valproate (VPA). Some women find that their seizures worsen mid-cycle or around menstruation, a phenomenon known as catamenial epilepsy. This exacerbation is thought to be a consequence of an imbalance between the proconvulsant estrogen and anticonvulsant progestogen concentrations. Manipulating the cycle with hormonal preparations is often unsuccessful, however, and may cause unwanted effects such as weight gain and depression. Another option is intermittent clobazam (CLB) for the few days just before and shortly after the onset of menstruation.
Pregnancy. The fertility of women with treated epilepsy is one-quarter to one-third lower than that of the general population. However, when women do conceive, most can expect to undergo uneventful pregnancies and deliver healthy babies. During pregnancy, metabolic processes change and close attention needs to be given to AED concentrations. Total serum concentrations of some drugs will fall, particularly those of PHT (Figure 8.1) and LTG. Women whose epilepsy is well controlled usually remain seizure free during pregnancy and delivery. Conversely, those who continue to report seizures before conception may have increased seizures during pregnancy. Before conception. Although it would be ideal to withdraw AED treatment in women contemplating pregnancy, for many this would result in recurrence or exacerbation of seizures that could be dangerous for both mother and fetus. If the criteria for discontinuation are met (see Therapy withdrawal), the AED should be stopped over a suitable interval before conception. If AED therapy cannot be withdrawn completely, it should be tapered to a minimally effective dose of, if possible, a single drug. In addition, supplemental folic acid, 4-5 mg daily, should be started before conception in an attempt to prevent neural tube defects. Folate treatment should be continued for the first 5 weeks of gestation, and current advice is to continue taking it at least until the end of week 12. These and other guidelines for managing epilepsy in women who are contemplating pregnancy are set out in Table 8.2.
Before conception. Although it would be ideal to withdraw AED treatment in women contemplating pregnancy, for many this would result in recurrence or exacerbation of seizures that could be dangerous for both mother and fetus. If the criteria for discontinuation are met (see Therapy withdrawal), the AED should be stopped over a suitable interval before conception. If AED therapy cannot be withdrawn completely, it should be tapered to a minimally effective dose of, if possible, a single drug. In addition, supplemental folic acid, 4-5 mg daily, should be started before conception in an attempt to prevent neural tube defects. Folate treatment should be continued for the first 5 weeks of gestation, and current advice is to continue taking it at least until the end of week 12. These and other guidelines for managing epilepsy in women who are contemplating pregnancy are set out in Table 8.2.
There are no clear data indicating differences in safety among PHT, CBZ, PB and PRM. Current evidence suggests that the risk of major congenital malformations is two to four times higher with the use of VPA than with other AEDs such as CBZ and LTG. Absolute rates have ranged from 6% to 11%, although the risk may be minimized by keeping daily doses at or below 1000 mg. High-dose exposure to VPA in utero may impair later cognitive function. The teratogenic risk associated with LTG monotherapy is low and is similar to that associated with CBZ, although preliminary data suggest the possibility of greater risk of major malformations at higher dosage. There are still insufficient data regarding the safety of other modern AEDs.
Old age is now the most common time in life to develop epilepsy. Approximately 1.5% of the population over the age of 70 years is diagnosed with active epilepsy. The number of elderly people diagnosed with epilepsy is set to rise further with the aging of the population. Nearly all de-novo seizures in elderly people are partial-onset with or without secondary generalization. Underlying factors can be identified in a greater proportion of elderly patients than younger patients, and include cerebrovascular disease, dementia and tumor. New-onset idiopathic syndromes are rare.
Diagnosis of epilepsy can be challenging and may depend on a witnessed event. Complex partial seizures presenting as confusion may be misdiagnosed as psychiatric symptoms. Postictal confusion can be prolonged in the elderly and may contribute to physical injury sustained during a seizure. AEDs are the mainstay of treatment, and are effective in most patients. Complete seizure control can be expected in more than 70% of elderly patients. A subgroup, often with progressive neurodegenerative disease, will continue to have seizures despite all attempts at pharmacological prevention. Elderly patients are particularly sensitive to the adverse effects of AEDs, possibly because of age-related pharmacokinetic changes caused by the delay in gastric emptying, reduction in body fat, and decreased hepatic metabolism and renal elimination. Low doses are generally recommended in the elderly in order to minimize adverse effects.
Children who develop epilepsy should be re-evaluated during their teenage years, and AED levels should be monitored. At puberty, hepatic metabolism slows to a rate similar to that in adults, which may lead to a rise in circulating AED concentrations. AED doses may, therefore, need to be reduced as a child grows older. However, such a rise is often offset by a teenage growth spurt. Falling AED levels may indicate imperfect compliance, a common occurrence in this age group. The teenage years are an appropriate time for counseling on contraception, clarifying the possible side effects of AEDs, and predicting prognosis and eventual drug withdrawal. Driving, social interactions and career advice are other issues that doctors caring for teenagers with epilepsy must address (see Chapter 9).
Before the doctor's first visit, a great deal of useful information can be obtained from a home assessment by a specialist epilepsy nurse following an agreed protocol. The home assessment should include. description of the episodes. evaluation of IQ. details of concomitant medication. previous and current AED treatment. circulating AED levels if appropriate. details of the carer's concerns and so on. Home video recordings can help to confirm or refute the diagnosis of epilepsy. At the outset, a management plan, including outcome aims, should be formulated with the full involvement of the carer(s) and family. Numbers and doses of AEDs should be minimized as much as possible. Attention should be paid not only to seizure frequency and severity, but also to behavior, mood, appetite, communication, cooperation, alertness and sleep pattern. Broad-spectrum AEDs, such as VPA, LTG, TPM, zonisamide and LEV, should be the preferred choice, and barbiturates and benzodiazepines should be avoided. The endpoint need not always be freedom from seizures, but perhaps better control accompanied by improved alertness, mood and cooperation.
Urologic symptoms are clearly a key aspect in the diagnosis of urinary disorders, but may not be reliable when used alone; as many have stated, the bladder may be an unreliable witness. The onset of urinary symptoms, their duration and severity, and the time(s) when they occur, should be recorded. Symptoms can be divided into filling/storage, voiding/emptying and postmicturition. Filling symptoms.
Urologic symptoms are clearly a key aspect in the diagnosis of urinary disorders, but may not be reliable when used alone; as many have stated, the bladder may be an unreliable witness. The onset of urinary symptoms, their duration and severity, and the time(s) when they occur, should be recorded. Symptoms can be divided into filling/storage, voiding/emptying and postmicturition. Filling symptoms. Frequency is the complaint of voiding too often by day and is usually defined as more than eight voids per 24 hours. Increased daytime frequency can occur with a normal bladder capacity where there is excessive fluid intake, or where the bladder capacity is affected by detrusor overactivity, impaired bladder compliance (compliance refers to the tonic change in bladder pressure during filling - usually, bladder compliance is normal if there is little or no change in detrusor pressure during filling) or increased bladder sensation (hypersensitivity). The causes of daytime frequency are shown in Table 2.1. Nocturia is the complaint of waking to void one or more times during the night. It may occur for the same reasons as daytime frequency, but may also occur in association with congestive heart failure (causing nocturnal polyuria) or because the normal circadian rhythm of antidiuretic hormone (ADH; desmopressin) secretion becomes reversed.
The strength of the pelvic floor muscles (PFM) should be assessed and can be quantified using a validated grading system such as the Oxford 1-5 scale. Factors to be assessed include strength, duration and repeatability of contractions, and displacement of the pelvic floor. Low-tone pelvic floor dysfunction refers to the examination findings of an impaired ability to isolate and contract the pelvic floor musculature in the presence of weak and atrophic musculature and is seen in women with POP, urinary or fecal incontinence, and vaginal weakness. High-tone pelvic floor dysfunction refers to the clinical condition of hypertonic spastic PFM with resultant impairment of muscle isolation, contraction and relaxation and is seen in women with interstitial cystitis/bladder pain syndrome, voiding dysfunction, overactive bladder, pelvic pain and sexual dysfunction with dyspareunia.
Quality of life. There are a number of ways to assess the impact of incontinence symptoms on a patient's quality of life. However, the only valid way to measure the patient's perception of their symptoms is through the use of psychometrically robust self-completion questionnaires, such as the International Continence Society's International Consultation on Incontinence modular questionnaire (ICIQ; Figure 2.2) A wide variety of questionnaires were assessed by the Continence Society the questionnaires recommended for the assessment of quality of life for patients with urinary incontinence alone or in the presence of lower urinary tract symptoms are listed in Table 2.2.
Frequency/volume bladder record. Use of a bladder record or diary is a simple and practical method to obtain information on a patient's normal voiding pattern, including frequency and amount of micturition and episodes of leakage, in addition to the time and volume of fluid ingested. The patient records the times and volumes of all voids over a specific time period, which should be at least 24 hours so that both day and night are included. Episodes of urinary incontinence are recorded and whether they are associated with, for example, urgency, straining or coughing. Eliciting an estimate of the volume of leakage during incontinence episodes is helpful. The following descriptions of urine leakage can be used.
Urinalysis and culture. Dipstick urinalysis is used to detect hematuria, glycosuria, pyuria and bacteriuria. It should be carried out for all patients presenting with urinary incontinence to exclude the possibility of infection, inflammation, urinary tract malignancy and diabetes. A positive dipstick test should be followed up by formal urine microscopy and culture to detect a urinary tract infection (UTI) before treatment and to allow antibiotic sensitivity to be evaluated. The presence of hematuria or red blood cells on microscopy should be investigated further with urine cytology, an imaging study of the upper tracts (kidneys and ureters) and endoscopic examination of the bladder and urethra to rule out malignancy, especially in a patient over 50 years of age with symptoms of bladder irritation. The investigation and management of hematuria are described in detail in Chapter 6.
Many clinicians request urodynamic investigation for any patient, especially a woman, who complains of lower urinary tract symptoms; however, the clinician may have little appreciation of the clinical indications, what the test involves and its limitations. Urodynamic investigation is safe, but men in particular may experience some discomfort related to catheterization, which can last for up to 24 hours after the test. The incidence of culture-proven UTI following urodynamic testing is approximately 1%; prophylactic antibiotics should therefore be considered for patients who may be at risk (exempli gratia immunosuppression or prosthesis implanted within last 2 years).
Before incontinence surgery. In our opinion, urodynamic information is essential if surgery to treat incontinence, especially stress incontinence, is contemplated. There is, however, some debate as to the need for urodynamic investigation before incontinence surgery. The UK's National Institute for Health and Clinical Excellence (NICE) has issued guidelines stating that preoperative urodynamic studies are not necessary for patients undergoing a primary procedure and whose symptoms and examination findings suggest simple stress incontinence. We disagree with this recommendation, as it has been claimed that surgery carried out on the basis of symptoms alone is inappropriate in up to 25% of cases. Furthermore, surgery for stress incontinence can lead to voiding dysfunction and de novo detrusor overactivity (the urodynamic term describing involuntary bladder contraction), or may exacerbate pre-existing symptoms, so it is important to perform a preoperative assessment.
Clinical gene therapy is a very active field, with a large number of clinical trials, approaches and disease targets. It is not feasible to review all of these here. Newer technologies such as gene editing will undoubtedly shape the design of future gene therapies. In the meantime, there are already a number of promising candidates in early-phase clinical trials that may add to the success of those more advanced gene therapies summarized in chapter 4 (Table 6.1). Several examples are described in the following sections.
X-linked myotubular myopathy (XLMTM) is a rare genetic neuromuscular disorder that has more recently been treated by systemic adeno-associated virus (AAV) vector delivery. Although results from more patients and longer-term follow-up data are still emerging, initial clinical trial results are quite remarkable. XLMTM is typically associated with severe muscle weakness. Symptoms are often already present at birth but may also develop later in infancy or early childhood. The defect is in a gene called MTM1 that encodes the enzyme myotubularin, which is required for the development and function of skeletal muscle. In addition to not being able to move on their own, boys born with the disease typically require assisted breathing and feeding. Approximately half of these children die within the first 1.5 years after birth. In a first clinical trial, nine patients aged from 8 months to 6 years were treated by systemic administration of a high dose of AAV8 vector, with the hope of widely transferring the MTM1 gene to muscle cells. Substantial restoration of myotubularin levels and improvements in muscle fiber development were observed on muscle biopsy. Impressively, at least four boys were able to sit up without help; three started to take steps with assistance. Some patients were able to vocalize sounds for the first time and eat food. These advances were presented at the 2019 annual meeting of the American Society of Gene and Cell Therapy.
Mutations in the ABCD1 gene cause an enzyme deficiency called adrenoleukodystrophy (ALD). As a consequence of the missing enzyme function, very-long-chain fatty acids accumulate, causing demyelination in the central nervous system (CNS) and the adrenal cortex. To initially test whether hematopoietic stem cell (HSC) gene transfer could treat this debilitating neurological disorder, two individuals with adrenoleukodystrophy were enrolled into a study. Lentiviral gene transfer was performed with autologous HSCs, and cells were transplanted following complete myeloablative conditioning. Impressively, these patients showed persistent therapeutic levels of aldolase protein for at least 3 years. Demyelination of the CNS was halted, resulting in stabilization of disease without any major safety complications. Cerebral ALD affects boys between ages 4 and 10 years, causing permanent disability; death occurs within 4-8 years of disease onset. The lentivirus/HSC approach is now being evaluated in such children in a Phase II/III trial. The absence of major functional disabilities at 24 months after transplantation serves as the primary efficacy endpoint for the study. Major functional disabilities include loss of ability to communicate, cortical blindness, need for tube feeding, total incontinence, wheelchair dependence and complete loss of voluntary movement. Among an initial group of 17 patients with median follow-up of 29.4 months, 15 were alive in 2017 with minimal clinical symptoms. As of early 2018, 29 individuals had received the gene therapy.
Hope for treatment of this disease comes from preclinical studies using AAV vectors that express not a therapeutic protein but a micro (mi)RNA that targets the HTT messenger (m)RNA and induces its degradation (the miRNA machinery of post-transcriptional regulation has evolved to specifically eliminate unwanted gene expression in a given cell type) (Figure 6.1). For example, an AAV5-miHTT vector was able to decrease production of the huntingtin protein by more than 50% in areas of gene transfer in the brains of minipigs that had been injected with the vector. Intracranial injections led to dose-dependent vector distribution to the striatum, putamen and spreading to the cerebral cortex. These areas are affected by neuropathological changes at different stages of the disease. Using this approach, sustained lowering of huntingtin protein levels and functional improvements have been demonstrated in a mouse model of the disease. For clinical trial design, high-resolution MRI scans of people with Huntington's disease serve to identify injection sites for safe and hopefully efficient delivery of the vector to the desired target regions of the brain. A Phase I/II trial is under way.
Hope for treatment of this disease comes from preclinical studies using AAV vectors that express not a therapeutic protein but a micro (mi)RNA that targets the HTT messenger (m)RNA and induces its degradation (the miRNA machinery of post-transcriptional regulation has evolved to specifically eliminate unwanted gene expression in a given cell type) (Figure 6.1). For example, an AAV5-miHTT vector was able to decrease production of the huntingtin protein by more than 50% in areas of gene transfer in the brains of minipigs that had been injected with the vector. Intracranial injections led to dose-dependent vector distribution to the striatum, putamen and spreading to the cerebral cortex. These areas are affected by neuropathological changes at different stages of the disease.
After a single seizure. Whether treatment should be started after a single episode remains controversial. Depending on study methods and inclusion criteria, the probability of recurrence over the next 5 years after a single unprovoked seizure ranges from 31% to 71%. As a substantial proportion of such patients will not have further episodes, most specialists do not routinely recommend treatment after a single seizure. Prospective randomized studies have shown that, compared with delaying treatment until a further episode, immediate treatment after a first generalized tonic-clonic seizure (GTCS) does not improve the long-term remission rate. However, treatment should be considered after the first seizure when the chance of recurrence is high - for instance, in the presence of an underlying cerebral lesion, an abnormal EEG or a strong family history of epilepsy, or if the patient has an epilepsy syndrome such as juvenile myoclonic epilepsy (JME) that is characterized by a high likelihood of seizure recurrence. In some instances, the patient may wish to start treatment after a single event because they are concerned about the potentially significant impact that recurrent seizures could have on their lifestyle, such as their ability to legally drive a car.
After a single seizure. Whether treatment should be started after a single episode remains controversial. Depending on study methods and inclusion criteria, the probability of recurrence over the next 5 years after a single unprovoked seizure ranges from 31% to 71%. As a substantial proportion of such patients will not have further episodes, most specialists do not routinely recommend treatment after a single seizure. Prospective randomized studies have shown that, compared with delaying treatment until a further episode, immediate treatment after a first generalized tonic-clonic seizure (GTCS) does not improve the long-term remission rate. However, treatment should be considered after the first seizure when the chance of recurrence is high - for instance, in the presence of an underlying cerebral lesion, an abnormal EEG or a strong family history of epilepsy, or if the patient has an epilepsy syndrome such as juvenile myoclonic epilepsy (JME) that is characterized by a high likelihood of seizure recurrence. In some instances, the patient may wish to start treatment after a single event because they are concerned about the potentially significant impact that recurrent seizures could have on their lifestyle, such as their ability to legally drive a car.
After a single seizure. Whether treatment should be started after a single episode remains controversial. Depending on study methods and inclusion criteria, the probability of recurrence over the next 5 years after a single unprovoked seizure ranges from 31% to 71%. As a substantial proportion of such patients will not have further episodes, most specialists do not routinely recommend treatment after a single seizure. Prospective randomized studies have shown that, compared with delaying treatment until a further episode, immediate treatment after a first generalized tonic-clonic seizure (GTCS) does not improve the long-term remission rate. However, treatment should be considered after the first seizure when the chance of recurrence is high - for instance, in the presence of an underlying cerebral lesion, an abnormal EEG or a strong family history of epilepsy, or if the patient has an epilepsy syndrome such as juvenile myoclonic epilepsy (JME) that is characterized by a high likelihood of seizure recurrence. In some instances, the patient may wish to start treatment after a single event because they are concerned about the potentially significant impact that recurrent seizures could have on their lifestyle, such as their ability to legally drive a car.
The goal of treatment should be to enable the patient to lead as normal a lifestyle as possible, which generally requires complete seizure control without, or with minimal, side effects. Choosing the most suitable AED for an individual patient requires knowledge of the characteristics of the epilepsy, the patient and the available AEDs. The issues discussed below should be included in the decision-making process. Monotherapy. In comparison with combination therapy, monotherapy is associated with better compliance and fewer side effects. It is therefore also likely to be more cost-effective. For these reasons, in general, serial monotherapy trials of two AEDs that are appropriate first-line treatment for the patient's seizure type(s) should be undertaken before combinations are tried (Figure 4.1). The chance of remission is highest with the first drug - 60% of patients with newly diagnosed epilepsy achieve seizure control with the first or second AED. Substantial attention should therefore be given to choosing the most appropriate initial AED, taking into account a range of factors, including the seizure type(s) and/or epilepsy syndrome. Other relevant issues include age, sex, weight, psychiatric and other comorbidities, childbearing potential and concomitant medication.
Titration and monitoring. Approximately 50% of newly diagnosed patients will be able to tolerate and become seizure free with the first AED, often in low or moderate doses. In general, the AED should be started at a low dose, with increments over a number of weeks to establish an effective and tolerable regimen, although some agents, such as sodium valproate (VPA) and levetiracetam (LEV), can be commenced at effective doses with, or even without, a rapid titration phase. Slow titration will help avoid concentration-dependent side effects as with carbamazepine (CBZ) or topiramate (TPM), in particular central nervous system toxicity, the presence of which is likely to discourage the patient from persevering with therapy in the long term. An additional benefit of a cautious approach is that it allows the development of tolerance to sedation or cognitive impairment. Such a policy will also ensure early detection of potentially serious idiosyncratic reactions, such as rash, hepatotoxicity and blood dyscrasias (see Side effects). Slow titration with lamotrigine (LTG) has been shown to reduce the risk of skin rash.
Titration and monitoring. Approximately 50% of newly diagnosed patients will be able to tolerate and become seizure free with the first AED, often in low or moderate doses. In general, the AED should be started at a low dose, with increments over a number of weeks to establish an effective and tolerable regimen, although some agents, such as sodium valproate (VPA) and levetiracetam (LEV), can be commenced at effective doses with, or even without, a rapid titration phase. Slow titration will help avoid concentration-dependent side effects as with carbamazepine (CBZ) or topiramate (TPM), in particular central nervous system toxicity, the presence of which is likely to discourage the patient from persevering with therapy in the long term. An additional benefit of a cautious approach is that it allows the development of tolerance to sedation or cognitive impairment. Such a policy will also ensure early detection of potentially serious idiosyncratic reactions, such as rash, hepatotoxicity and blood dyscrasias (see Side effects). Slow titration with lamotrigine (LTG) has been shown to reduce the risk of skin rash.
For partial seizures and GTCS (the most common seizure types), the established AEDs, with the exception of ethosuximide (ESM), appear to have similar efficacy. There is a possible small benefit of CBZ over VPA for partial seizures. Phenobarbital (PB) and primidone (PRM) have demonstrated higher withdrawal rates because of their sedative effects at higher dosages. None of the newer AEDs has shown superior efficacy when tested against the established agents for the treatment of partial seizures and GTCS, but some have demonstrated better tolerability, in particular fewer neurotoxic side effects (Table 4.5). Thus, LTG and OXC have shown better overall effectiveness than CBZ and PHT, respectively, for partial epilepsy whereas VPA may be more efficacious than LTG for some generalized epilepsies.
The practical difficulty with combination therapy is that troublesome or disabling side effects are common at high doses, and complex pharmacokinetic interactions can occur. Consequently, it is advisable to combine drugs with different side-effect profiles and those that do not have the potential for deleterious drug interactions. Practical guidelines for prescribing AEDs are summarized in Table 4.9. Drug-resistant epilepsy. The International League Against Epilepsy (ILAE) defines drug-resistant epilepsy as 'a failure of adequate trials of two tolerated and appropriately chosen and used AED schedules (whether as monotherapies or in combination) to achieve sustained seizure freedom'. An online classifier, intended to aid the application of the ILAE definition of drug-resistant epilepsy, is available at www.drugresistantepilepsy.com. Fulfillment of the definition in a patient should prompt a comprehensive review of the diagnosis and management, preferably by an epilepsy specialist.
Attending to the patient's psychosocial, cognitive, educational and vocational needs is an important part of caring for people with epilepsy. Both the primary care physician and the epilepsy specialist should work closely with other medical and social service professionals, and extend their roles beyond that of clinician to educator and advocate. Subsequent referral to a comprehensive epilepsy center for EEG monitoring, investigational drugs or devices, or consideration for epilepsy surgery is indicated for compliant patients whose seizures prove resistant to two or three reasonable attempts at pharmacological manipulation using new and established AEDs singly and in combination.
Management. Antihypertensive therapy is beneficial in reducing both cardiovascular and renal events, as well as lowering mortality. In patients with CKD, treating hypertension is important in slowing disease progression and in reducing cardiovascular risk. In patients with ESKD, the focus should be directed towards reducing cardiovascular morbidity. Patients with albuminuric CKD (> 500 mg albumin/24 hours) require aggressive management of blood pressure, with a target of less than 130/80 mmHg. A more relaxed target of less than 140/90 mmHg is recommended for patients who are normoalbuminuric. First-line therapy should comprise lifestyle changes, such as reducing salt intake, moderating alcohol intake, stopping smoking and taking regular exercise, which together can lower blood pressure by 10/5 mmHg. An angiotensin-converting enzyme (ACE) inhibitor or an angiotensin- receptor blocker (ARB) is recommended as first-line therapy in patients with CKD (Figure 5.2). However, usually more than one drug is required, and a beta-blocker, a calcium-channel blocker or a diuretic agent can be added. The key features of several commonly used antihypertensive drug classes are shown in Table 5.2. The choice of drugs can be influenced by comorbid conditions, as shown in Table 5.3.
Renovascular disease is a remediable form of hypertension and should be excluded in high-risk patients, such as elderly hypertensives with evidence of diffuse atherosclerosis, in refractory or malignant hypertension, in those with 'flash' pulmonary edema and in individuals with an abdominal bruit. In young women with hypertension of recent onset, fibromuscular renal artery disease should be excluded. The preferred diagnostic tests include magnetic resonance angiography and ACE-inhibitor renography. Duplex ultrasonography with Doppler flow measurements can be a useful screening test but is rather operator dependent, and in many patients the renal arteries cannot be visualized. The definitive diagnostic tests in almost all patients are still digital subtraction angiography or arteriography (Figure 5.3), but both carry a risk of contrast nephropathy and cholesterol embolization. Magnetic resonance angiography with gadolinium is not recommended in patients with an estimated glomerular filtration rate (GFR) of less than 60 mL/min/1.73m because of the risk of gadolinium-associated nephrogenic skin fibrosis, although the risk is very small and possibly dependent on the type of gadolinium used.
Hypertension during pregnancy is defined as any rise in systolic blood pressure of more than 30 mmHg or a rise in diastolic blood pressure of more than 15 mmHg above baseline, or the use of antihypertensive agents. It is classified according to its presentation (Table 5.5). Chronic hypertension is more common in multiparous women, and is present at the first antenatal visit. On the other hand, pre-eclampsia is more common in primigravidas (in 10% of first pregnancies), and represents an important cause of maternal and perinatal mortality. It usually presents only after 20 weeks of gestation, with or without proteinuria and a raised serum urate. Elevated levels of soluble fms-like tyrosine kinase-1 (sFlt-1 or sVEGFR-1) and endoglin have been reported in pre-eclampsia and have been implicated in disease pathogenesis. Pre-eclampsia may progress to full-blown eclampsia, which is characterized by seizures and also associated with acute kidney injury (AKI). Management of eclampsia comprises immediate delivery, and magnesium sulfate, anticonvulsant and antihypertensive therapy.
Hypertension during pregnancy is defined as any rise in systolic blood pressure of more than 30 mmHg or a rise in diastolic blood pressure of more than 15 mmHg above baseline, or the use of antihypertensive agents. It is classified according to its presentation (Table 5.5). Chronic hypertension is more common in multiparous women, and is present at the first antenatal visit. On the other hand, pre-eclampsia is more common in primigravidas (in 10% of first pregnancies), and represents an important cause of maternal and perinatal mortality. It usually presents only after 20 weeks of gestation, with or without proteinuria and a raised serum urate. Elevated levels of soluble fms-like tyrosine kinase-1 (sFlt-1 or sVEGFR-1) and endoglin have been reported in pre-eclampsia and have been implicated in disease pathogenesis. Pre-eclampsia may progress to full-blown eclampsia, which is characterized by seizures and also associated with acute kidney injury (AKI). Management of eclampsia comprises immediate delivery, and magnesium sulfate, anticonvulsant and antihypertensive therapy.
Antihypertensive agents must be reviewed in women with renal disease who wish to get pregnant. Methyldopa, labetalol, hydralazine and nifedipine are all safe drugs for treating hypertension in pregnancy, but diuretics should be avoided. ACE inhibitors are contraindicated from the second trimester, but may be important in controlling the progression of CKD. Women may therefore continue to take these as they plan a pregnancy but must stop when pregnant.
Diabetic nephropathy is defined by the presence of albuminuria. Overt nephropathy is characterized by albuminuria of more than 300 mg/24 hours or 200 µg/minute; in addition, hypertension and kidney dysfunction, with a progressive decline in kidney function over time, may be present. The pathology of nephropathy in type 1 and type 2 diabetes is identical and comprises glomerular hypertrophy, glomerular basement membrane thickening, mesangial matrix accumulation and nodular glomerulosclerosis (Figure 5.5). Natural history (Table 5.6). The earliest clinical evidence of nephropathy is the appearance of microalbuminuria, which is a low but abnormal amount of albumin in the urine (> 30 mg/24 hours or 20 µg/minute). Microalbuminuria can also be detected by an increased albumin:creatinine ratio in a spot urine sample (> 2.5 mg/mmol in men or 3.5 mg/mmol in women), which avoids the need for timed urine collections. Patients with early disease have incipient nephropathy and without specific interventions may progress to overt or clinical albuminuria over a period of 2-10 years. Most patients will also develop hypertension, which initially manifests as the absence of a nocturnal dip in blood pressure, but later becomes sustained hypertension.
Type 2 diabetes. All patients with type 2 diabetes should be screened for incipient or established diabetic nephropathy, because microalbuminuria is present at diagnosis in approximately 25% of patients. If urinalysis is positive for protein (in the absence of infection), it is very likely that the patient has clinical albuminuria (> 300 mg/24 hours), which has important implications in terms of the progression of renal disease and overall cardiovascular risks. Positive urinalysis should be confirmed quantitatively (exempli gratia spot urine albumin:creatinine ratio), and patients in whom urinalysis is negative for protein require quantitative assessment for microalbuminuria. Type 1 diabetes. In contrast, microalbuminuria is rarely present at the time of diagnosis of type 1 diabetes or before puberty, and therefore screening should begin with the onset of puberty or 5 years after the diagnosis and be performed annually.
Type 2 diabetes. All patients with type 2 diabetes should be screened for incipient or established diabetic nephropathy, because microalbuminuria is present at diagnosis in approximately 25% of patients. If urinalysis is positive for protein (in the absence of infection), it is very likely that the patient has clinical albuminuria (> 300 mg/24 hours), which has important implications in terms of the progression of renal disease and overall cardiovascular risks. Positive urinalysis should be confirmed quantitatively (exempli gratia spot urine albumin:creatinine ratio), and patients in whom urinalysis is negative for protein require quantitative assessment for microalbuminuria. Type 1 diabetes. In contrast, microalbuminuria is rarely present at the time of diagnosis of type 1 diabetes or before puberty, and therefore screening should begin with the onset of puberty or 5 years after the diagnosis and be performed annually.
Risk factors. The major factor influencing the development of diabetic nephropathy is hyperglycemia. Persistent hyperglycemia leads to the development of glycosylated macromolecules and their conversion to advanced glycosylation end products. This process results in thickening of the basement membranes (including the glomerular basement membrane) and accumulation of matrix proteins within the glomeruli.
Although genetic factors predispose individuals to develop diabetes, whether they also influence the rate of progression of the nephropathy remains controversial. The racial and familial distribution of diabetes also suggests a role for as yet undetermined polygenic influences. Other risk factors include male sex and smoking. Apart from glycemic control, the other major factor determining progression through diabetic nephropathy is hypertension. Prevention and treatment. Aggressive intervention in patients with either incipient or established nephropathy has been shown unequivocally to prevent progression of renal disease. Strategies include aggressive glycemic control, angiotensin blockade, blood pressure control, protein restriction and smoking cessation (Figure 5.6 and Table 5.8).
Prevention and treatment. Aggressive intervention in patients with either incipient or established nephropathy has been shown unequivocally to prevent progression of renal disease. Strategies include aggressive glycemic control, angiotensin blockade, blood pressure control, protein restriction and smoking cessation (Figure 5.6 and Table 5.8). The US Diabetes Control and Complications Trial (DCCT) and the UK Prospective Diabetes Study (UKPDS) have clearly shown that intensive therapy can significantly reduce the risk of the development of microalbuminuria and overt nephropathy in individuals with diabetes. In the UKPDS, there was a 75% reduction in the relative risk of doubling serum creatinine over 12 years.
There is a strong link between smoking and many psychiatric disorders, including mood disorders, schizophrenia and substance abuse. Smoking is also prevalent among homeless people, many of whom suffer from mental health disorders. Not only are persons with psychiatric disorders more likely to smoke, but they are also likely to smoke more heavily than others. It has yet to be established why these links exist: whether smoking causes or exacerbates these conditions, whether a disorder makes it more likely that a patient will smoke and be unable to stop, or whether there is a common underlying cause. It is widely thought that smoking is particularly closely linked to schizophrenia, but in fact the dominant factors are the severity of the psychiatric disorder and whether the patient is institutionalized (Figure 3.1). Thus, discussion about whether specific links exist between smoking behavior and the mechanisms that underlie schizophrenia or its treatment are somewhat premature.
In countries such as the UK, smokers support these kinds of policies, presumably because they recognize that they can provide an added incentive to stop - which is what they mostly want to do. Taxation has to be linked to effective countermeasures against illicit supply. It is important to structure it to prevent tobacco companies using pricing policies to undermine its deterrent effect. Not all of the decrease in consumption involves smokers giving up altogether; in some cases smokers merely reduce the number of cigarettes they smoke. The health benefits of this action may be undermined, however, because smokers tend to smoke each cigarette more intensively. It is also not fully known how reductions in consumption translate into health benefits. Nevertheless, it is clear that increasing the cost of smoking is, potentially, an important public health measure. Mass media campaigns can be effective in promoting smoking cessation and reducing smoking prevalence. The size of the effect is related to the intensity of the campaign (as indexed by viewing numbers) and whether it is sustained. Specific quitting events, for example the UK's 'No Smoking Day' and 'Stoptober' (a mass quitting event that challenges smokers to be smoke-free for a month as a stepping stone to permanent cessation), and the US 'Great American Smokeout' (which encourages quitting for a day), have been evaluated as a highly cost-effective way of promoting smoking cessation.
Family functioning. Historically, the role of dysfunctional styles of family interaction was put forward in theories of the development of eating disorders. Unfortunately and unfairly, this has led to some parenting styles being blamed for causing eating disorders in children. Still, the type of relationships that children and adolescents develop with food and body image, both healthy and unhealthy, is strongly influenced by. parental attitudes toward eating, weight and body shape. parental eating and weight-related behavior modeled in the home. excessive parental control over a child's nutritional intake such that the child is unable to make independent food choices. Perceived pressure to be thin, family criticism regarding weight, and maternal investment in slenderness predict eating disturbances in adolescents. Parents also have a strong influence over their children's internalization of the aesthetic ideal.
Societal influences. The preoccupation with body image and the drive to attain thinness that are characteristic of eating disorders relate to the idealized representation of the human figure within a given culture, and to the pressure to conform from peers and the media. In Western countries, the body dimensions of female cultural icons, such as fashion models and actresses, have become progressively thinner over the past decades, with a concomitant rise in disordered eating among women. Mounting evidence implicates the mass media in the promotion of body-image and eating disturbances, with the emphasis on dieting and other weight-control behaviors often targeted at women rather than men, thus paralleling the gender distribution of eating pathology. A longitudinal prospective study of ethnic Fijian adolescent girls demonstrated an increase in key indicators of disordered eating following novel prolonged television exposure to the aesthetic ideal. The internalization of societal pressures has been shown to have a clear effect on body dissatisfaction and eating dysregulation in population samples. The first diet in adolescent girls is most frequently triggered by comparison with others' appearance and their own self-ideal. Societal influences and internalization of the thin ideal may lead directly to body dissatisfaction and unhealthy eating, or may be mediated by more general psychological processes such as intrapersonal (self-esteem, mood, personality) or interpersonal functioning and/or emotional regulation and coping. Stressors and life events precipitate the onset of eating disorders in 70% of cases, and include parental neglect, abuse, indifference, loss and separation. In some studies, a high incidence of sexual abuse during childhood is reported by women with diagnosed eating disorders; rates of abuse are seemingly higher in bulimia than anorexia. In a US statewide representative sample, both sexual and physical abuse were strong independent risk factors for disordered eating in adolescent girls and boys. The nature of this relationship is difficult to assess because of differences in diagnostic criteria for abuse, a high base rate of sexual abuse in the general female population and a high rate of abuse associated with other psychiatric diagnoses. The issue is insufficiently explored in young people. Male university students who reported physical and sexual abuse in childhood were also at a greater risk for eating disorders.
Stressors and life events precipitate the onset of eating disorders in 70% of cases, and include parental neglect, abuse, indifference, loss and separation. In some studies, a high incidence of sexual abuse during childhood is reported by women with diagnosed eating disorders; rates of abuse are seemingly higher in bulimia than anorexia. In a US statewide representative sample, both sexual and physical abuse were strong independent risk factors for disordered eating in adolescent girls and boys. The nature of this relationship is difficult to assess because of differences in diagnostic criteria for abuse, a high base rate of sexual abuse in the general female population and a high rate of abuse associated with other psychiatric diagnoses. The issue is insufficiently explored in young people. Male university students who reported physical and sexual abuse in childhood were also at a greater risk for eating disorders.
Prepuberty and adolescence. Studies have also confirmed that eating problems emerge in response to pubertal change, especially fat accumulation. Girls who feel most negatively about their bodies at puberty are at a higher risk of developing eating difficulties. Several studies have identified associations between disturbed eating in adolescents and.
Depression is one of the most salient psychiatric comorbidities in both men and women with eating disorders. Dysregulation in serotonin, a neurotransmitter involved in the regulation of both mood and satiety, has been implicated as a causal factor in depression and eating disorders. Antidepressants that selectively block serotonin reuptake are effective in the treatment of both depression and bulimia or binge-eating disorder. Anxiety and obsessive-compulsive behavior. Similarly, increased levels of anxiety and obsessiveness have been described in young people and adults with eating disorders. Premorbid overanxious disorder and obsessive-compulsive tendencies are seen significantly more often in patients with anorexia than in controls. Similarly, the risk for bulimia is increased by the presence of overanxious disorder or social phobia relative to controls. However, longitudinal studies in other fields indicate that premorbid anxiety disorders and negative affectivity are also risk factors for the development of other psychiatric conditions such as affective disorders and substance abuse.
17% of bulimics report a current or past history of drug, substance or alcohol abuse and/or dependence, or treatment for any of the above. 20% of drug abusers report a current or past history of bulimia or bulimic behaviors. Among bulimics, the family history studies show alcoholism rates of 39%, and drug or substance use rates of 19%. When treating a patient with either an eating disorder or a substance-abuse problem, the clinician should always consider the possibility of a comorbid substance-abuse or eating problem.
Prostate cancer is the most common malignancy to affect men of middle age and beyond in most developed countries and, increasingly in developing countries, it is second only to lung cancer as a cause of cancer deaths in men. The lifetime risk of developing clinical prostate cancer in western countries is about 1 in 8. Approximately 80% of men aged 80 years have prostate cancer at autopsy. However, many of these cancers grow slowly and the risk of developing clinically detectable cancer is about 13%; the lifetime risk of actually dying from prostate cancer is approximately 3%. Worldwide, there has been a steady increase in the incidence of clinically significant prostate cancer, although in the USA the number of incidental diagnoses of prostate cancer has fallen by 28% since the US Preventive Task Force issued a draft guideline in 2011 (which became a final recommendation 2012) discouraging prostate-specific antigen (PSA)-based screening in all men (Figure 1.1).
Race. Marked geographic and racial variations are seen in the incidence of clinical prostate cancer (Table 1.2). The risk is highest in North America and northern European countries, and lowest in the Far East. In the USA, the risk is higher in black men than in white men, and black men also appear to develop more aggressive disease earlier. The incidence of prostate cancer is lowest in Chinese and Japanese races, although the prevalence is now increasing in both. The incidence of latent (clinically insignificant) disease is similar in all populations studied. The incidence of prostate cancer in men who emigrate from a low- to a high-risk area increases to that of the local population within two generations. This suggests that environmental influences such as diet and lifestyle factors may have a profound effect on the development of prostate cancer and on the progression of latent to clinically detectable cancer.
Most prostate cancers are adenocarcinomas. The majority (> 70%) appear to arise in the peripheral zone of the gland (Figure 1.3); 5-15% arise in the central zone and the remainder from the transition zone, which is where benign prostatic hyperplasia (BPH) also develops. Microscopic foci of 'latent' prostate cancer are a common autopsy finding and may appear very early in life: approximately 30% of men over 50 years of age have evidence of latent disease. However, these microscopic tumors often grow very slowly, and many never progress to clinical disease. Beyond a certain size, however, these lesions progressively de-differentiate, probably as a result of clonal selection, and become increasingly invasive. A tumor with a volume greater than 0.5 cm or that is anything other than well differentiated is generally regarded as clinically significant.
Because prostate cancers are often heterogeneous, the numbers of the two most widely represented grades are added to produce the Gleason score (exempli gratia 3 + 4), which provides useful prognostic information. Occasionally, more than two grades are observed in prostatectomy or biopsy specimens, the least common being known as the tertiary grade. If the tertiary grade has a high score (4 or 5), the patient has increased risk of disease progression even if the primary and secondary grades are lower, and the tertiary rather than the secondary grade informs the score.
The characteristic history of amyotrophic lateral sclerosis (ALS) is one of often insidious, yet always progressive, asymmetric weakness without prominent sensory symptoms. The most common complaints are of a weakness in one arm or leg, or a change in the voice. Individuals are often able to date the onset of symptoms to a specific month. While individuals often try to associate the onset of symptoms with other events (exempli gratia a viral infection or surgery), there is no firm epidemiological evidence to support a consistent trigger in this regard. Occasionally, an individual with ALS will perceive that the initial symptom came on overnight. Despite this assertion, they rarely seek acute services, unlike those who have a stroke, even though such individuals are frequently, and erroneously, referred for assessment as such.
Occasionally, an individual with ALS will perceive that the initial symptom came on overnight. Despite this assertion, they rarely seek acute services, unlike those who have a stroke, even though such individuals are frequently, and erroneously, referred for assessment as such. The history of progressive weakening is critical. In the early stages, symptoms may fluctuate from day to day or week to week. More rarely, an individual with ALS will report transient remission of weakness. In these cases, it is important to consider the broader overall trajectory of the condition to establish the clear presence of progression of weakness. Individual symptoms depend on the region affected and the relative burden of upper and lower motor neuron disease.
Atrophy can be best observed by comparing muscles side by side and looking for asymmetry, which is the more common pattern in ALS. The lateral intrinsic hand muscles, especially the first dorsal interossei, are typically more affected than the medial ones. This so-called 'split hand' in ALS is not easily explained in terms of peripheral or proximal limb innervation and may instead reflect the cortical organization associated with the uniquely opposable thumb in humans, or selective involvement of motor neuronal pools in the anterior horns of the cervical spinal cord (Figure 3.1). The tongue, quadriceps, tibialis anterior and calf muscles are also frequently affected by visible atrophy. Tongue atrophy in ALS is invariably symmetric (unlike atrophy in the limbs) (Figure 3.2). Fasciculation may be missed unless the individual is undressed to expose the upper chest, back and proximal arms and legs (see Case report 3.1). Individuals with ALS usually do not report fasciculation (unlike those with benign fasciculation). Fasciculation in the tongue can be difficult to distinguish from brief semi-voluntary movements, exaggerated by protrusion. It is best appreciated with the tongue relaxed, resting in the floor of the mouth, with the mouth gently opened. Muscle tone is reduced in LMN disease. This is not commonly a useful sign, as it only becomes apparent when weakness is advanced. Conversely, the increased tone seen in UMN disorders may be detectable before any weakness becomes apparent. 'Clasp-knife' spasticity may occur and there may be clonus, commonly at the ankles and, more rarely, at the jaw and occasionally at the patella or forearm. Repetitive movements are slowed in UMN disease. This is a crucial part of the examination in suspected ALS, and is best appreciated by asking the individual to.
Lower motor neuron weakness in a limb characteristically affects muscles supplied by more than one peripheral nerve or nerve root. Any muscles may be affected, but a common combination is to see weakness in the hand involving the median innervated abductor pollicis brevis (ask the individual to put their palms face up and point their thumbs to the ceiling) and weakness of the ulnar interossei (ask the individual to spread their fingers against resistance). Early 'finger drop' (distal upper-limb extensor weakness) is unusual for ALS and should prompt consideration of multifocal motor neuropathy with conduction block (see page 62). Proximal weakness in the arms may result in weakness of shoulder abduction or of flexion and extension at the elbow. Proximal arm weakness may become bilateral: the brachial amyotrophic diplegic phenotype ('flail arm' or 'man-in-a-barrel'; see page 18). When onset is in the leg, the ankle dorsiflexors are often involved early. Listening and watching for a foot drop and steppage gait can be a sensitive way to detect this, as can asking the individual to walk on their heels. Cramping on muscle strength testing, and occasionally when the patient bends to remove their socks or shoes, is a non-specific sign but often seen in ALS.
Proximal weakness in the arms may result in weakness of shoulder abduction or of flexion and extension at the elbow. Proximal arm weakness may become bilateral: the brachial amyotrophic diplegic phenotype ('flail arm' or 'man-in-a-barrel'; see page 18). When onset is in the leg, the ankle dorsiflexors are often involved early. Listening and watching for a foot drop and steppage gait can be a sensitive way to detect this, as can asking the individual to walk on their heels. Cramping on muscle strength testing, and occasionally when the patient bends to remove their socks or shoes, is a non-specific sign but often seen in ALS.
Primary lateral sclerosis presentation. Approximately 3% of those diagnosed within the spectrum of ALS have a slowly progressive, pure UMN syndrome called primary lateral sclerosis (PLS) (see page 15). Weakness is far less prominent a symptom than in typical ALS. Instead, PLS tends to involve stiffness and poor balance, sometimes with falls. The symptoms most commonly start in the legs. In a minority with an initial bulbar presentation, common symptoms include a strained or forced voice and marked emotional lability. Distinguishing PLS from UMN-predominant ALS is challenging (see Chapter 4).
This sets up a cascade of phosphorylation steps of subcellular enzymes that are controlled by key regulators. The eventual result is the movement of a glucose transporter, glucose transporter 4 (GLUT4), from the cell cytosol to the cell surface, and this permits glucose uptake into the cell (Figure 4.1). Within this complex pathway, there are many points at which signaling may be perturbed. Overall, such perturbation results in a reduced glucose-uptake response to insulin (insulin resistance). The body attempts to override this by producing more insulin (hyperinsulinemia). When the pancreatic beta cells can no longer produce sufficient insulin to overcome insulin resistance, blood glucose levels start to rise.
In addition, low-grade systemic inflammation is often found in obesity; disturbed adipose tissue secretion of molecules called adipokines (such as adiponectin, tumor necrosis factor alpha [TNFalpha], interleukin-6) can contribute to this. Adipokines can interfere with insulin action through a number of specific pathways involving intracellular inflammation signal transduction pathways that link in to insulin signaling pathways. These disturbances in inflammation add to the metabolic disturbances in the regulation of insulin signaling and contribute to insulin resistance.
Lipotoxicity in type 2 diabetes is found in the muscle cells, where glucose is the major substrate. However, it has also been reported in the pancreas, where the effects of excess lipid can contribute to damage to insulin-secreting beta cells. Thus, in the situation of nutrient excess and obesity, where there are excess amounts of circulating fatty acids, lipotoxicity can increase insulin resistance (and the demand for insulin) and diminish the ability to respond by worsening beta cell impairment (see Figure 4.2).
In the context of cancer, the term immunotherapy encompasses a variety of approaches, targeting diverse immunologic targets. The history of immuno-oncology. The concept of immuno-oncology dates back more than 100 years, to 1893 (Figure 3.1). In that year, William Coley, an American surgeon and cancer researcher, observed remission of cancer in patients with postoperative bacterial infections, and suggested that activation of the immune system must play a role in combating cancer., Subsequently, in 1909, Paul Ehrlich suggested that the immune system must play an important role in preventing the development of cancer. However, it was not until the mid-20th century when Lewis Thomas and Frank MacFarlane Burnet hypothesized that the immune system is capable of eliminating cancerous cells through a process known as immune surveillance, and that this process depends on recognition of tumor-associated antigens by the immune system., Subsequently, through the laboratory work of Lloyd Old and Robert Schreiber, the concept of immune surveillance has evolved into 'immunoediting', reflecting the ability of tumor cells to evade the immune system. Increasing understanding of the underlying mechanisms of immunoediting has identified numerous potential therapeutic targets, some of which - notably immune checkpoint inhibition as first demonstrated by James Allison in the 1990s - are already yielding promising results in clinical practice., Indeed, in 2013, cancer immunotherapy was cited as the 'breakthrough of the year' by the journal Science.
What types of tumor are potentially susceptible to immuno-oncology?. Clearly, the potential sensitivity of a given cancer to immuno-oncology therapies will depend on the ability of the tumor to trigger an immune response (immunogenicity). Cancer is characterized by an accumulation of genetic mutations, many of which result in the expression of cancer-specific antigens that can bind to major histocompatibility complex (MHC) class I molecules on the cancer cell surface. These antigen-MHC complexes can be recognized by cytotoxic CD8+ lymphocytes, that, if activated, could potentially mount an immune response against the tumor. As a result, tumors with high somatic mutation rates may be more susceptible to immuno-oncology therapies than those with lower mutation rates. Somatic mutation rates differ markedly, both between tumor types and within an individual tumor type: the rate may vary more than 1000-fold between tumors with the highest and lowest rates (Figure 3.2). The highest rates are seen in cancers of the skin, lung, bladder and stomach, while the lowest are seen in hematologic and pediatric cancers. It is noteworthy that the highest rates occur in tumors that are induced by carcinogens such as tobacco smoke or ultraviolet light.
Clearly, the potential sensitivity of a given cancer to immuno-oncology therapies will depend on the ability of the tumor to trigger an immune response (immunogenicity). Cancer is characterized by an accumulation of genetic mutations, many of which result in the expression of cancer-specific antigens that can bind to major histocompatibility complex (MHC) class I molecules on the cancer cell surface. These antigen-MHC complexes can be recognized by cytotoxic CD8+ lymphocytes, that, if activated, could potentially mount an immune response against the tumor. As a result, tumors with high somatic mutation rates may be more susceptible to immuno-oncology therapies than those with lower mutation rates. Somatic mutation rates differ markedly, both between tumor types and within an individual tumor type: the rate may vary more than 1000-fold between tumors with the highest and lowest rates (Figure 3.2). The highest rates are seen in cancers of the skin, lung, bladder and stomach, while the lowest are seen in hematologic and pediatric cancers. It is noteworthy that the highest rates occur in tumors that are induced by carcinogens such as tobacco smoke or ultraviolet light. Potential targets for cancer immunotherapy. A variety of cancer immunotherapy strategies are currently being investigated, or have already entered clinical practice. These are conventionally classified as passive or active immunotherapies, according to their ability to activate an immune response against tumor cells (Table 3.1), although this classification does not adequately reflect the complexity of drug-host-tumor interactions. As a result, it has been suggested that immunotherapies should be classified according to their antigen specificity; however, even therapies initially directed against a single antigen may eventually become responsive to multiple antigens, a phenomenon known as epitope spreading. Passive immunotherapies. Tumor-targeting monoclonal antibodies. Monoclonal antibodies (mAbs) that specifically target malignant cells are among the best characterized forms of cancer immunotherapy.
Assessment of the benefits and risks of cancer immunotherapies can be challenging, as the criteria used for conventional therapies cannot generally be extrapolated to immunotherapies. Assessing efficacy. A key issue in immuno-oncology is that patients may show a survival benefit in the absence of an objective response as defined by conventional RECIST (Response Evaluation Criteria in Solid Tumors) criteria. Response to immunotherapies may vary markedly between patients: while some patients may show an initial response or stable disease, in others the response may be delayed because of the need to restore T-cell responses - a process that requires the interaction of numerous other immune cells. Indeed, in some patients, there is an initial phase of pseudoprogression during which the tumor appears to enlarge due to infiltration of newly reactivated T cells and subsequent inflammation. For these reasons, a set of immune-related response criteria (irRC) have been proposed (Table 3.6), relating to four patterns of response.
Assessing safety and tolerability. Some immunotherapies, notably checkpoint inhibitors, are associated with immune-related adverse events such as fatigue, diarrhea, nausea and altered liver or kidney function (Figure 3.4). Many of these resemble the adverse events often seen with conventional chemotherapy but have different etiologies: while adverse events with conventional chemotherapy usually reflect cytotoxic effects on healthy tissue, adverse events with immunotherapies typically reflect actions on the immune system. For example, diarrhea associated with immunotherapy may be due to a reaction to gut-associated or self-antigens. Such adverse events require careful management, because although most are mild or moderate in severity, failure to recognize them as immune related could lead to suboptimal management, with potentially serious or life-threatening consequences. For example, if untreated, diarrhea from immune-related colitis may become self-perpetuating, potentially leading to gut perforation.
Patients with mild acute pancreatitis (AP) (65% of cases) have an uneventful disease course, with initial severe pain that improves quickly. In general terms, these patients are easily managed. In contrast, patients with moderate-to-severe AP may be challenging: they may require aggressive fluid resuscitation and they have prolonged pain and sometimes intolerance to oral refeeding. These patients may develop organ failure (OF) and be prone to late complications. This chapter addresses the early management of AP, focusing on the evidence underpinning each intervention.
However, local complications such as pancreatic necrosis are associated with fluid sequestration, as intravascular liquid leaks to the retroperitoneum. This results in hemoconcentration and it has been suggested that an increased hematocrit is in fact a marker for local complications, not their cause (reverse causation bias). In 2009 and 2010, two studies were published by the same research group., These were open-label randomized controlled trials (RCTs) comparing a more aggressive versus a moderate fluid volume administration (10-15 vs 5-10 mL/kg/hour) and a more rapid versus a slower hemodilution (hematocrit < 35% vs >= 35% at 48 hours) in patients with severe AP according to the classic 1993 Atlanta criteria (presence of local complications and/or organ failure). In both trials, the more aggressive approach was associated with worse outcomes, including decreased survival. These studies suggested that vigorous resuscitation is dangerous in patients with severe AP. The studies had some flaws, including being open-label single-center RCTs, with suboptimal randomization, an unexpectedly high rate of sepsis in patients with aggressive resuscitation and large differences in mortality between treatment groups despite a very small sample of patients, and they require validation.
However, local complications such as pancreatic necrosis are associated with fluid sequestration, as intravascular liquid leaks to the retroperitoneum. This results in hemoconcentration and it has been suggested that an increased hematocrit is in fact a marker for local complications, not their cause (reverse causation bias). In 2009 and 2010, two studies were published by the same research group., These were open-label randomized controlled trials (RCTs) comparing a more aggressive versus a moderate fluid volume administration (10-15 vs 5-10 mL/kg/hour) and a more rapid versus a slower hemodilution (hematocrit < 35% vs >= 35% at 48 hours) in patients with severe AP according to the classic 1993 Atlanta criteria (presence of local complications and/or organ failure). In both trials, the more aggressive approach was associated with worse outcomes, including decreased survival. These studies suggested that vigorous resuscitation is dangerous in patients with severe AP. The studies had some flaws, including being open-label single-center RCTs, with suboptimal randomization, an unexpectedly high rate of sepsis in patients with aggressive resuscitation and large differences in mortality between treatment groups despite a very small sample of patients, and they require validation.
Fluid type. Both an open-label and a triple-blind RCT have demonstrated that fluid resuscitation using lactated Ringer's solution (a balanced salt solution) is associated with a decreased inflammatory response when compared with fluid resuscitation with normal saline (with a high chloride content). According to in vitro experiments, it seems that this anti-inflammatory effect depends on lactate. However, both studies included a small number of patients, and the influence of lactated Ringer's solution on important outcomes such as OF or mortality is unknown. In studies addressing other clinical scenarios, balanced fluids such as lactated Ringer's solution seem to be associated with a decreased need for blood products and a lower incidence of renal replacement therapy, hyperkalemia and postoperative infections when compared with normal saline. For the time being, it seems that lactated Ringer's solution is a good choice for fluid resuscitation in AP.
However, placement of a nasojejunal tube is not easy, it is time-consuming and results in great patient discomfort. Furthermore, it has been shown that standard nasojejunal feeding does in fact stimulate pancreatic secretion. Three studies comparing a nasogastric versus a nasojejunal route found no difference in outcomes, so both feeding routes can be recommended, depending on the presence or absence of gastric outlet obstruction. In 2014, the Dutch Pancreatitis Study Group published an RCT in patients with predicted severe AP which compared early (within 24 hours) nasojejunal enteral nutrition versus on-demand nasojejunal enteral nutrition (the patients tried oral refeeding on the third day and enteral nutrition was given on the fourth day only to those who could not tolerate oral feeding). The study showed that on-demand oral feeding was not associated with worse outcomes, and only 31% of patients needed a nasojejunal tube. Overall, therefore, in patients with moderate-to-severe AP, oral refeeding on day 3 to 4 should be encouraged and nasogastric or nasojejunal tube feeding from day 4 should be reserved for patients who cannot tolerate oral refeeding or who are sedated. The nasojejunal route is indicated in patients with gastric outlet obstruction.
Early endoscopic retrograde cholangiopancreatography. Gallstone AP is associated with choledocholithiasis, but in most cases the stones are cleared to the duodenum spontaneously. The first single-center RCTs suggested a benefit for early endoscopic retrograde cholangiopancreatography (ERCP) in AP, but later, better designed RCTs which excluded patients with acute cholangitis, showed that regardless of severity and the presence of choledocholithiasis, patients undergoing ERCP within the first 72 hours do not have better outcomes., Patients with AP and acute cholangitis may benefit from early ERCP, as the first studies (those showing better outcomes for early ERCP) included patients with this complication. Preliminary data from a large Dutch multicenter study, the APEC trial, have confirmed the lack of benefits from early ERCP in AP.
Traditionally, SE is diagnosed when the patient has continuous or repeated seizure activity without regaining consciousness for more than 30 minutes. This time frame is defined on the basis of decompensatory cerebral damage after 30 minutes of seizure activity when physiological changes fail to compensate for the increase in cerebral metabolism. In practice, however, most authorities would recommend emergency antiepileptic drug (AED) treatment when a seizure has lasted more than 5-10 minutes, excluding simple febrile seizures.
The most readily recognized type of SE is tonic-clonic SE, but it has been estimated that 25% of SE cases are 'non-convulsive' in nature. Diagnosis of the latter can only be established by concurrent EEG recording. Depending on the electrographic changes, non-convulsive SE is subdivided into complex partial and absence SE. SE is a neurological emergency that requires immediate treatment. SE may result from a variety of causes (Table 7.1), the commonest of which include non-compliance with antiepileptic medication, consumption of alcohol, metabolic problems, acute stroke and hypoxia.
The most readily recognized type of SE is tonic-clonic SE, but it has been estimated that 25% of SE cases are 'non-convulsive' in nature. Diagnosis of the latter can only be established by concurrent EEG recording. Depending on the electrographic changes, non-convulsive SE is subdivided into complex partial and absence SE. SE is a neurological emergency that requires immediate treatment. SE may result from a variety of causes (Table 7.1), the commonest of which include non-compliance with antiepileptic medication, consumption of alcohol, metabolic problems, acute stroke and hypoxia.
Most centers would initiate treatment with a benzodiazepine intravenously (most commonly lorazepam or diazepam), followed by phenytoin or fosphenytoin, or phenobarbital. If the seizure persists, the patient might be considered as having refractory SE and general anesthesia would be warranted. Although not tested in randomized control trials, AEDs with intravenous formulations (exempli gratia sodium valproate, levetiracetam, lacosamide) are often used when first-line therapies fail. Table 7.3 lists the schedules for treating resistant SE, as discussed at the first London Colloquium on Status Epilepticus on behalf of the Taskforce on Status Epilepticus of the International League Against Epilepsy in 2007. In persistent SE, it is important to watch for potential complications including hypothermia, acidosis, hypotension, rhabdomyolysis, renal failure, infection and cerebral edema. An underlying cause should continue to be investigated. Treatment response should be monitored clinically and with EEG.
During a seizure cluster, oral therapy in a child may be problematic and intravenous access is usually unavailable or difficult. Rectal diazepam administered by parents or other caregivers may be effective in this situation. Rectal diazepam is absorbed more rapidly than rectal lorazepam or oral diazepam because of its high lipid solubility. A gel-containing prefilled unit-dose rectal delivery system is commercially available. The doses used in clinical studies (0.5 mg/kg for children aged 2-5 years, 0.3 mg/kg for children aged 6-11 years, 0.2 mg/kg for those over 12 years) were effective and well tolerated, and did not produce respiratory depression. The most common side effect was somnolence. Buccal midazolam, available in Europe, is being increasingly used instead of rectal diazepam. In adults and children over 10 years of age, 10 mg can be given and repeated once if necessary. Lower amounts can be used in younger children. Nasal formulations of benzodiazepines are under development.
Essential thrombocythemia (ET) is characterized by vascular features, including both thrombosis and paradoxical bleeding. In addition to the risk of major vessel thrombosis, thrombosis in the microcirculation (most likely transient) can give rise to symptoms such as red and painful extremities (erythromelalgia; Figure 4.1), headache, paresthesia, loss of vision or hearing and transient ischemic attack. Given this risk of thrombosis and hemorrhage, a key aim in the treatment of ET is to prevent blood clotting and bleeding; however, it is also important to alleviate any problematic symptoms.
Essential thrombocythemia (ET) is characterized by vascular features, including both thrombosis and paradoxical bleeding. In addition to the risk of major vessel thrombosis, thrombosis in the microcirculation (most likely transient) can give rise to symptoms such as red and painful extremities (erythromelalgia; Figure 4.1), headache, paresthesia, loss of vision or hearing and transient ischemic attack. Given this risk of thrombosis and hemorrhage, a key aim in the treatment of ET is to prevent blood clotting and bleeding; however, it is also important to alleviate any problematic symptoms.
As described in Chapter 3, the risk of thrombosis in ET is assessed on the basis of age and previous history of thrombosis. Thus, a patient below the age of 60 years with no previous history of thrombosis would be considered at low risk of vascular complications, whereas an older patient or one with previous thrombosis is considered to be at high risk. Similarly, Janus kinase 2 (JAK2) mutations are associated with a higher risk of thrombosis than are calreticulin (CALR) mutations, and may therefore be considered an additional risk factor for thrombosis in patients with ET (Figure 4.2), although this has yet to be fully incorporated into clinical practice. The choice of treatment depends on the patient's risk level. In general, patients at the lowest level of risk defined by the International Prognostic Score for Essential Thrombocythemia (IPSET) scoring system (Table 3.6, page 38) - younger patients without JAK2 mutations, no cardiovascular risk factors and no history of thrombosis - can often be managed by observation only, and they may not require aspirin (yet to be validated in clinical practice). Low-risk patients with JAK2 mutations, or cardiovascular risk factors in the absence of JAK2 mutations, should perhaps be treated with aspirin. As a general principle, all high-risk patients should be treated with aspirin (unless contraindicated) and cytoreductive therapy to reduce the platelet count.
Management of low-risk patients. Treatment to reduce cardiovascular risk factors, and promotion of a generally healthy lifestyle, may be sufficient intervention for very-low-risk patients. Smoking cessation should be actively promoted because cigarette smoking has been shown to be an independent risk factor for thrombosis in patients with ET. Low-dose aspirin has been shown to reduce both microvascular symptoms (exempli gratia erythromelalgia) and transient neurological and visual disturbances such as hemiparesis, scintillating scotomas, amaurosis fugax (transcient monocular blindness) and seizures. There is also evidence that antiplatelet therapy reduces the risk of venous thrombosis in patients with JAK2 V617F mutations and cardiovascular risk factors (arterial thrombosis). Higher doses of aspirin (up to 500 mg daily) may be required in patients with acute erythromelalgia.
Low-dose aspirin has been shown to reduce both microvascular symptoms (exempli gratia erythromelalgia) and transient neurological and visual disturbances such as hemiparesis, scintillating scotomas, amaurosis fugax (transcient monocular blindness) and seizures. There is also evidence that antiplatelet therapy reduces the risk of venous thrombosis in patients with JAK2 V617F mutations and cardiovascular risk factors (arterial thrombosis). Higher doses of aspirin (up to 500 mg daily) may be required in patients with acute erythromelalgia. Cytoreductive therapy does not reduce the risk of thrombosis compared with observation alone in low-risk patients with ET, and recent data from the PT-1 study have shown that early cytoreductive therapy does not reduce mortality from thrombotic events. Management of high-risk patients. The agents most commonly used for cytoreductive therapy in high-risk patients with ET are hydroxyurea (also known as hydroxycarbamide), interferon-(IFN)-alpha, which suppresses hematopoietic cells in the bone marrow, anagrelide and busulfan (Table 4.1).
Typically, evaluation of treatment responses involves monitoring of blood cell counts and assessment of constitutional symptoms and their impact on the patient's quality of life and general wellbeing. Since the treatment of ET aims primarily to reduce the risk of thrombosis and bleeding, response criteria have traditionally focused on platelet count. Response criteria cannot be defined in low-risk patients treated with aspirin, whereas the aim of treatment in higher-risk patients receiving cytoreductive therapy is to reduce platelet counts to below 400-450 x 10 /L. However, the likelihood of thrombosis during cytoreductive treatment appears to be influenced more by the degree of leukocytosis (> 10 x 10 /L) than by the platelet count, which suggests that this is a more relevant response criterion. In clinical practice, an inadequate response to treatment in patients with ET (or indeed PV) may be identified by various criteria, including elevated platelet or white blood cell counts, burdensome symptoms and clinical events such as thrombosis or bleeding (Table 4.2). It is important to recognize developing resistance to standard therapy - hydroxyurea in particular - because of an increased risk of disease transformation.
Chemoprevention refers to the use of drugs to reduce the risk of cancer. The 5alpha-reductase inhibitor finasteride has been shown to reduce the incidence of prostate cancer by 24.8% compared with placebo over a 7-year period, although at the cost of a small but significant increase in sexual side effects. However, this is counterbalanced by the finding that a small proportion of cancers in the finasteride group tended to be more aggressive than those in the placebo group, although this may have been an artifact of taking biopsies from the smaller prostates in the active treatment arm resulting from the shrinkage effect of finasteride. A 2013 study reported that there was no difference in the overall survival (OS) rate, or survival after a diagnosis of prostate cancer, between the placebo-treated and finasteride-treated patients after 18 years of follow-up. Another 5alpha-reductase inhibitor, dutasteride, has been evaluated for its effect on the occurrence of prostate cancer in the REDUCE study (Reduction by Dutasteride of Prostate Cancer Events). Dutasteride resulted in a 23% reduction in the development of prostate cancer, mainly by suppressing the well-differentiated cancers, with only a slight (statistically insignificant) increase in Gleason pattern 7 or 8-10 poorly differentiated tumors. It also effectively treated the symptoms arising from benign prostatic hyperplasia (BPH). Neither of these compounds were approved by the regulatory authorities for chemoprevention.
Very few trials have investigated the effect of diet and lifestyle change on prostate cancer progression. Table 2.2 outlines the current body of evidence. In addition, a large number of compounds - many of them herbal - have been tested in the laboratory and show potential; these include green tea and other polyphenols, resveratrol from red wine, vitamin D, epilobium and Serenoa repens (saw palmetto). It must be remembered that cardiovascular disease is still the primary cause of death in men, with or without prostate cancer, and heart-healthy lifestyle choices will reduce mortality in men with prostate cancer. These include improving lipid profiles, decreasing obesity and increasing physical fitness. A healthy diet and regular vigorous exercise may help protect the individual against various forms of cancer, in addition to decreasing the risk of death from cardiovascular causes.
Anatomy, physiology and epidemiology. The pancreas. Anatomy. The pancreas is the shape of a small flat fish, 6-8 inches long and salmon pink in color. It lies behind the stomach, stretching between the duodenum on the right, to the center of the spleen (hilum) on the left (Figure 1.1). It is conventionally divided into the head, uncinate process, neck, body and tail. Physiology. The pancreas is important for the production of. digestive enzymes - from the acinar cells. bicarbonate - from the duct cells (to neutralize gastric acid). insulin - from the cells of the islets of Langerhans (essential for glucose control). Epidemiology of pancreatic disease. In the year 2000 there were 1.15 million patients with non-malignant pancreatic disease in the USA. Each year 125 000 North Americans present with acute pancreatitis, 100 000 present with chronic pancreatitis and at least 45 000 die from diseases of the pancreas. Pancreatic cancer is a highly lethal cancer and ranks fourth among cancer-related deaths in the USA. It is estimated that about 48 960 people will be diagnosed with pancreatic cancer and about 40 560 people will die of pancreatic cancer in 2015 in the USA.
Epidemiology of pancreatic disease. In the year 2000 there were 1.15 million patients with non-malignant pancreatic disease in the USA. Each year 125 000 North Americans present with acute pancreatitis, 100 000 present with chronic pancreatitis and at least 45 000 die from diseases of the pancreas. Pancreatic cancer is a highly lethal cancer and ranks fourth among cancer-related deaths in the USA. It is estimated that about 48 960 people will be diagnosed with pancreatic cancer and about 40 560 people will die of pancreatic cancer in 2015 in the USA.
Anatomy. The main pancreatic duct joins the bile duct to form the common channel or ampulla of Vater (also known as the major papilla). In 90% of people, the embryonic dorsal and ventral pancreatic ducts are fused to form this pancreatic duct, meeting in the head of the pancreas. In the other 10%, the ducts drain separately into the duodenum (pancreas divisum) and the dorsal duct (known as the accessory duct) drains through the minor papilla. Small sphincters around the ends of the main bile and pancreatic ducts control the flow of bile and pancreatic juice, respectively; the sphincter of Oddi controls the outflow from the ampulla of Vater.
Epidemiology of biliary tract disease. Gallstones are prevalent worldwide and are a considerable cause of morbidity and mortality. They may cause acute biliary colic, acute cholecystitis or chronic cholecystitis, acute pancreatitis or cholangitis. Gallbladder carcinoma is the fifth most common gastrointestinal (GI) cancer in the USA and the most common GI cancer in Native Americans. Incidence and mortality are very high in certain Latin American countries, especially Chile. Of the most commonly seen GI cancers in the USA, Europe and Australia, gallbladder cancer is the least common compared with other parts of the world. In most EU countries (with similar trends in the USA and Australia), mortality rates for gallbladder cancer have declined by approximately 30% among women and 10% among men, but mortality is still high in central and eastern Europe.
Improvements in therapy for systemic cancer have increased the number of patients living long enough to develop symptomatic brain metastases. Indeed, brain metastases are the most common intracranial tumor. In particular, human epidermal growth factor receptor-2-positive (Her2+) breast cancer patients with systemic disease controlled with trastuzumab appear to have an increased risk of developing brain metastases. Thus, the development of new strategies to prevent and treat brain metastases is increasingly important. Approximately 1 in 4 patients with cancer will develop a brain metastasis; patients with melanoma, lung or breast cancer are at the greatest risk (Table 4.1). Most patients present with headaches or focal neurological deficits; 20% or more present with or develop seizures. Radiographically, metastases are ring-enhancing lesions, most often located at the gray-white matter junction. There is often significant surrounding edema. About half are single lesions (Figure 4.1), with the remainder being multiple lesions (Figures 4.2 and 4.3). Skull and dural metastases are most commonly seen in association with prostate and breast cancer.
Patients with a new diagnosis of brain metastasis should be systemically restaged as appropriate for their primary tumor. The Radiation Therapy Oncology Group (RTOG) has delineated specific prognostic categories for patients with newly diagnosed brain metastases (Table 4.2). These may be helpful in determining appropriate treatment options and long-term plans (exempli gratia hospice care) for individual patients. A treatment algorithm for newly diagnosed brain metastasis is shown in Figure 4.4.
Aggressive focused management of brain metastases may improve the prognosis for some patients. Those with a single brain metastasis located in a surgically accessible region clearly benefit from a combination of surgical resection and whole-brain radiotherapy. Stereotactic radiosurgery may also be helpful. In this patient group, the median survival with either of these approaches is 8-9 months. These results, while encouraging, have been obtained in highly selected patient populations, most of whom had a high Karnofsky performance status, limited systemic tumor burden and small brain metastases. Such patients have an inherently better prognosis, and consequently these results may not be easily extrapolated to all patients. (The Karnofsky performance status is scored from 0 to 100, with higher scores meaning a patient is better able to carry out daily activities.).
'Depression', or 'clinical depression', refers to a mood disorder that ranges in severity from mild to severe, in duration from brief to enduring, and in pattern of illness from single to recurrent episodes. Diagnosis is based on the symptom profile and the severity, duration and course of the disorder. It is characterized by low mood and the absence of positive affect (id est loss of interest and enjoyment in everyday activities), together with a range of emotional, cognitive, physical and behavioral features. Clinical depression is a heterogeneous disorder, with some forms having clear biological underpinnings whereas others arise from psychosocial adversity. While classification systems have specified diagnostic criteria, uncertainties remain about the validity of the threshold that differentiates clinical depression from 'normal' unhappiness. Some investigators and commentators have questioned the validity of depression on the basis of variations that are purported to exist in its presentation, prevalence, prognosis and meaning within different cultures. Some commentators identify psychiatric diagnoses such as depression as 'Western' categories that can be imposed on non-Western peoples - a form of medical imperialism.
Alongside the lack of clear biological characteristics for depression (as well as for a large number of other psychiatric conditions), there is a problem of where to draw the boundary between normal and pathological depression. The distinction between depression and the distress and angst that are part of normal human experience requires a dichotomization of this continuum of symptoms. Rather than being based on 'hard' criteria related to a clear causal mechanism, with associated biological markers, this differentiation is based on clinical characteristics. Although this is problematic, it is useful to bear in mind that this also applies to other common medical conditions such as diabetes, hypertension and irritable bowel syndrome, where the variation between extensive and disabling symptoms and few and insignificant symptoms are on a continuum.
Alongside the lack of clear biological characteristics for depression (as well as for a large number of other psychiatric conditions), there is a problem of where to draw the boundary between normal and pathological depression. The distinction between depression and the distress and angst that are part of normal human experience requires a dichotomization of this continuum of symptoms. Rather than being based on 'hard' criteria related to a clear causal mechanism, with associated biological markers, this differentiation is based on clinical characteristics. Although this is problematic, it is useful to bear in mind that this also applies to other common medical conditions such as diabetes, hypertension and irritable bowel syndrome, where the variation between extensive and disabling symptoms and few and insignificant symptoms are on a continuum.
Delineating depression from other mental disorders. In the community, as well as in primary care settings, the most prevalent mood disorder is a combination of depression and anxiety. The overlap between symptoms such as low mood, lack of energy, insomnia, worry and irritability is considerable; for example, in 2014, nearly 8% of the UK household population demonstrated this combination of symptoms to a clinically significant extent, although smaller proportions have sufficient symptoms to be diagnosed with depression or anxiety disorders. Among people who meet the diagnostic thresholds for depression or anxiety disorders there is also a high degree of concurrence of these conditions, raising questions about the specificity of these diagnostic categories. While there is no distinct etiology for depression - it is best conceptualized as having a mix of biopsychosocial and lifestyle factors that contribute to its onset - a common genetic factor for anxiety and depressive conditions is apparent, and similarities in the types of environmental adversities that seem to provoke depression and anxiety, such as childhood adversity, have been reported. Moreover, the pharmacological treatments principally classified as antidepressants are also effective in anxiety disorders, and similar types of individual, group and internet-based psychological treatments appear to be effective for both conditions.
The cluster of symptoms experienced in depression is central to its classification as a mental health disorder. The number, intensity and effects of these symptoms are central to differentiating depression from normal experiences and from other disorders. There is a consensus concerning the symptoms of depression. The two most widely used diagnostic systems are the World Health Organization's International Classification of Diseases and Related Health Problems, currently in its tenth revision (ICD-10), and the American Psychiatric Association's Diagnostic and Statistical Manual of Mental Disorders, currently in its fifth edition (DSM-5). The criteria used by these classification systems are broadly similar, although the symptom thresholds differ. The DSM-5 criteria are used as the basis for clinical descriptions of depression and the related disorders considered in this book, as the majority of research and the most recent clinical guidelines that inform knowledge about depression and its management use the DSM criteria.
The cardinal features of low mood and diminished interest are central to the condition; at least one of these has to be present for a diagnosis to be made. A minimum number of additional depressive symptoms must also be present, such that at least five of the group of nine symptoms are present in total (Table 2.1). Major depression needs to be distinguished from normal bereavement where similar symptoms may occur; however, a major depressive episode in addition to the normal response to a significant loss may be considered. A diagnosis of depression is excluded if the symptoms are judged to be due to the direct physiological effects of a medical illness or prescribed or illicit medications. Single episode or recurrent. A generation ago, standard psychiatry texts typically considered depression as an acute illness best managed by specialist treatment. The findings of longitudinal observational studies have increasingly revealed the variability of illness course and show that, for many people, depression has a lifelong episodic course, characterized by relapses. There is consistent evidence from population-based studies (as well as primary and specialist care samples) that around 50% of people who have an initial depressive episode will have further episodes.
National data have demonstrated an alarming increase in the prevalence of diabetes mellitus in the developed world. According to the US 2011 National Diabetes Fact Sheet, the prevalence of diabetes in the US population is 8.3%, with estimates ranging from 5.8% in Vermont to 11.3% in Mississippi. Prevalence varies from 7.1% in non-Hispanic whites to 12.6% in non-Hispanic blacks (with even higher rates in Mexican Americans). This equates to 18.8 million people with diabetes (and 7.0 million with undiagnosed diabetes). Data from Diabetes UK reveals that 4.45% of the UK population had diabetes in 2011, equating to 2.9 million people. This figure is expected to grow to 5 million people by 2025. With increasing urbanization in India there has been an explosive increase in the prevalence of diabetes, which has now reached 8.0%, with 50 million people with type 2 diabetes. In China, diabetes has become a major public health problem, with an estimated prevalence of 9.7%.
Globally, most people with diabetes are in the age range 40-59 years, a time in which productivity at work and contribution to family life is anticipated. Illness, disability and premature death in this age group profoundly affect personal and family life, communities and national productivity. IDF data show that preventable complications of diabetes account for an additional 23 million years of life lost through disability and reduced quality of life.
In terms of the population-based burden of diabetes, China has the highest number of people affected, based on 2013 data collected by the IDF, followed by India and the USA (Table 1.2). Rapid changes in lifestyle associated with westernization have led to large increases in the prevalence of diabetes throughout Asia. Of concern, recent data show no sign that the rate is slowing. People of Asian descent develop diabetes at lower degrees of obesity and at younger ages. There are also data to suggest Asian people suffer longer from diabetes complications and die earlier than people in other regions. An accelerating factor appears to be childhood obesity, which is increasing at alarming rates in Asia.
Type 1 diabetes develops in about 79 000 children under the age of 14 every year. Recent data indicate the rate of new cases of type 1 diabetes is increasing by 3% every year, promoted by, among other factors, escalating rates of childhood obesity. About 25% of all cases of type 1 diabetes are in South East Asia, with about 20% in Europe. Finland, Sweden and Norway have the highest incidence of type 1 diabetes. Rates of type 1 diabetes also appear to be increasing in eastern European countries. The rate of type 2 diabetes is also increasing in children, though more data are required.
Relapsed and refractory PTCL are associated with dismal outcomes, with median overall survival (OS) of 5.3 months reported in a population-based retrospective series of 163 patients from British Columbia. A recent prospective international registry study (the T Cell Project) reported survival outcomes from 633 patients with relapsed or refractory disease following frontline therapy: median OS was 11 months for those with relapsed disease and 5 months for those with refractory disease. Only 16% of this large cohort proceeded to stem cell transplantation. Given these outcomes, treatment within a clinical trial is recommended for patients with relapsed or refractory PTCL. Several novel agents have recently been approved for the treatment of relapsed and refractory PTCL, and studies are defining how these agents are best used (id est as monotherapy or in combination) to improve survival outcomes.
Relapsed and refractory PTCL are associated with dismal outcomes, with median overall survival (OS) of 5.3 months reported in a population-based retrospective series of 163 patients from British Columbia. A recent prospective international registry study (the T Cell Project) reported survival outcomes from 633 patients with relapsed or refractory disease following frontline therapy: median OS was 11 months for those with relapsed disease and 5 months for those with refractory disease. Only 16% of this large cohort proceeded to stem cell transplantation. Given these outcomes, treatment within a clinical trial is recommended for patients with relapsed or refractory PTCL.
Relapsed and refractory PTCL are associated with dismal outcomes, with median overall survival (OS) of 5.3 months reported in a population-based retrospective series of 163 patients from British Columbia. A recent prospective international registry study (the T Cell Project) reported survival outcomes from 633 patients with relapsed or refractory disease following frontline therapy: median OS was 11 months for those with relapsed disease and 5 months for those with refractory disease. Only 16% of this large cohort proceeded to stem cell transplantation. Given these outcomes, treatment within a clinical trial is recommended for patients with relapsed or refractory PTCL.
Decisions on the treatment of relapsed or refractory PTCL should first consider whether a patient is a candidate for potentially curative allogeneic stem cell transplantation (see Chapter 7). For these patients the National Comprehensive Cancer Network guidelines recommend either multi- or single-agent chemotherapy for salvage. Patients who are not candidates for transplant should receive single-agent therapy to provide palliative benefit with minimal toxicity. Multi-agent chemotherapy regimens for PTCL include conventional lymphoma salvage regimens such as ICE, DHAP and ESHAP (Table 6.1). Gemcitabine-based regimens have also shown activity, including GDP, GVD and GemOx. Single agents. Single agents approved for relapsed or refractory PTCL include pralatrexate, romidepsin and belinostat. Chidamide is a histone deacetylase (HDAC) inhibitor only approved in China and mogamulizumab is approved for human T-cell lymphotropic virus 1 (HTLV-1)-associated ATLL in Japan. Response rates seen with these treatments are presented in Table 6.2 and their administration and adverse effects in Table 6.3.
Brentuximab vedotin is an immunoconjugate comprising a humanized CD30-specific antibody and the microtubule disrupting agent methylauristatin E (MMAE). It binds to the CD30 receptor and is internalized, where it liberates the MMAE fragment into the cytosol to disrupt the microtubule network and induce apoptosis. CD30 is expressed to a varying degree in PTCL, including in about 50% of PTCL-NOS cases, 20% of AITL, and most cases of EATL and ALCL (ALK − and ALK +). It is also thought that small amounts of MMAE are released by tumor cells and affect the tumor microenvironment, potentially explaining the activity of brentuximab vedotin in malignancies with low levels of CD30 expression. Efficacy and dosage. Brentuximab vedotin is approved in the USA for use in combination with chemotherapy (CHP + A) for previously untreated CD30-expressing subtypes of PTCL, irrespective of the degree of expression of CD30. In Europe, it is approved only for relapsed and refractory systemic ALCL. The standard dose is 1.8 mg/kg every 3 weeks.
Advances in the management of heart failure (HF) over the past 20 years have been informed by a better understanding of its pathophysiology. There are few situations in cardiology where treatment has been as closely linked to an appreciation of the underlying science. Vicious cycle of heart failure. HF is a disease of inappropriate adaptation to injury. The body has a limited range of compensatory responses to circulatory impairment, mainly vasoconstriction and sodium and water retention (see below). In general, however, these adjustments to hypovolemia are poorly suited to pump failure, and increases in the preload and afterload of the failing heart lead to worsening HF (Figure 2.1). Neurohormonal pathways activated in HF include the sympathetic nervous system (SNS), the renin-angiotensin-aldosterone system (RAAS) and the natriuretic peptide (NP) system. They play a significant role in the pathophysiology of HF, and pharmacological interventions have been developed accordingly (see Chapter 7).
Vicious cycle of heart failure. HF is a disease of inappropriate adaptation to injury. The body has a limited range of compensatory responses to circulatory impairment, mainly vasoconstriction and sodium and water retention (see below). In general, however, these adjustments to hypovolemia are poorly suited to pump failure, and increases in the preload and afterload of the failing heart lead to worsening HF (Figure 2.1).
Natriuretic peptide system. The natriuretic peptide family consists of A (atrial) and B (brain) type natriuretic peptides (ANP and BNP), which are produced by cardiomyocytes in response to atrial and ventricular stretch, and C type natriuretic peptide, which is secreted by endothelial and renal cells. NPs, mainly BNP, lead to increased sodium excretion and vasodilation, especially in the early phases of HF. BNP also has anti-remodeling properties. The biological action of BNP is mediated through membrane-bound natriuretic peptide receptors (NPRs) and the peptide is degraded by neutral endopeptidase (including neprilysin). It is postulated that HF is a state of relative BNP deficiency caused by both lack of biologically active peptide and resistance at a receptor level. In end-stage HF, the peptides may not be released because of myocyte loss.
Peripheral vasoconstriction, as described above, symptomatically may contribute to cold sensitivity. Loss of skeletal muscle is an important manifestation of HF, reflecting inactivity, consequences of circulating substances such as tumor growth factor (TGF)-beta and reduced cardiac output. In its most advanced manifestation, loss of skeletal muscle may lead to cachexia. The consequences of this process include contributions to insulin resistance as well as loss of the skeletal muscle circulatory bed. The loss of this vasculature represents an additional decrement in the amount of vasculature that can undergo vasodilation (and therefore unload the LV). Cardiorenal interactions. Reduced renal perfusion in HF (due to reduced stroke volume and vasoconstriction) is an important contributor to sodium and fluid overload. The exact links between cardiac and renal function have yet to be resolved. More marked disturbances of renal function, leading to coexisting renal failure, may also occur and pose problems for volume control.
Cardiorenal interactions. Reduced renal perfusion in HF (due to reduced stroke volume and vasoconstriction) is an important contributor to sodium and fluid overload. The exact links between cardiac and renal function have yet to be resolved. More marked disturbances of renal function, leading to coexisting renal failure, may also occur and pose problems for volume control. Clinical stages and functional classes. The clinical syndrome of HF represents the final manifestation of advanced disease. Although progress has been made in the management of this entity, the greatest hope of avoiding the adverse outcome of HF is to intervene at an earlier subclinical stage, when there is more likelihood of reversing the process. The American Cardiology Association (ACC)/American Heart Association (AHA) guidelines divide progression of the disease into four preclinical and clinical stages (Table 2.1). It is important to distinguish these from functional classes, as described in the New York Heart Association (NYHA) classification system, which is based on severity of symptoms and exercise capacity and can be used to assess response to treatment (see Table 2.1). ACC/AHA stages A and B are preclinical; these patients fall into NYHA functional class I. ACC/AHA stage C reflects patients with symptoms or signs of HF, so these patients may be classified functionally in any of the NYHA classes I to III. The functional status of patients in ACC/AHA class D (with marked symptoms and signs of HF) is usually limited (NYHA class II to IV). The association between functional class, cardiac function (LVEF) and prognosis is discussed in more detail in Chapter 9.
Initial assessment should include a thorough history (see Table 3.1, page 19) and take into account clinical presentation, extent and overall severity of the patient's acne (graded using a system such as The Leeds Acne Grading Scale; see Chapter 3). The type of treatment may be dictated by the predominant type of lesion, so good lighting is required for the physical examination in order to detect non-inflamed lesions, which can easily be missed. Clinicians must also take into consideration the psychosocial effects of the condition, using questionnaires such as Assessment of the Psychosocial Effects of Acne (APSEA), the Cardiff Acne Diability Index (CADI) or the Dermatology Life Quality Index (DLQI) (see Chapter 4), along with the presence of and potential for scarring, and failure to respond to previous therapy.
Dispel myths. Dispelling popular myths about acne can have a positive effect on a person's motivation to cope with the condition, improve adherence to treatment and stop the patient from adopting unnecessary or potentially harmful behavior (see page 17). Myths about the disease should be dispelled in a frank and thorough discussion with the patient. For example, certain foods do not cause acne, acne is not infectious and excessive washing does not help manage the disease (see Table 8.1). Inform about treatment duration and response. It should be stressed that acne is a chronic disease and that no response will be seen before a minimum of 4 weeks of therapy. This is especially important for teenage patients, who often become discouraged if results are not seen quickly despite the fact that they have been following their prescribed regimen.
In all cases, the choice of a specific agent or agents should depend on the type and severity of acne lesions as well as the presence of scarring and/or psychological disability. Clinicians should seek to achieve maximum efficacy and tolerability with minimum risk of adverse effects. With the exception of early comedonal acne in prepubertal children, it is rare for a patient to present with a single type of acne lesion. For this reason, combination therapy is the mainstay of acne treatment. For example, different topical therapies may be alternated morning and evening, or formulations containing a stable combination of products may be prescribed. Therapeutic agents should be chosen to match the type and severity of lesions observed in each individual patient.
Prevention. Early treatment of acne is likely, although not proven, to prevent or modify development of the disease; thus, early use of appropriate topical therapy in mild acne (see below) may well prevent development of moderate acne. Recognizing predictive factors for severity (see page 38) is important. A family history of acne and scarring should be taken into account when implementing therapy to prevent significant disease. Scarring has been shown to develop with more prolonged disease and the duration of inflammation appears to be relevant. Hence, early targeted therapy is associated with better prognosis.
Oral antibiotics. Second-generation tetracycline antibiotics (see pages 59-64) should be the systemic treatment of choice for those patients who can tolerate them. Second-generation tetracyclines are absorbed more rapidly, are more rapidly efficacious and achieve better adherence than first-generation tetracyclines. They are usually administered as capsules. If minocycline is used (not as first-line treatment, see pages 61-2), it is available as aqueous film-coated tablets. Patients who crush their tablets because they are unable to swallow entire pills may not absorb an adequate amount of antibiotic. Minocycline is thought to be associated with the lowest incidence of P. acnes resistance but development of resistance to oral tetracyclines is a potential problem in patients with acne. Resistance should be suspected if a patient's acne fails to respond, or improves then worsens after 3 months of treatment. In such cases, an alternative agent should be chosen. Erythromycin is now used only as a substitute for tetracyclines in women who 'may become' pregnant. The third-line treatment is oral trimethoprim (see page 65). Maintenance therapy. Global overutilization of antibiotics and the resulting emergence of antibacterial resistance (see pages 91-3) have led to calls to limit the use of oral antibiotics in acne treatments. Three well-designed trials indicate that the benefit achieved with a 12-week course of antibiotics plus a retinoid or retinoid/BPO fixed combination can be maintained with continued use of the retinoid or retinoid/BPO combination after the course of antibiotics. This approach limits the long-term use of antibiotics, thus minimizing the ongoing selective pressure for development of antibiotic-resistant strains of bacteria. Since microcomedones are thought to be the precursor lesions of both inflammatory and non-inflammatory acne, a topical retinoid regimen aimed at reducing microcomedones may be useful as maintenance therapy following treatment with oral antibiotics or isotretinoin (see below).
Young men with highly inflammatory or cystic acne are at particular risk of developing a severe flare, and in some cases exuberant lesions similar to pyogenic granulomas may develop. It is strongly recommended that patients with severe inflammatory cystic acne who are at risk of complications such as these be referred to a dermatologist for treatment with isotretinoin and possibly a concomitant course of oral corticosteroids. Successful use of isotretinoin requires careful patient selection and education, personalization of the dosage (according to factors such as age, sex and bodyweight) and appropriate monitoring and follow-up on the part of an experienced dermatologist. Patients should be given immediate access to a dermatologist if any problem with therapy arises or if they fail to respond adequately to the drug. Expected response. Since its inception, the use of oral isotretinoin treatment has been responsible for a dramatic improvement in the appearance and psychological wellbeing of numerous individuals affected by moderate-to-severe acne. By the end of an adequate course of treatment, acne will have cleared in the majority of patients.
Young men with highly inflammatory or cystic acne are at particular risk of developing a severe flare, and in some cases exuberant lesions similar to pyogenic granulomas may develop. It is strongly recommended that patients with severe inflammatory cystic acne who are at risk of complications such as these be referred to a dermatologist for treatment with isotretinoin and possibly a concomitant course of oral corticosteroids. Successful use of isotretinoin requires careful patient selection and education, personalization of the dosage (according to factors such as age, sex and bodyweight) and appropriate monitoring and follow-up on the part of an experienced dermatologist. Patients should be given immediate access to a dermatologist if any problem with therapy arises or if they fail to respond adequately to the drug.
Young men with highly inflammatory or cystic acne are at particular risk of developing a severe flare, and in some cases exuberant lesions similar to pyogenic granulomas may develop. It is strongly recommended that patients with severe inflammatory cystic acne who are at risk of complications such as these be referred to a dermatologist for treatment with isotretinoin and possibly a concomitant course of oral corticosteroids.
Management of advanced and metastatic disease. A core principle in the management of solid tumors is to consider control of both the primary and metastatic disease. Several clinical scenarios occur in bladder cancer. Cancers that are clearly confined to the bladder can potentially be cured if the primary tumor can be removed or ablated, through surgery, radiation therapy or multimodality approaches, and there is no metastatic disease; 5-year survival rates are about 70%. Management of these cancers is discussed in chapter on 'Management of non-muscle-invasive disease'.
Locally advanced cancers and tumors that have spread to loco-regional lymph nodes are associated with an increased risk of local relapse and a higher risk of micrometastatic disease at diagnosis. Five-year survival is about 35%. Lymph node involvement is identified through lymph node dissection or accurate imaging. The primary cancer may still be amenable to local therapy, and is potentially curable in the absence of distant metastases. Optimum systemic therapy with cisplatin-based chemotherapy is standard of care for patients with adequate renal function who are suitable for chemotherapy.
Locally advanced cancers and tumors that have spread to loco-regional lymph nodes are associated with an increased risk of local relapse and a higher risk of micrometastatic disease at diagnosis. Five-year survival is about 35%. Lymph node involvement is identified through lymph node dissection or accurate imaging. The primary cancer may still be amenable to local therapy, and is potentially curable in the absence of distant metastases. Optimum systemic therapy with cisplatin-based chemotherapy is standard of care for patients with adequate renal function who are suitable for chemotherapy.
Cancers predominantly involving the bladder but where there is small-volume overt metastatic disease are unlikely to be cured with currently available modalities; treatment is therefore palliative in intent, which must be clearly understood from the outset. Five-year survival for patients with metastatic disease is approximately 5%, although this varies depending on the bulk of disease, response to therapy and patient factors, including comorbidities. The mainstay of therapy is systemic treatment to control the progression of metastatic disease although management of the primary cancer may be necessary to alleviate symptoms and to prevent future complications such as pain, intractable hematuria and upper urinary tract obstruction. Surgery or radiation therapy may therefore be necessary for management of the primary tumor, and sometimes for management of metastatic disease.
Cancers predominantly involving the bladder but where there is small-volume overt metastatic disease are unlikely to be cured with currently available modalities; treatment is therefore palliative in intent, which must be clearly understood from the outset. Five-year survival for patients with metastatic disease is approximately 5%, although this varies depending on the bulk of disease, response to therapy and patient factors, including comorbidities. The mainstay of therapy is systemic treatment to control the progression of metastatic disease although management of the primary cancer may be necessary to alleviate symptoms and to prevent future complications such as pain, intractable hematuria and upper urinary tract obstruction. Surgery or radiation therapy may therefore be necessary for management of the primary tumor, and sometimes for management of metastatic disease.
Cancers predominantly involving the bladder but where there is small-volume overt metastatic disease are unlikely to be cured with currently available modalities; treatment is therefore palliative in intent, which must be clearly understood from the outset. Five-year survival for patients with metastatic disease is approximately 5%, although this varies depending on the bulk of disease, response to therapy and patient factors, including comorbidities. The mainstay of therapy is systemic treatment to control the progression of metastatic disease although management of the primary cancer may be necessary to alleviate symptoms and to prevent future complications such as pain, intractable hematuria and upper urinary tract obstruction. Surgery or radiation therapy may therefore be necessary for management of the primary tumor, and sometimes for management of metastatic disease.
Cancers predominantly involving the bladder but where there is small-volume overt metastatic disease are unlikely to be cured with currently available modalities; treatment is therefore palliative in intent, which must be clearly understood from the outset. Five-year survival for patients with metastatic disease is approximately 5%, although this varies depending on the bulk of disease, response to therapy and patient factors, including comorbidities. The mainstay of therapy is systemic treatment to control the progression of metastatic disease although management of the primary cancer may be necessary to alleviate symptoms and to prevent future complications such as pain, intractable hematuria and upper urinary tract obstruction. Surgery or radiation therapy may therefore be necessary for management of the primary tumor, and sometimes for management of metastatic disease.
The treatment of metastatic bladder cancer was transformed following publication of a randomized Phase III trial comparing MVAC versus gemcitabine and cisplatin (GC)., The study was somewhat ambitiously designed to demonstrate a 33% improvement in OS with GC, rather than as an equivalence or non-inferiority study. The survival curves for the two regimens were similar, and the trial did not meet its primary endpoint. However, GC was found to be better tolerated than MVAC and was adopted as standard of care for the treatment of metastatic disease. GC has become the de facto standard for trials in other settings, even though this is not supported by high-level evidence. Modifications to the regimen are frequently made (often with little supporting evidence), such as splitting the dose of cisplatin, dropping treatment weeks or shortening treatment cycles, modifying the gemcitabine dosage, or substitution with drugs such as carboplatin. It is important to recognize when and how far we should go beyond high-level evidence when making treatment decisions with patients.
Traditional clinical trials collect snippets of data when a participant visits the study site and represent a tiny snapshot of patients' lived experience with a disease or condition. Yet researchers, industry sponsors and regulators rely on this limited information to make life-or-death decisions and multibillion-dollar investments. Digital measurements will convert that snapshot into a movie, with the ability to collect near continuous data outside the physical confines of the clinical environment, such as in a person's home, using connected products, including smartphones, wearables, implantables and ingestible devices and sensors. Decentralized clinical trials. Digital tools enable new forms of research such as decentralized clinical trials (DCTs), which are conducted outside of the clinic to capture data about a study participant in their day-to-day life (Figure 8.2). DCTs have a number of potential benefits, including faster participant recruitment, improved participant retention in the trial, greater control and convenience for participants, increased diversity (exempli gratia because it is easier to enroll in the first place) and trial results that are more generalizable. ,3.
Decentralized clinical trials. Digital tools enable new forms of research such as decentralized clinical trials (DCTs), which are conducted outside of the clinic to capture data about a study participant in their day-to-day life (Figure 8.2). DCTs have a number of potential benefits, including faster participant recruitment, improved participant retention in the trial, greater control and convenience for participants, increased diversity (exempli gratia because it is easier to enroll in the first place) and trial results that are more generalizable. ,3. DCTs offer a way to make better-informed decisions about the efficacy of new therapies. More sensitive, objective measures from digital technologies coupled with a greater density of information - continuously sampling multiple times a day, not just once a quarter - will help the industry fail faster and win more efficiently.
Two features of data collection determine how 'decentralized' a clinical trial is: where and how the data are collected. Where are data collected? In traditional clinical trials, drugs, devices and therapies are administered in a clinic or research hospital. In newer direct-to-patient or remote trials, participant data are collected in the home or in the study participant's natural environment. How are the data collected? In the past, most data were collected via an intermediary - someone from the team would record information in a custom software system and/or case report form. As digital tools advance, we can collect more endpoint-supporting data at home via digital surveys and sensors, and study teams can 'visit' patients at home via telemedicine conference calls. This means that more of the data are participant-generated and collected 'virtually', without an intermediary. In context. A doctor who remote teleconferences with a patient would be conducting a 'remote trial', but they might collect the data manually through a survey, so the study would not be considered a 'virtual trial'. In contrast, a study team might collect all the data passively from a smartwatch in a clinic, and this study would be a 'virtual trial' from a data collection perspective, but not a 'remote trial' because the patient is in a centralized location.
What are real-world data?. Real world is a term that is important to define as it is often misused. The regulatory definition of real-world data is the data collected outside of a traditional clinical study, such as a randomized controlled trial (RCT). These data sources include electronic health records (EHRs), claims and billing activities, product and disease registries, patient-generated data including in home-use settings, and data gathered from other sources that can inform on health status, such as mobile technologies. Real-world evidence is the evidence derived from real-world data. In the context of a traditional RCT, if study participants contribute to some measurements at home, such as pain measurement via an electronic patient-reported outcome (ePRO) or step count from a wearable sensor, many often mistakenly believe this would constitute real-world data. However, these measures would not constitute real-world data because the participants have been preselected for study entry by the inclusion and exclusion criteria of a given trial. They do not represent the overall population in a certain indication. Therefore, when working with clinical research, it is important to focus on the benefits of health-related data collected in natural settings - which may not be classified as 'real world' by a strict regulatory definition.
The aggressive B-cell lymphomas (also known as high-grade B-cell lymphomas) include diffuse large B-cell lymphoma (DLBCL), mediastinal large B-cell lymphoma, Burkitt lymphoma, and lymphoblastic lymphoma or acute lymphoblastic leukemia (see page 80). It can sometimes be difficult for pathologists to distinguish DLBCL from Burkitt lymphoma. Another subtype of lymphoma has therefore been identified, known for now as 'aggressive B-cell lymphoma with features intermediate between DLBCL and Burkitt lymphoma'. Other terms sometimes used for particularly aggressive types of DLBCL include ' c-Myc -positive DLBCL' and 'double hit' and 'triple hit' lymphomas, depending on the number of BCL2 and MYC translocations. Left untreated, these tumors can rapidly be fatal. Treatment aims to provide a cure. Relapse is associated with a poor prognosis.
The aggressive B-cell lymphomas (also known as high-grade B-cell lymphomas) include diffuse large B-cell lymphoma (DLBCL), mediastinal large B-cell lymphoma, Burkitt lymphoma, and lymphoblastic lymphoma or acute lymphoblastic leukemia (see page 80). It can sometimes be difficult for pathologists to distinguish DLBCL from Burkitt lymphoma. Another subtype of lymphoma has therefore been identified, known for now as 'aggressive B-cell lymphoma with features intermediate between DLBCL and Burkitt lymphoma'. Other terms sometimes used for particularly aggressive types of DLBCL include ' c-Myc -positive DLBCL' and 'double hit' and 'triple hit' lymphomas, depending on the number of BCL2 and MYC translocations. Left untreated, these tumors can rapidly be fatal. Treatment aims to provide a cure. Relapse is associated with a poor prognosis.
The most common aggressive lymphoma is DLBCL, which accounts for approximately 30% of all cases of non-Hodgkin lymphoma (NHL). Typically, the cells are large (Figure 5.1) and express B-cell markers. While there are a few recurring cytogenetic and molecular abnormalities, they are not particularly helpful diagnostically (Table 5.1). Importantly for treatment, most DLBCL express CD20, which is the target for rituximab. The condition may present at any age, but is increasingly common in later life. Pathology. The most common finding is sheets of large cells, which stain with the B-cell markers CD19, CD79a and CD20. Molecular profiling using expression microarrays (see page 37) has identified two main types of DLBCL, namely those derived from germinal-center B cells (GCB subtype) and those derived from a more differentiated stage in the B-cell life cycle - activated B-cell (ABC) type.
Relapse or progressive disease. The prognosis for patients who relapse after treatment is generally poor, with only 20-30% of patients rescued with salvage/relapse protocols. Most patients destined to relapse will do so in the first 2 years after initial treatment. Salvage protocols vary, but are usually based on regimens containing platinum. The key consideration is response, because patients achieving a satisfactory response may then benefit from high-dose therapy and peripheral stem-cell rescue (Figure 5.2). The following salvage/relapse regimens are used.
As most readers will be aware, there are a number of different corticosteroid preparations but experts have not reached consensus on what dose or which particular agent should be used for a given OA joint. Methylprednisolone and triamcinolone are commonly used, the latter being a more potent steroid, although few data exist on whether this provides any clinically significant differences in outcome. In general, a greater dose of drug is given into a large joint (exempli gratia methylprednisolone, 80 mg for the knee versus 10 mg in the base of the thumb).
Platelet-rich plasma (PRP) injections for hip and knee OA have increased in popularity over the last few years. PRP is an autologous blood product with concentrated platelets that contains various growth factors and cytokines. A recent review including 15 randomized controlled trials found that these injections appear to be safe, and may provide some short-term symptomatic benefit. However, the trials were all of low to moderate quality, used a variety of different protocols and preparations of PRP, and did not assess structural benefit or harms or longer-term outcomes. To date, given the lack of high-quality evidence to support its use, PRP is not recommended in any clinical guideline.
The second-generation EGFR TKI afatinib has also been shown to be more effective than chemotherapy in patients with EGFR mutations., More recently, patients receiving the third-generation EGFR TKI osimertinib have been shown to have a higher PFS (18.9 months versus 10.2 months) and a lower number of high-grade adverse events compared with those taking first-generation TKIs. ALK rearrangements occur in a limited number of patients with advanced stage NSCLC (3-5%). Despite the low number, patients with an ALK fusion have been shown to respond well to the first-generation anaplastic lymphoma kinase (ALK)- fusion TKI crizotinib when compared with chemotherapy (PFS 10.9 months versus 7.0 months and objective response rate [ORR] 74% versus 45%), with a significant improvement in quality of life.
The second-generation EGFR TKI afatinib has also been shown to be more effective than chemotherapy in patients with EGFR mutations., More recently, patients receiving the third-generation EGFR TKI osimertinib have been shown to have a higher PFS (18.9 months versus 10.2 months) and a lower number of high-grade adverse events compared with those taking first-generation TKIs. ALK rearrangements occur in a limited number of patients with advanced stage NSCLC (3-5%). Despite the low number, patients with an ALK fusion have been shown to respond well to the first-generation anaplastic lymphoma kinase (ALK)- fusion TKI crizotinib when compared with chemotherapy (PFS 10.9 months versus 7.0 months and objective response rate [ORR] 74% versus 45%), with a significant improvement in quality of life.
BRAF p.V600E. Identification of the BRAF p.V600E mutation is increasingly important as it supports treatment with dabrafenib plus trametinib in advanced stage NSCLC. Programmed death-ligand 1. In addition to the must test genes, the guidelines (see above) strongly recommend evaluating PD-L1 expression to inform immunotherapy decisions.
Primary breast cancer. Besides the classic biomarkers used by pathologists in every case of primary breast cancer, such as estrogen receptor (ER), progesterone receptor (PR) and HER2, which guide prognostication and treatment selection, gene expression profile assays have recently been incorporated into the biomarker assessment of early breast cancer. Commercially available genomic assays that provide these profiles include Oncotype DX, MammaPrint, Predictor Analysis of Microarrays 50 (PAM50), EndoPredict and Breast Cancer Index. Data from two large randomized clinical trials examining Oncotype DX and MammaPrint have yielded important evidence for use in discussions about potential benefit from chemotherapy in specific patient populations. When using the Oncotype DX assay, chemotherapy is not recommended for patients older than 50 years whose tumors have a recurrence score of less than 26. For those patients younger than 50 years whose tumors have a recurrence score of less than 16, there is little to no benefit from chemotherapy; however, clinicians may offer chemoendocrine therapy to those with a recurrence score in the range 16-25. In addition, oncologists may offer chemoendocrine therapy to any patient with recurrence score of 26-30. There are many guidelines published concerning the use of these assays.
The genomic landscape of mBC is broad; alterations in multiple genes have been found, many with potentially actionable changes. Here, we will discuss only those classified as tier I-A (prospective randomized clinical trials show the alteration-drug match in a specific tumor type results in a clinically meaningful improvement in a survival endpoint) according to the ESMO Scale for Clinical Actionability of molecular Targets (ESCAT) or level 1 (FDA-recognized biomarker predictive of response to an FDA-approved drug in this indication - see Chapter 4) by the precision oncology knowledge base OncoKB., These are PIK3CA mutations, germline BRCA1 / mutations, HER2 amplification, MSI and NTRK translocations. PIK3CA codes for the catalytic subunit of PI3K. A gain-of-function mutation can cause the activation of multiple downstream signaling cascades, including the PI3K/AKT/mTOR pathway that promotes cell survival and proliferation (see Figure 1.6). The Phase III randomized SOLAR-1 trial compared the combination of the PI3K inhibitor alpelisib and fulvestrant with fulvestrant alone in patients with HR-positive HER2 -negative mBC who had progressed on prior endocrine therapy. Participants receiving alpelisib-fulvestrant had superior PFS compared with those receiving fulvestrant alone, leading the FDA to approve alpelisib for HR-positive mBC. These findings stress the importance of clinical testing for the PIK3CA mutation in patients with HR-positive mBC who experience progression on first-line endocrine therapy. Alpelisib is now also authorized for use in the EU.
chromosomal instability (CIN), which accounts for around 85% of all CRCs. MSI, which accounts for around 15% of CRCs. CpG island methylator (CIMP), which is found in 17% of CRCs and shows overlap with the MSI pathway. Chromosomal instability is characterized by alterations in chromosomes 17p and 18q. In addition, the tumors acquire mutations in oncogenes and tumor suppressors including APC, TP53, KRAS and BRAF. According to the Vogelstein model, there is initial inactivation of APC, followed by mutations of RAS with inactivation of the TP53 suppressor gene. The most clinically relevant pathways affected are the Wnt and MAPK pathways. Alterations in the Wnt signaling pathway, which occur in 93% of all CRC tumors, lead to cell proliferation. The MAPK pathway is activated by RTKs, such as EGFR, though it can be activated by other downstream signaling molecules, such as KRAS proto-oncogene, GTPase (KRAS), NRAS proto-oncogene, GTPase (NRAS) and BRAF, as well as ERK.
CpG island methylator phenotype. The CIMP pathway is characterized by hypermethylation of CpG island loci and inactivation of suppressor genes. Sporadic MSI CRCs are associated with CIMP-associated methylation of the MLH1 promoter which, in turn, is associated with the presence of BRAF mutation. NGS testing for predictive biomarkers. EGFR activation of the RAS/RAF/MEK/ERK pathway (see Chapter 1) plays an important role in oncogenesis in CRC. Up to 50% of CRCs show activating mutations of KRAS. Anti-EGFR antibodies, such as cetuximab and panitumumab, can be beneficial in patients with metastatic CRC provided that there is no downstream mutation activating the RAS/RAF/MEK/ERK pathway. Initially, patients with codon 12/13 KRAS mutations did not benefit in clinical trials, and subsequently mutations in other codons of KRAS and in NRAS were also shown to confer resistance to antibody-based therapies., Thus, guidelines require an 'extended' RAS analysis be performed. At present, the minimum testing required to determine whether anti-EGFR therapy may be of benefit is this extended RAS testing of KRAS and NRAS.
Melanoma is a highly mutated malignancy, with mutations documented in all subtypes (Table 5.3)., The KIT mutation is associated with chronic sun damage. The BRAF mutation is present in 11% of patients with mucosal melanoma, NRAS mutation in 5% and KIT mutation in 15-20%. From a molecular point of view, uveal melanoma is a distinct condition characterized, in 50% of patients, by the presence of a GNAQ mutation. The presence of BRAF and NRAS mutations has not been described in uveal melanoma. The serine/threonine kinase BRAF is involved in the downstream signaling of the RTK and RAS proteins. Approximately half of melanomas show BRAF point mutations (Figure 5.2). In the majority of cases, a valine at position 600 is mutated to glutamic acid or lysine (BRAF p.V600E and BRAF p.V600K); both mutations are associated with kinase activation that results from relieving an intramolecular autoinhibitory interaction between the activation segment and P-loop of the protein.
BRAF inhibitors can lead to remarkable early tumor responses in melanoma, though these may be of short duration in some patients. Approximately 20% of patients with mutant BRAF melanoma show no response, and most patients treated with monotherapy relapse, with a median PFS of 8-9 months. Vemurafenib is an orally available small molecule kinase inhibitor with activity against BRAF with the p.V600E mutation; its indication is restricted to melanoma patients with a demonstrated BRAF p.V600E mutation by an FDA-approved test. This agent was approved by the FDA in 2011 and by the EMA in 2012. Vemurafenib has shown an improvement in PFS and overall survival in patients with unresectable or advanced melanoma.
c-KIT inhibitors. Early data suggest that mucosal or acral melanomas with activating mutations or amplifications in KIT may be sensitive to a variety of c-KIT inhibitors. BRAF and MEK inhibitors in combination. In 2014, the combination of dabrafenib and trametinib received accelerated approval from the FDA for patients with unresectable or metastatic melanomas that carry the BRAF p.V600E or p.V600K mutation. The combination demonstrated improved durable response rates over single-agent dabrafenib. The treatment combination is also approved for use in the EU.
BRAF and MEK inhibitors in combination. In 2014, the combination of dabrafenib and trametinib received accelerated approval from the FDA for patients with unresectable or metastatic melanomas that carry the BRAF p.V600E or p.V600K mutation. The combination demonstrated improved durable response rates over single-agent dabrafenib. The treatment combination is also approved for use in the EU. In 2015, the combination of vemurafenib and cobimetinib was approved by the FDA and the EMA for metastatic melanomas that carry the BRAF p.V600E or p.V600K mutation.
Gastrointestinal stromal tumors. Around 80% of GISTs show mutations in KIT that result in constitutive activation of the RTK, c-KIT. Most commonly, there is mutation (SNV or indel) of exon 11, then exon 9, followed by exons 13 and 17 (Table 5.5). Up to 50% of KIT -mutation-negative GISTs have activating mutations of the PDGFRA gene, usually in exons 18, 12 and 14.
Initially, imatinib was the drug of choice, but the newer TKIs sunitinib and regorafenib have also shown efficacy, particularly for GISTs resistant to imatinib. Avapritinib was approved by the FDA in early 2020 for GIST harboring a PDGFRA exon 18 mutation, including the D842V mutation, while the kinase inhibitor ripretinib was approved later in the same year as fourth-line therapy for adults with an advanced GIST. Crenolanib, which selectively inhibits PDGFRA mutant protein, particularly that arising from PDGFRA D842 mutation, is in clinical trials for use in patients with GIST., The second- and third-generation TKIs dasatinib, nilotinib and ponatinib, which target BCR - ABL products, have shown limited results.
Molecular targeting in other non-GIST sarcomas. Pazopanib, an oral anti-angiogenic drug targeting vascular endothelial growth factor receptor (VEGFR), PDGFR, fibroblast growth factor receptor (FGFR), c-KIT and many other tyrosine kinases, was associated with improved PFS in patients with soft-tissue sarcomas other than liposarcomas (mainly leiomyosarcoma and synovial sarcoma) in the Phase III PALETTE study. There is, however, no biomarker to guide its use. Other TKIs used for treating GISTs, such sorafenib, sunitinib and regorafenib, have some effect against non-GI sarcomas, particularly in tumors with PDGFRA mutations.

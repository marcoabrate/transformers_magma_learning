{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P95DxvqWi_2Y"
   },
   "source": [
    "#### For Colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 55
    },
    "executionInfo": {
     "elapsed": 661,
     "status": "ok",
     "timestamp": 1611824055179,
     "user": {
      "displayName": "Marco Pietro Abrate",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gjh-8YF-8BlnrkN9mLZ0xfVOWfOh7kYncpYRv-Y=s64",
      "userId": "15422244832836998434"
     },
     "user_tz": -60
    },
    "id": "GD_KFnI1H1ip",
    "outputId": "a266fdea-b5dc-436b-e4a7-1d77e4b82eda"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'\\nfunction ClickConnect(){\\n    console.log(\"Working\");\\n    document.querySelector(\"colab-toolbar-button\").click() \\n}\\nvar i = setInterval(ClickConnect, 900000)\\nclearInterval(i)\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "function ClickConnect(){\n",
    "    console.log(\"Working\");\n",
    "    document.querySelector(\"colab-toolbar-button\").click() \n",
    "}\n",
    "var i = setInterval(ClickConnect, 900000)\n",
    "clearInterval(i)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ja6-0xXdM-RH"
   },
   "source": [
    "First, let's try to get a GPU with at least 15GB RAM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iEIBtKCIM55i"
   },
   "outputs": [],
   "source": [
    "# crash colab to get more RAM\n",
    "!kill -9 -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 891,
     "status": "ok",
     "timestamp": 1611844609366,
     "user": {
      "displayName": "Marco Pietro Abrate",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gjh-8YF-8BlnrkN9mLZ0xfVOWfOh7kYncpYRv-Y=s64",
      "userId": "15422244832836998434"
     },
     "user_tz": -60
    },
    "id": "TuKL2zYwNIzA",
    "outputId": "6bec7f16-9102-4fed-e258-c32696ab6f6e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Jan 28 14:36:48 2021       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 460.32.03    Driver Version: 418.67       CUDA Version: 10.1     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
      "| N/A   73C    P0    32W /  70W |      0MiB / 15079MiB |      0%      Default |\n",
      "|                               |                      |                 ERR! |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1718,
     "status": "ok",
     "timestamp": 1611844612909,
     "user": {
      "displayName": "Marco Pietro Abrate",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gjh-8YF-8BlnrkN9mLZ0xfVOWfOh7kYncpYRv-Y=s64",
      "userId": "15422244832836998434"
     },
     "user_tz": -60
    },
    "id": "RR-OcN_Wy1jE",
    "outputId": "2d60135a-3001-4c46-a060-81358b1d4244"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive', force_remount=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "au5Z9XQAC7C-"
   },
   "outputs": [],
   "source": [
    "drive_dir = '/content/drive/My Drive/MAGMA: Summarization/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "id": "L5sXxqeNCtkN"
   },
   "source": [
    "#### Install Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 12068,
     "status": "ok",
     "timestamp": 1611844626207,
     "user": {
      "displayName": "Marco Pietro Abrate",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gjh-8YF-8BlnrkN9mLZ0xfVOWfOh7kYncpYRv-Y=s64",
      "userId": "15422244832836998434"
     },
     "user_tz": -60
    },
    "hidden": true,
    "id": "m6KSIQlYzjEy",
    "outputId": "5de708dc-7605-4dae-823e-f4fec13071c7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: datasets==1.2.1 in /usr/local/lib/python3.6/dist-packages (1.2.1)\n",
      "Requirement already satisfied: multiprocess in /usr/local/lib/python3.6/dist-packages (from datasets==1.2.1) (0.70.11.1)\n",
      "Requirement already satisfied: dill in /usr/local/lib/python3.6/dist-packages (from datasets==1.2.1) (0.3.3)\n",
      "Requirement already satisfied: pyarrow>=0.17.1 in /usr/local/lib/python3.6/dist-packages (from datasets==1.2.1) (3.0.0)\n",
      "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from datasets==1.2.1) (3.4.0)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from datasets==1.2.1) (1.1.5)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.6/dist-packages (from datasets==1.2.1) (1.19.5)\n",
      "Requirement already satisfied: tqdm<4.50.0,>=4.27 in /usr/local/lib/python3.6/dist-packages (from datasets==1.2.1) (4.41.1)\n",
      "Requirement already satisfied: xxhash in /usr/local/lib/python3.6/dist-packages (from datasets==1.2.1) (2.0.0)\n",
      "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from datasets==1.2.1) (0.8)\n",
      "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.6/dist-packages (from datasets==1.2.1) (2.23.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->datasets==1.2.1) (3.7.4.3)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->datasets==1.2.1) (3.4.0)\n",
      "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas->datasets==1.2.1) (2018.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.6/dist-packages (from pandas->datasets==1.2.1) (2.8.1)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.19.0->datasets==1.2.1) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.19.0->datasets==1.2.1) (2020.12.5)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.19.0->datasets==1.2.1) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.19.0->datasets==1.2.1) (1.24.3)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.7.3->pandas->datasets==1.2.1) (1.15.0)\n",
      "Requirement already satisfied: transformers==4.2.0 in /usr/local/lib/python3.6/dist-packages (4.2.0)\n",
      "Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers==4.2.0) (0.0.43)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers==4.2.0) (4.41.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers==4.2.0) (2019.12.20)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers==4.2.0) (1.19.5)\n",
      "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers==4.2.0) (0.8)\n",
      "Requirement already satisfied: tokenizers==0.9.4 in /usr/local/lib/python3.6/dist-packages (from transformers==4.2.0) (0.9.4)\n",
      "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from transformers==4.2.0) (3.4.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers==4.2.0) (3.0.12)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers==4.2.0) (20.8)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers==4.2.0) (2.23.0)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==4.2.0) (1.15.0)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==4.2.0) (7.1.2)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==4.2.0) (1.0.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers==4.2.0) (3.4.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers==4.2.0) (3.7.4.3)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers==4.2.0) (2.4.7)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==4.2.0) (1.24.3)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==4.2.0) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==4.2.0) (2020.12.5)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==4.2.0) (2.10)\n",
      "Requirement already satisfied: rouge_score in /usr/local/lib/python3.6/dist-packages (0.0.4)\n",
      "Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.6/dist-packages (from rouge_score) (1.15.0)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from rouge_score) (1.19.5)\n",
      "Requirement already satisfied: absl-py in /usr/local/lib/python3.6/dist-packages (from rouge_score) (0.10.0)\n",
      "Requirement already satisfied: nltk in /usr/local/lib/python3.6/dist-packages (from rouge_score) (3.2.5)\n",
      "Requirement already up-to-date: wandb in /usr/local/lib/python3.6/dist-packages (0.10.15)\n",
      "Requirement already satisfied, skipping upgrade: requests<3,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from wandb) (2.23.0)\n",
      "Requirement already satisfied, skipping upgrade: promise<3,>=2.0 in /usr/local/lib/python3.6/dist-packages (from wandb) (2.3)\n",
      "Requirement already satisfied, skipping upgrade: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from wandb) (2.8.1)\n",
      "Requirement already satisfied, skipping upgrade: docker-pycreds>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from wandb) (0.4.0)\n",
      "Requirement already satisfied, skipping upgrade: configparser>=3.8.1 in /usr/local/lib/python3.6/dist-packages (from wandb) (5.0.1)\n",
      "Requirement already satisfied, skipping upgrade: shortuuid>=0.5.0 in /usr/local/lib/python3.6/dist-packages (from wandb) (1.0.1)\n",
      "Requirement already satisfied, skipping upgrade: GitPython>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from wandb) (3.1.12)\n",
      "Requirement already satisfied, skipping upgrade: subprocess32>=3.5.3 in /usr/local/lib/python3.6/dist-packages (from wandb) (3.5.4)\n",
      "Requirement already satisfied, skipping upgrade: protobuf>=3.12.0 in /usr/local/lib/python3.6/dist-packages (from wandb) (3.12.4)\n",
      "Requirement already satisfied, skipping upgrade: PyYAML in /usr/local/lib/python3.6/dist-packages (from wandb) (3.13)\n",
      "Requirement already satisfied, skipping upgrade: psutil>=5.0.0 in /usr/local/lib/python3.6/dist-packages (from wandb) (5.4.8)\n",
      "Requirement already satisfied, skipping upgrade: Click>=7.0 in /usr/local/lib/python3.6/dist-packages (from wandb) (7.1.2)\n",
      "Requirement already satisfied, skipping upgrade: six>=1.13.0 in /usr/local/lib/python3.6/dist-packages (from wandb) (1.15.0)\n",
      "Requirement already satisfied, skipping upgrade: sentry-sdk>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from wandb) (0.19.5)\n",
      "Requirement already satisfied, skipping upgrade: watchdog<0.10.5,>=0.8.3 in /usr/local/lib/python3.6/dist-packages (from wandb) (0.10.4)\n",
      "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.0.0->wandb) (2020.12.5)\n",
      "Requirement already satisfied, skipping upgrade: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.0.0->wandb) (3.0.4)\n",
      "Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.0.0->wandb) (1.24.3)\n",
      "Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.0.0->wandb) (2.10)\n",
      "Requirement already satisfied, skipping upgrade: gitdb<5,>=4.0.1 in /usr/local/lib/python3.6/dist-packages (from GitPython>=1.0.0->wandb) (4.0.5)\n",
      "Requirement already satisfied, skipping upgrade: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.12.0->wandb) (51.3.3)\n",
      "Requirement already satisfied, skipping upgrade: pathtools>=0.1.1 in /usr/local/lib/python3.6/dist-packages (from watchdog<0.10.5,>=0.8.3->wandb) (0.1.2)\n",
      "Requirement already satisfied, skipping upgrade: smmap<4,>=3.0.1 in /usr/local/lib/python3.6/dist-packages (from gitdb<5,>=4.0.1->GitPython>=1.0.0->wandb) (3.0.5)\n",
      "Requirement already up-to-date: sentence-transformers in /usr/local/lib/python3.6/dist-packages (0.4.1.2)\n",
      "Requirement already satisfied, skipping upgrade: tqdm in /usr/local/lib/python3.6/dist-packages (from sentence-transformers) (4.41.1)\n",
      "Requirement already satisfied, skipping upgrade: numpy in /usr/local/lib/python3.6/dist-packages (from sentence-transformers) (1.19.5)\n",
      "Requirement already satisfied, skipping upgrade: scipy in /usr/local/lib/python3.6/dist-packages (from sentence-transformers) (1.4.1)\n",
      "Requirement already satisfied, skipping upgrade: torch>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from sentence-transformers) (1.7.0+cu101)\n",
      "Requirement already satisfied, skipping upgrade: sentencepiece in /usr/local/lib/python3.6/dist-packages (from sentence-transformers) (0.1.95)\n",
      "Requirement already satisfied, skipping upgrade: scikit-learn in /usr/local/lib/python3.6/dist-packages (from sentence-transformers) (0.22.2.post1)\n",
      "Requirement already satisfied, skipping upgrade: transformers<5.0.0,>=3.1.0 in /usr/local/lib/python3.6/dist-packages (from sentence-transformers) (4.2.0)\n",
      "Requirement already satisfied, skipping upgrade: nltk in /usr/local/lib/python3.6/dist-packages (from sentence-transformers) (3.2.5)\n",
      "Requirement already satisfied, skipping upgrade: typing-extensions in /usr/local/lib/python3.6/dist-packages (from torch>=1.6.0->sentence-transformers) (3.7.4.3)\n",
      "Requirement already satisfied, skipping upgrade: future in /usr/local/lib/python3.6/dist-packages (from torch>=1.6.0->sentence-transformers) (0.16.0)\n",
      "Requirement already satisfied, skipping upgrade: dataclasses in /usr/local/lib/python3.6/dist-packages (from torch>=1.6.0->sentence-transformers) (0.8)\n",
      "Requirement already satisfied, skipping upgrade: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->sentence-transformers) (1.0.0)\n",
      "Requirement already satisfied, skipping upgrade: packaging in /usr/local/lib/python3.6/dist-packages (from transformers<5.0.0,>=3.1.0->sentence-transformers) (20.8)\n",
      "Requirement already satisfied, skipping upgrade: tokenizers==0.9.4 in /usr/local/lib/python3.6/dist-packages (from transformers<5.0.0,>=3.1.0->sentence-transformers) (0.9.4)\n",
      "Requirement already satisfied, skipping upgrade: requests in /usr/local/lib/python3.6/dist-packages (from transformers<5.0.0,>=3.1.0->sentence-transformers) (2.23.0)\n",
      "Requirement already satisfied, skipping upgrade: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers<5.0.0,>=3.1.0->sentence-transformers) (2019.12.20)\n",
      "Requirement already satisfied, skipping upgrade: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from transformers<5.0.0,>=3.1.0->sentence-transformers) (3.4.0)\n",
      "Requirement already satisfied, skipping upgrade: filelock in /usr/local/lib/python3.6/dist-packages (from transformers<5.0.0,>=3.1.0->sentence-transformers) (3.0.12)\n",
      "Requirement already satisfied, skipping upgrade: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers<5.0.0,>=3.1.0->sentence-transformers) (0.0.43)\n",
      "Requirement already satisfied, skipping upgrade: six in /usr/local/lib/python3.6/dist-packages (from nltk->sentence-transformers) (1.15.0)\n",
      "Requirement already satisfied, skipping upgrade: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers<5.0.0,>=3.1.0->sentence-transformers) (2.4.7)\n",
      "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers<5.0.0,>=3.1.0->sentence-transformers) (2020.12.5)\n",
      "Requirement already satisfied, skipping upgrade: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers<5.0.0,>=3.1.0->sentence-transformers) (3.0.4)\n",
      "Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers<5.0.0,>=3.1.0->sentence-transformers) (1.24.3)\n",
      "Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers<5.0.0,>=3.1.0->sentence-transformers) (2.10)\n",
      "Requirement already satisfied, skipping upgrade: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers<5.0.0,>=3.1.0->sentence-transformers) (3.4.0)\n",
      "Requirement already satisfied, skipping upgrade: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers<5.0.0,>=3.1.0->sentence-transformers) (7.1.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install datasets==1.2.1\n",
    "!pip install transformers==4.2.0\n",
    "!pip install rouge_score\n",
    "!pip install -U wandb\n",
    "!pip install -U sentence-transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S0FByNNOIRvG"
   },
   "source": [
    "### **Config**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8866,
     "status": "ok",
     "timestamp": 1611844626669,
     "user": {
      "displayName": "Marco Pietro Abrate",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gjh-8YF-8BlnrkN9mLZ0xfVOWfOh7kYncpYRv-Y=s64",
      "userId": "15422244832836998434"
     },
     "user_tz": -60
    },
    "id": "82WSp6khIcua",
    "outputId": "0af4c55a-4adb-4ef9-8083-5f9070ccc804"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mmarcoabrate\u001b[0m (use `wandb login --relogin` to force relogin)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: WANDB_PROJECT=finetune_led\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.insert(0, drive_dir)\n",
    "import config\n",
    "\n",
    "import wandb\n",
    "wandb.login()\n",
    "\n",
    "project_name = 'ft_led_karger_books'\n",
    "%env WANDB_PROJECT=$project_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6Hgw3GTXLLw0"
   },
   "source": [
    "## 🤗 Finetune **Longformer Encoder-Decoder (LED)** on Karger Books 🤗"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W7-QHmRiAMB9"
   },
   "source": [
    "The *Longformer Encoder-Decoder (LED)* was recently added as an extension to [Longformer: The Long-Document Transformer](https://arxiv.org/abs/2004.05150) by Iz Beltagy, Matthew E. Peters, Arman Cohan.\n",
    "\n",
    "We will leverage 🤗`Seq2SeqTrainer`, gradient checkpointing and as usual 🤗`datasets`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0u9twLMqYEzT"
   },
   "source": [
    "Let's start by loading and preprocessing the dataset.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9119,
     "status": "ok",
     "timestamp": 1611844627656,
     "user": {
      "displayName": "Marco Pietro Abrate",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gjh-8YF-8BlnrkN9mLZ0xfVOWfOh7kYncpYRv-Y=s64",
      "userId": "15422244832836998434"
     },
     "user_tz": -60
    },
    "id": "ODLQ8MUJfmi4",
    "outputId": "e4107fa7-7ecf-4e32-f13c-016083e2e5e6",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default\n",
      "Reusing dataset csv (/root/.cache/huggingface/datasets/csv/default-0498b287fc32a431/0.0.0/2960f95a26e85d40ca41a230ac88787f715ee3003edaacb8b1f0891e9f04dda2)\n",
      "Using custom data configuration default\n",
      "Reusing dataset csv (/root/.cache/huggingface/datasets/csv/default-82fd9fd954b5a267/0.0.0/2960f95a26e85d40ca41a230ac88787f715ee3003edaacb8b1f0891e9f04dda2)\n",
      "Using custom data configuration default\n",
      "Reusing dataset csv (/root/.cache/huggingface/datasets/csv/default-acb527b34156b505/0.0.0/2960f95a26e85d40ca41a230ac88787f715ee3003edaacb8b1f0891e9f04dda2)\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset, load_metric\n",
    "train_dataset = load_dataset('csv', data_files=drive_dir+'datasets/karger_books_base/train.csv', split='train')\n",
    "val_dataset = load_dataset('csv', data_files=drive_dir+'datasets/karger_books_base/val.csv', split='train')\n",
    "test_dataset = load_dataset('csv', data_files=drive_dir+'datasets/karger_books_base/test.csv', split='train')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lrwXZ_LBGLwt"
   },
   "source": [
    "We can see that the input data is the `text` - a scientific chapter and the target data is the `bullets` - a concise summary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jpUr9QeebZ-n"
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AddedToken\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"allenai/led-base-16384\")\n",
    "\n",
    "print(len(tokenizer))\n",
    "print(tokenizer.additional_special_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 11000,
     "status": "ok",
     "timestamp": 1611844631489,
     "user": {
      "displayName": "Marco Pietro Abrate",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gjh-8YF-8BlnrkN9mLZ0xfVOWfOh7kYncpYRv-Y=s64",
      "userId": "15422244832836998434"
     },
     "user_tz": -60
    },
    "id": "vnUtPnElMlpa",
    "outputId": "d20769fd-9c6f-487a-ccc7-e6a51c537889"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have added 1 tokens\n",
      "50266\n"
     ]
    }
   ],
   "source": [
    "num_added_toks = tokenizer.add_tokens(AddedToken('<BULL>', single_word=False, lstrip=True, rstrip=True, normalized=False))\n",
    "print('We have added', num_added_toks, 'tokens')\n",
    "print(len(tokenizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZhQeQg3oCcL-"
   },
   "source": [
    "Note that for the sake of this notebook, we finetune the \"smaller\" LED checkpoint [\"allenai/led-base-16384\"](https://huggingface.co/allenai/led-base-16384). Better performance can however be attained by finetuning [\"allenai/led-large-16384\"](https://huggingface.co/allenai/led-large-16384) at the cost of a higher required GPU RAM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_VkTU_K6Mlpb"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df_train = pd.read_csv(drive_dir+'datasets/karger_books_base/train.csv').set_index(['book', 'chapter'])\n",
    "df_val = pd.read_csv(drive_dir+'datasets/karger_books_base/val.csv').set_index(['book', 'chapter'])\n",
    "df_test = pd.read_csv(drive_dir+'datasets/karger_books_base/test.csv').set_index(['book', 'chapter'])\n",
    "\n",
    "df = pd.concat([df_train, df_val, df_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FzT6E_MxMlpc"
   },
   "outputs": [],
   "source": [
    "df['bullets_tok'] = df.bullets.map(tokenizer.tokenize)\n",
    "df['bullets_enc'] = df.bullets.map(tokenizer.encode)\n",
    "df['bullets_num_tok'] = df.bullets_enc.map(len)\n",
    "df['text_enc'] = df.text.map(tokenizer.encode)\n",
    "df['text_num_tok'] = df.text_enc.map(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 14015,
     "status": "ok",
     "timestamp": 1611844635256,
     "user": {
      "displayName": "Marco Pietro Abrate",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gjh-8YF-8BlnrkN9mLZ0xfVOWfOh7kYncpYRv-Y=s64",
      "userId": "15422244832836998434"
     },
     "user_tz": -60
    },
    "id": "XRmpaNvXQugc",
    "outputId": "39f63b67-4ca7-48ee-e262-0a2ac95c4300"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "168 170\n"
     ]
    }
   ],
   "source": [
    "print(len(df.iloc[0].bullets_tok), len(df.iloc[0].bullets_enc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 13772,
     "status": "ok",
     "timestamp": 1611844635258,
     "user": {
      "displayName": "Marco Pietro Abrate",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gjh-8YF-8BlnrkN9mLZ0xfVOWfOh7kYncpYRv-Y=s64",
      "userId": "15422244832836998434"
     },
     "user_tz": -60
    },
    "id": "u61KfpMrQ2eX",
    "outputId": "3b136f9c-f404-4c8a-fd98-82f3f832e835"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 2\n",
      "0 2\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.bos_token_id, tokenizer.eos_token_id)\n",
    "print(df.iloc[0].bullets_enc[0], df.iloc[0].bullets_enc[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 13545,
     "status": "ok",
     "timestamp": 1611844635261,
     "user": {
      "displayName": "Marco Pietro Abrate",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gjh-8YF-8BlnrkN9mLZ0xfVOWfOh7kYncpYRv-Y=s64",
      "userId": "15422244832836998434"
     },
     "user_tz": -60
    },
    "id": "jK_dewH9Per7",
    "outputId": "55bfdad7-6feb-4975-db38-46bcac943feb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('<BULL> ', 50265),\n",
       " ('The', 133),\n",
       " ('Ġfour', 237),\n",
       " ('Ġmain', 1049),\n",
       " ('Ġtypes', 3505),\n",
       " ('Ġof', 9),\n",
       " ('Ġleukemia', 28837),\n",
       " ('Ġare', 32),\n",
       " ('Ġacute', 13827),\n",
       " ('Ġmy', 127),\n",
       " ('el', 523),\n",
       " ('oid', 12572),\n",
       " ('Ġleukemia', 28837),\n",
       " (',', 6),\n",
       " ('Ġacute', 13827),\n",
       " ('Ġlymph', 23496),\n",
       " ('obl', 33449),\n",
       " ('astic', 11599),\n",
       " ('Ġleukemia', 28837),\n",
       " (',', 6),\n",
       " ('Ġchronic', 7642),\n",
       " ('Ġmy', 127),\n",
       " ('el', 523),\n",
       " ('oid', 12572),\n",
       " ('Ġleukemia', 28837),\n",
       " ('Ġand', 8),\n",
       " ('Ġchronic', 7642),\n",
       " ('Ġlymph', 23496),\n",
       " ('ocy', 30321),\n",
       " ('tic', 13240),\n",
       " ('Ġleukemia', 28837),\n",
       " ('.', 4),\n",
       " (' <BULL> ', 50265),\n",
       " ('The', 133),\n",
       " ('Ġacute', 13827),\n",
       " ('Ġle', 2084),\n",
       " ('uke', 7480),\n",
       " ('m', 119),\n",
       " ('ias', 5003),\n",
       " ('Ġare', 32),\n",
       " ('Ġpredominantly', 15351),\n",
       " ('Ġcharacterized', 17407),\n",
       " ('Ġby', 30),\n",
       " ('Ġthe', 5),\n",
       " ('Ġuncontrolled', 38411),\n",
       " ('Ġgrowth', 434),\n",
       " ('Ġof', 9),\n",
       " ('Ġimmature', 39001),\n",
       " ('Ġpoorly', 12101),\n",
       " ('Ġdifferentiated', 32691),\n",
       " ('Ġcells', 4590),\n",
       " ('Ġthat', 14),\n",
       " ('Ġare', 32),\n",
       " ('Ġblocked', 4953),\n",
       " ('Ġfrom', 31),\n",
       " ('Ġfurther', 617),\n",
       " ('Ġdifferentiation', 37225),\n",
       " ('.', 4),\n",
       " (' <BULL> ', 50265),\n",
       " ('The', 133),\n",
       " ('Ġchronic', 7642),\n",
       " ('Ġle', 2084),\n",
       " ('uke', 7480),\n",
       " ('m', 119),\n",
       " ('ias', 5003),\n",
       " ('Ġare', 32),\n",
       " ('Ġcharacterized', 17407),\n",
       " ('Ġby', 30),\n",
       " ('Ġmat', 7821),\n",
       " ('uring', 5206),\n",
       " ('Ġprolifer', 37168),\n",
       " ('ative', 3693),\n",
       " ('Ġlater', 423),\n",
       " ('-', 12),\n",
       " ('stage', 10850),\n",
       " ('Ġcells', 4590),\n",
       " ('.', 4),\n",
       " (' <BULL> ', 50265),\n",
       " ('The', 133),\n",
       " ('Ġmain', 1049),\n",
       " ('Ġreason', 1219),\n",
       " ('Ġfor', 13),\n",
       " ('Ġthe', 5),\n",
       " ('Ġdevelopment', 709),\n",
       " ('Ġof', 9),\n",
       " ('Ġleukemia', 28837),\n",
       " ('Ġis', 16),\n",
       " ('Ġthe', 5),\n",
       " ('Ġaccumulation', 20477),\n",
       " ('Ġof', 9),\n",
       " ('Ġgene', 10596),\n",
       " ('Ġmutations', 28513),\n",
       " ('Ġover', 81),\n",
       " ('Ġtime', 86),\n",
       " ('.', 4),\n",
       " ('ĠChrom', 26877),\n",
       " ('os', 366),\n",
       " ('omal', 38868),\n",
       " ('Ġtransl', 37297),\n",
       " ('ocations', 29876),\n",
       " ('Ġare', 32),\n",
       " ('Ġcommon', 1537),\n",
       " ('.', 4),\n",
       " (' <BULL> ', 50265),\n",
       " ('The', 133),\n",
       " ('Ġidentification', 10614),\n",
       " ('Ġof', 9),\n",
       " ('Ġchromos', 47411),\n",
       " ('omal', 38868),\n",
       " ('Ġabnormalities', 39063),\n",
       " ('Ġaids', 25842),\n",
       " ('Ġtreatment', 1416),\n",
       " ('Ġstrat', 30789),\n",
       " ('ification', 5000),\n",
       " ('Ġin', 11),\n",
       " ('Ġpatients', 1484),\n",
       " ('.', 4),\n",
       " ('ĠNew', 188),\n",
       " ('-', 12),\n",
       " ('generation', 11092),\n",
       " ('Ġsequencing', 32243),\n",
       " ('Ġtechnologies', 4233),\n",
       " ('Ġhave', 33),\n",
       " ('Ġrevolution', 7977),\n",
       " ('ized', 1538),\n",
       " ('Ġthe', 5),\n",
       " ('Ġdiscovery', 6953),\n",
       " ('Ġof', 9),\n",
       " ('Ġmutations', 28513),\n",
       " ('Ġin', 11),\n",
       " ('Ġleukemia', 28837),\n",
       " ('.', 4),\n",
       " (' <BULL> ', 50265),\n",
       " ('Mal', 18764),\n",
       " ('ignant', 35090),\n",
       " ('Ġcl', 3741),\n",
       " ('onal', 20171),\n",
       " ('Ġsub', 2849),\n",
       " ('pop', 15076),\n",
       " ('ulations', 16685),\n",
       " ('Ġidentified', 2006),\n",
       " ('Ġat', 23),\n",
       " ('Ġdiagnosis', 9726),\n",
       " ('Ġhave', 33),\n",
       " ('Ġalso', 67),\n",
       " ('Ġbeen', 57),\n",
       " ('Ġidentified', 2006),\n",
       " ('Ġat', 23),\n",
       " ('Ġrelapse', 38387),\n",
       " ('.', 4),\n",
       " (' <BULL> ', 50265),\n",
       " ('Pro', 10653),\n",
       " ('gn', 16993),\n",
       " ('osis', 13310),\n",
       " ('Ġdepends', 7971),\n",
       " ('Ġon', 15),\n",
       " ('Ġthe', 5),\n",
       " ('Ġgenetic', 9186),\n",
       " ('Ġabnormalities', 39063),\n",
       " ('Ġinvolved', 963),\n",
       " (',', 6),\n",
       " ('Ġas', 25),\n",
       " ('Ġwell', 157),\n",
       " ('Ġas', 25),\n",
       " ('Ġother', 97),\n",
       " ('Ġclinical', 5154),\n",
       " ('Ġfactors', 2433),\n",
       " ('.', 4)]"
      ]
     },
     "execution_count": 16,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(zip(df.iloc[0].bullets_tok, df.iloc[0].bullets_enc[1:-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 13235,
     "status": "ok",
     "timestamp": 1611844635262,
     "user": {
      "displayName": "Marco Pietro Abrate",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gjh-8YF-8BlnrkN9mLZ0xfVOWfOh7kYncpYRv-Y=s64",
      "userId": "15422244832836998434"
     },
     "user_tz": -60
    },
    "id": "Edn3Z0zbMlpc",
    "outputId": "a811df47-d121-47b2-d8de-a3b9a1dd6833",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count      453.000000\n",
       "mean      2957.896247\n",
       "std       1896.892605\n",
       "min        640.000000\n",
       "25%       1680.000000\n",
       "50%       2488.000000\n",
       "75%       3616.000000\n",
       "max      13452.000000\n",
       "Name: text_num_tok, dtype: float64"
      ]
     },
     "execution_count": 17,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.text_num_tok.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 13039,
     "status": "ok",
     "timestamp": 1611844635264,
     "user": {
      "displayName": "Marco Pietro Abrate",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gjh-8YF-8BlnrkN9mLZ0xfVOWfOh7kYncpYRv-Y=s64",
      "userId": "15422244832836998434"
     },
     "user_tz": -60
    },
    "id": "HwEipr3bMlpc",
    "outputId": "b5d7e636-4ee0-4db6-dde7-5521d18a4d13",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 18,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df[df.text_num_tok > 8192])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 12764,
     "status": "ok",
     "timestamp": 1611844635266,
     "user": {
      "displayName": "Marco Pietro Abrate",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gjh-8YF-8BlnrkN9mLZ0xfVOWfOh7kYncpYRv-Y=s64",
      "userId": "15422244832836998434"
     },
     "user_tz": -60
    },
    "id": "XVL8epyaMlpd",
    "outputId": "8e203980-dfb9-496d-c0b6-3c8b31981a58",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    453.000000\n",
       "mean     185.512141\n",
       "std       90.921720\n",
       "min       48.000000\n",
       "25%      115.000000\n",
       "50%      170.000000\n",
       "75%      235.000000\n",
       "max      680.000000\n",
       "Name: bullets_num_tok, dtype: float64"
      ]
     },
     "execution_count": 19,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.bullets_num_tok.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 12544,
     "status": "ok",
     "timestamp": 1611844635267,
     "user": {
      "displayName": "Marco Pietro Abrate",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gjh-8YF-8BlnrkN9mLZ0xfVOWfOh7kYncpYRv-Y=s64",
      "userId": "15422244832836998434"
     },
     "user_tz": -60
    },
    "id": "occi5ifrMlpd",
    "outputId": "7f9406c2-6f53-4892-f6b8-5c4e40d315d9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 20,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df[df.bullets_num_tok > 512])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Nbb24Uh-Y4xO"
   },
   "outputs": [],
   "source": [
    "max_input_length = 8192\n",
    "max_output_length = 512"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WN_SAv1JE40f"
   },
   "source": [
    "Now, let's write down the input data processing function that will be used to map each data sample to the correct model format.\n",
    "As explained earlier `text` represents here our input data and `bullets` is the target data. The datasamples are thus tokenized up to the respective maximum lengths of 8192 and 512.\n",
    "\n",
    "In addition to the usual `attention_mask`, LED can make use of an additional `global_attention_mask` defining which input tokens are attended globally and which are attended only locally, just as it's the case of [Longformer](https://huggingface.co/transformers/model_doc/longformer.html). For more information on Longformer's self-attention, please take a look at the corresponding [docs](https://huggingface.co/transformers/model_doc/longformer.html#longformer-self-attention). For summarization, we follow recommendations of the [paper](https://arxiv.org/abs/2004.05150) and use global attention only for the very first token. Finally, we make sure that no loss is computed on padded tokens by setting their index to `-100`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lEcAaZhNY8ge"
   },
   "outputs": [],
   "source": [
    "def process_data_to_model_inputs(batch):\n",
    "    # tokenize the inputs and labels\n",
    "    inputs = tokenizer(\n",
    "        batch[\"text\"],\n",
    "        padding=\"max_length\",\n",
    "        truncation=True,\n",
    "        max_length=max_input_length,\n",
    "    )\n",
    "    outputs = tokenizer(\n",
    "        batch[\"bullets\"],\n",
    "        padding=\"max_length\",\n",
    "        truncation=True,\n",
    "        max_length=max_output_length,\n",
    "    )\n",
    "\n",
    "    batch[\"input_ids\"] = inputs.input_ids\n",
    "    batch[\"attention_mask\"] = inputs.attention_mask\n",
    "\n",
    "    # create 0 global_attention_mask lists\n",
    "    batch[\"global_attention_mask\"] = len(batch[\"input_ids\"]) * [\n",
    "        [0 for _ in range(len(batch[\"input_ids\"][0]))]\n",
    "    ]\n",
    "\n",
    "    # since above lists are references, the following line changes the 0 index for all samples\n",
    "    batch[\"global_attention_mask\"][0][0] = 1\n",
    "    batch[\"labels\"] = outputs.input_ids\n",
    "\n",
    "    # We have to make sure that the PAD token is ignored\n",
    "    batch[\"labels\"] = [\n",
    "        [-100 if token == tokenizer.pad_token_id else token for token in labels]\n",
    "        for labels in batch[\"labels\"]\n",
    "    ]\n",
    "\n",
    "    return batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iyseRmC5IcXj"
   },
   "source": [
    "For the sake of this notebook, we will reduce the training and validation data \n",
    "to a dummy dataset of sizes 250 and 25 respectively. For a full training run, those lines should be commented out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 11478,
     "status": "ok",
     "timestamp": 1611844635273,
     "user": {
      "displayName": "Marco Pietro Abrate",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gjh-8YF-8BlnrkN9mLZ0xfVOWfOh7kYncpYRv-Y=s64",
      "userId": "15422244832836998434"
     },
     "user_tz": -60
    },
    "id": "8DiGsjD4Mlpj",
    "outputId": "bf7bc51a-bb16-4788-cf4b-46bb28a856be"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['book', 'chapter', 'text', 'bullets'],\n",
       "    num_rows: 362\n",
       "})"
      ]
     },
     "execution_count": 23,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fNzZZACtIoCD"
   },
   "source": [
    "Great, having defined the mapping function, let's preprocess the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10999,
     "status": "ok",
     "timestamp": 1611844635275,
     "user": {
      "displayName": "Marco Pietro Abrate",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gjh-8YF-8BlnrkN9mLZ0xfVOWfOh7kYncpYRv-Y=s64",
      "userId": "15422244832836998434"
     },
     "user_tz": -60
    },
    "id": "8RClMjZOZCPO",
    "outputId": "983d47ab-7b05-4e9d-8840-64204c4fffa1"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /root/.cache/huggingface/datasets/csv/default-0498b287fc32a431/0.0.0/2960f95a26e85d40ca41a230ac88787f715ee3003edaacb8b1f0891e9f04dda2/cache-d04e131ec9c71489.arrow\n"
     ]
    }
   ],
   "source": [
    "train_dataset = train_dataset.map(\n",
    "    process_data_to_model_inputs,\n",
    "    batched=True,\n",
    "    batch_size=batch_size,\n",
    "    remove_columns=['book', 'chapter', 'text', 'bullets'],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10794,
     "status": "ok",
     "timestamp": 1611844635277,
     "user": {
      "displayName": "Marco Pietro Abrate",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gjh-8YF-8BlnrkN9mLZ0xfVOWfOh7kYncpYRv-Y=s64",
      "userId": "15422244832836998434"
     },
     "user_tz": -60
    },
    "id": "eG9bds3RMlpk",
    "outputId": "894af0cd-9a4f-417f-e297-5b79cd461c16"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['attention_mask', 'global_attention_mask', 'input_ids', 'labels'],\n",
       "    num_rows: 362\n",
       "})"
      ]
     },
     "execution_count": 25,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RUtRFmgVIuHG"
   },
   "source": [
    "and validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10347,
     "status": "ok",
     "timestamp": 1611844635279,
     "user": {
      "displayName": "Marco Pietro Abrate",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gjh-8YF-8BlnrkN9mLZ0xfVOWfOh7kYncpYRv-Y=s64",
      "userId": "15422244832836998434"
     },
     "user_tz": -60
    },
    "id": "Gy_9DCocZD5G",
    "outputId": "6003f5f3-a6e0-423d-8547-76191d0afc72"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /root/.cache/huggingface/datasets/csv/default-82fd9fd954b5a267/0.0.0/2960f95a26e85d40ca41a230ac88787f715ee3003edaacb8b1f0891e9f04dda2/cache-5ee4aebeea5df705.arrow\n",
      "Loading cached processed dataset at /root/.cache/huggingface/datasets/csv/default-acb527b34156b505/0.0.0/2960f95a26e85d40ca41a230ac88787f715ee3003edaacb8b1f0891e9f04dda2/cache-758d0938dbb23390.arrow\n"
     ]
    }
   ],
   "source": [
    "val_dataset = val_dataset.map(\n",
    "    process_data_to_model_inputs,\n",
    "    batched=True,\n",
    "    batch_size=batch_size,\n",
    "    remove_columns=['book', 'chapter', 'text', 'bullets'],\n",
    ")\n",
    "test_dataset = test_dataset.map(\n",
    "    process_data_to_model_inputs,\n",
    "    batched=True,\n",
    "    batch_size=batch_size,\n",
    "    remove_columns=['book', 'chapter', 'text', 'bullets'],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "evRRitZaIw9N"
   },
   "source": [
    "Finally, the datasets should be converted into the PyTorch format as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ci2QYHCMZiNO"
   },
   "outputs": [],
   "source": [
    "train_dataset.set_format(\n",
    "    type=\"torch\",\n",
    "    columns=[\"input_ids\", \"attention_mask\", \"global_attention_mask\", \"labels\"],\n",
    ")\n",
    "val_dataset.set_format(\n",
    "    type=\"torch\",\n",
    "    columns=[\"input_ids\", \"attention_mask\", \"global_attention_mask\", \"labels\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dI-QHywgI6Hb"
   },
   "source": [
    "Alright, we're almost ready to start training. Let's load the model via the `AutoModelForSeq2SeqLM` class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SZf_8QXJacIc"
   },
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSeq2SeqLM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hNJQlLDKJHIK"
   },
   "source": [
    "We've decided to stick to the smaller model `\"allenai/led-base-16384\"` for the sake of this notebook. In addition, we directly enable gradient checkpointing and disable the caching mechanism to save memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 18697,
     "status": "ok",
     "timestamp": 1611844645470,
     "user": {
      "displayName": "Marco Pietro Abrate",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gjh-8YF-8BlnrkN9mLZ0xfVOWfOh7kYncpYRv-Y=s64",
      "userId": "15422244832836998434"
     },
     "user_tz": -60
    },
    "id": "R-UfEo0Zadpl",
    "outputId": "dc7e4b18-0a98-4065-9a1f-403d4a01a75c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Embedding(50266, 768)"
      ]
     },
     "execution_count": 29,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_name_or_path = 'allenai/led-base-16384'\n",
    "led = AutoModelForSeq2SeqLM.from_pretrained(\"allenai/led-base-16384\", gradient_checkpointing=True, use_cache=False)\n",
    "led.resize_token_embeddings(len(tokenizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kQOaX6eRJXkM"
   },
   "source": [
    "During training, we want to evaluate the model on Rouge, the most common metric used in summarization, to make sure the model is indeed improving during training. For this, we set fitting generation parameters. We'll use beam search with a small beam of just 2 to save memory. Also, we force the model to generate at least 100 tokens, but no more than 512. In addition, some other generation parameters are set that have been found helpful for generation. For more information on those parameters, please take a look at the [docs](https://huggingface.co/transformers/main_classes/model.html?highlight=generate#transformers.generation_utils.GenerationMixin.generate)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kPnNi_tWaklV"
   },
   "outputs": [],
   "source": [
    "# set generate hyperparameters\n",
    "led.config.num_beams = 2\n",
    "led.config.max_length = 512\n",
    "led.config.min_length = 70\n",
    "led.config.length_penalty = 1.0\n",
    "led.config.early_stopping = True\n",
    "led.config.no_repeat_ngram_size = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wsytOIWVKqFz"
   },
   "source": [
    "The compute metrics function expects the generation output, called `pred.predictions` as well as the gold label, called `pred.label_ids`.\n",
    "\n",
    "Those tokens are decoded and consequently, the rouge score can be computed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 19575,
     "status": "ok",
     "timestamp": 1611844647662,
     "user": {
      "displayName": "Marco Pietro Abrate",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gjh-8YF-8BlnrkN9mLZ0xfVOWfOh7kYncpYRv-Y=s64",
      "userId": "15422244832836998434"
     },
     "user_tz": -60
    },
    "id": "p02Ltd_7xS0c",
    "outputId": "3324f4e2-383a-4c7f-decb-a37fe9361471"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from rouge_score import rouge_scorer, scoring\n",
    "import numpy as np\n",
    "import re\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "from sentence_transformers import SentenceTransformer\n",
    "sentence_distilroberta = SentenceTransformer('paraphrase-distilroberta-base-v1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1ahmf7mcZzU7"
   },
   "outputs": [],
   "source": [
    "ROUGE_KEYS = [\"rouge1\", \"rouge2\", \"rougeL\", \"rougeLsum\"]\n",
    "\n",
    "def extract_rouge_mid_statistics(dct):\n",
    "    new_dict = {}\n",
    "    for k1, v1 in dct.items():\n",
    "        mid = v1.mid\n",
    "        for stat in [\"precision\", \"recall\", \"fmeasure\"]:\n",
    "            new_dict[k1+'_'+stat] = round(getattr(mid, stat), 4)*100\n",
    "    return new_dict\n",
    "\n",
    "def add_newline_to_end_of_each_sentence(x: str) -> str:\n",
    "    \"\"\"This was added to get rougeLsum scores matching published rougeL scores for BART and PEGASUS.\"\"\"\n",
    "    re.sub(\"<n>\", \"\", x)  # remove pegasus newline char\n",
    "    return \"\\n\".join(nltk.sent_tokenize(x))\n",
    "\n",
    "def calculate_rouge(\n",
    "    pred_lns,\n",
    "    tgt_lns,\n",
    "    use_stemmer=True,\n",
    "    rouge_keys=ROUGE_KEYS,\n",
    "    return_precision_and_recall=True,\n",
    "    bootstrap_aggregation=True,\n",
    "    newline_sep=True):\n",
    "\n",
    "    scorer = rouge_scorer.RougeScorer(rouge_keys, use_stemmer=use_stemmer)\n",
    "    aggregator = scoring.BootstrapAggregator()\n",
    "    for tgt, pred in zip(tgt_lns, pred_lns):\n",
    "        # rougeLsum expects \"\\n\" separated sentences within a summary\n",
    "        if newline_sep:\n",
    "            pred = add_newline_to_end_of_each_sentence(pred)\n",
    "            tgt = add_newline_to_end_of_each_sentence(tgt)\n",
    "        scores = scorer.score(tgt, pred)\n",
    "        aggregator.add_scores(scores)\n",
    "\n",
    "    if bootstrap_aggregation:\n",
    "        result = aggregator.aggregate()\n",
    "        if return_precision_and_recall:\n",
    "            return extract_rouge_mid_statistics(result)  # here we return dict\n",
    "        else:\n",
    "            return {k: round(v.mid.fmeasure * 100, 4) for k, v in result.items()}\n",
    "\n",
    "    else:\n",
    "        return aggregator._scores  # here we return defaultdict(list)\n",
    "\n",
    "def calculate_sentence_trans_cosine(pred_lns, tgt_lns):\n",
    "\n",
    "    cosine_sim = lambda a, b: (np.dot(a, b) / (np.linalg.norm(a)*np.linalg.norm(b)))\n",
    "\n",
    "    return np.mean([\\\n",
    "        cosine_sim(sentence_distilroberta.encode(pred),\n",
    "                   sentence_distilroberta.encode(tgt))\\\n",
    "        for tgt, pred in zip(tgt_lns, pred_lns)])*100\n",
    "\n",
    "def compute_metrics(pred):\n",
    "    labels_ids = pred.label_ids\n",
    "    pred_ids = pred.predictions\n",
    "\n",
    "    pred_str = tokenizer.batch_decode(pred_ids, skip_special_tokens=True)\n",
    "    labels_ids[labels_ids == -100] = tokenizer.pad_token_id\n",
    "    label_str = tokenizer.batch_decode(labels_ids, skip_special_tokens=True)\n",
    "\n",
    "    metrics = calculate_rouge(pred_str, label_str)\n",
    "\n",
    "    cosine_sim = calculate_sentence_trans_cosine(pred_str, label_str)\n",
    "    metrics.update({\"sentence_distilroberta_cosine\": cosine_sim})\n",
    "\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rrX2gBnYLAna"
   },
   "source": [
    "Now, we're ready to start training. Let's import the `Seq2SeqTrainer` and `Seq2SeqTrainingArguments`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Gq7CajIWaUo5"
   },
   "outputs": [],
   "source": [
    "from transformers import Seq2SeqTrainer, Seq2SeqTrainingArguments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ga-fCOB4LI4W"
   },
   "source": [
    "In contrast to the usual `Trainer`, the `Seq2SeqTrainer` makes it possible to use the `generate()` function during evaluation. This should be enabled with `predict_with_generate=True`. Because our GPU RAM is limited, we make use of gradient accumulation by setting `gradient_accumulation_steps=4` to have an effective `batch_size` of 2 * 4 = 8.\n",
    "\n",
    "Other training arguments can be read upon in the [docs](https://huggingface.co/transformers/main_classes/trainer.html?highlight=trainingarguments#transformers.TrainingArguments)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 19979,
     "status": "ok",
     "timestamp": 1611844649142,
     "user": {
      "displayName": "Marco Pietro Abrate",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gjh-8YF-8BlnrkN9mLZ0xfVOWfOh7kYncpYRv-Y=s64",
      "userId": "15422244832836998434"
     },
     "user_tz": -60
    },
    "id": "yyURQdR3S-6S",
    "outputId": "ace28274-64d4-43af-bba4-10145db5c580"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/drive/My Drive/MAGMA: Summarization/fine-tuning/allenai?led-base-16384_karger_books_base/logs\n"
     ]
    }
   ],
   "source": [
    "output_dir = drive_dir+'fine-tuning/'+project_name\n",
    "\n",
    "log_dir = output_dir + '/logs'\n",
    "print(log_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mMehwI4QZqB_"
   },
   "outputs": [],
   "source": [
    "# enable fp16 apex training\n",
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir=output_dir,\n",
    "    overwrite_output_dir=True,\n",
    "    do_train=True,\n",
    "    num_train_epochs=5,\n",
    "    do_eval=True,\n",
    "    evaluation_strategy='steps',\n",
    "    eval_steps=10,\n",
    "    predict_with_generate=True,\n",
    "    per_device_train_batch_size=2,\n",
    "    per_device_eval_batch_size=2,\n",
    "    gradient_accumulation_steps=8,\n",
    "    fp16=True,\n",
    "    logging_steps=5,\n",
    "    save_steps=20,\n",
    "    save_total_limit=10,\n",
    "    logging_dir=log_dir\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JZCY-C5mLzXY"
   },
   "source": [
    "The training arguments, along with the model, tokenizer, datasets and the `compute_metrics` function can then be passed to the `Seq2SeqTrainer`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6WPyTYO_JfHW"
   },
   "outputs": [],
   "source": [
    "trainer = Seq2SeqTrainer(\n",
    "    model=led,\n",
    "    tokenizer=tokenizer,\n",
    "    args=training_args,\n",
    "    compute_metrics=compute_metrics,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xZxSe_afL9TH"
   },
   "source": [
    "and we can start training. This will take about ~35min."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "g4zkCpeQa2NN",
    "outputId": "c6b10664-4a94-4b42-ae8a-5448b142d611"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.15<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">/content/drive/My Drive/MAGMA: Summarization/fine-tuning/allenai?led-base-16384_karger_books_base</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/marcoabrate/finetune_led\" target=\"_blank\">https://wandb.ai/marcoabrate/finetune_led</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/marcoabrate/finetune_led/runs/exg9w845\" target=\"_blank\">https://wandb.ai/marcoabrate/finetune_led/runs/exg9w845</a><br/>\n",
       "                Run data is saved locally in <code>/content/wandb/run-20210128_143733-exg9w845</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/datasets/arrow_dataset.py:851: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /pytorch/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "  return torch.tensor(x, **format_kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='71' max='110' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 71/110 2:37:13 < 1:28:51, 0.01 it/s, Epoch 3.18/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Rouge1 Precision</th>\n",
       "      <th>Rouge1 Recall</th>\n",
       "      <th>Rouge1 Fmeasure</th>\n",
       "      <th>Rouge2 Precision</th>\n",
       "      <th>Rouge2 Recall</th>\n",
       "      <th>Rouge2 Fmeasure</th>\n",
       "      <th>Rougel Precision</th>\n",
       "      <th>Rougel Recall</th>\n",
       "      <th>Rougel Fmeasure</th>\n",
       "      <th>Rougelsum Precision</th>\n",
       "      <th>Rougelsum Recall</th>\n",
       "      <th>Rougelsum Fmeasure</th>\n",
       "      <th>Sentence Distilroberta Cosine</th>\n",
       "      <th>Runtime</th>\n",
       "      <th>Samples Per Second</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>2.782400</td>\n",
       "      <td>2.544499</td>\n",
       "      <td>52.350000</td>\n",
       "      <td>30.700000</td>\n",
       "      <td>36.340000</td>\n",
       "      <td>16.220000</td>\n",
       "      <td>9.630000</td>\n",
       "      <td>11.440000</td>\n",
       "      <td>29.670000</td>\n",
       "      <td>17.570000</td>\n",
       "      <td>20.670000</td>\n",
       "      <td>34.870000</td>\n",
       "      <td>20.300000</td>\n",
       "      <td>24.050000</td>\n",
       "      <td>70.823926</td>\n",
       "      <td>701.865200</td>\n",
       "      <td>0.064000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>2.503200</td>\n",
       "      <td>2.438534</td>\n",
       "      <td>51.050000</td>\n",
       "      <td>34.060000</td>\n",
       "      <td>38.300000</td>\n",
       "      <td>16.780000</td>\n",
       "      <td>11.040000</td>\n",
       "      <td>12.490000</td>\n",
       "      <td>27.930000</td>\n",
       "      <td>18.760000</td>\n",
       "      <td>20.950000</td>\n",
       "      <td>33.790000</td>\n",
       "      <td>21.850000</td>\n",
       "      <td>24.830000</td>\n",
       "      <td>71.699560</td>\n",
       "      <td>825.669300</td>\n",
       "      <td>0.055000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>2.262200</td>\n",
       "      <td>2.381989</td>\n",
       "      <td>48.050000</td>\n",
       "      <td>36.870000</td>\n",
       "      <td>38.140000</td>\n",
       "      <td>14.960000</td>\n",
       "      <td>11.510000</td>\n",
       "      <td>11.880000</td>\n",
       "      <td>26.360000</td>\n",
       "      <td>20.530000</td>\n",
       "      <td>20.970000</td>\n",
       "      <td>31.640000</td>\n",
       "      <td>24.320000</td>\n",
       "      <td>25.100000</td>\n",
       "      <td>73.104674</td>\n",
       "      <td>1049.603900</td>\n",
       "      <td>0.043000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>2.249100</td>\n",
       "      <td>2.354266</td>\n",
       "      <td>51.340000</td>\n",
       "      <td>32.780000</td>\n",
       "      <td>37.670000</td>\n",
       "      <td>16.590000</td>\n",
       "      <td>10.760000</td>\n",
       "      <td>12.280000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>19.080000</td>\n",
       "      <td>21.600000</td>\n",
       "      <td>34.490000</td>\n",
       "      <td>22.020000</td>\n",
       "      <td>25.230000</td>\n",
       "      <td>73.239094</td>\n",
       "      <td>799.889100</td>\n",
       "      <td>0.056000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>2.082800</td>\n",
       "      <td>2.383488</td>\n",
       "      <td>50.490000</td>\n",
       "      <td>34.570000</td>\n",
       "      <td>38.230000</td>\n",
       "      <td>16.150000</td>\n",
       "      <td>11.120000</td>\n",
       "      <td>12.270000</td>\n",
       "      <td>29.240000</td>\n",
       "      <td>20.010000</td>\n",
       "      <td>22.010000</td>\n",
       "      <td>33.820000</td>\n",
       "      <td>22.750000</td>\n",
       "      <td>25.260000</td>\n",
       "      <td>73.963046</td>\n",
       "      <td>900.814400</td>\n",
       "      <td>0.050000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>2.040600</td>\n",
       "      <td>2.365585</td>\n",
       "      <td>50.290000</td>\n",
       "      <td>38.040000</td>\n",
       "      <td>40.920000</td>\n",
       "      <td>16.200000</td>\n",
       "      <td>12.510000</td>\n",
       "      <td>13.280000</td>\n",
       "      <td>27.510000</td>\n",
       "      <td>20.960000</td>\n",
       "      <td>22.460000</td>\n",
       "      <td>33.060000</td>\n",
       "      <td>24.590000</td>\n",
       "      <td>26.630000</td>\n",
       "      <td>74.976486</td>\n",
       "      <td>1039.729000</td>\n",
       "      <td>0.043000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='12' max='23' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [12/23 07:12 < 07:12, 0.03 it/s]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n",
      "/usr/local/lib/python3.6/dist-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n",
      "/usr/local/lib/python3.6/dist-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n",
      "/usr/local/lib/python3.6/dist-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='101' max='110' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [101/110 3:57:52 < 21:37, 0.01 it/s, Epoch 4.53/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Rouge1 Precision</th>\n",
       "      <th>Rouge1 Recall</th>\n",
       "      <th>Rouge1 Fmeasure</th>\n",
       "      <th>Rouge2 Precision</th>\n",
       "      <th>Rouge2 Recall</th>\n",
       "      <th>Rouge2 Fmeasure</th>\n",
       "      <th>Rougel Precision</th>\n",
       "      <th>Rougel Recall</th>\n",
       "      <th>Rougel Fmeasure</th>\n",
       "      <th>Rougelsum Precision</th>\n",
       "      <th>Rougelsum Recall</th>\n",
       "      <th>Rougelsum Fmeasure</th>\n",
       "      <th>Sentence Distilroberta Cosine</th>\n",
       "      <th>Runtime</th>\n",
       "      <th>Samples Per Second</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>2.782400</td>\n",
       "      <td>2.544499</td>\n",
       "      <td>52.350000</td>\n",
       "      <td>30.700000</td>\n",
       "      <td>36.340000</td>\n",
       "      <td>16.220000</td>\n",
       "      <td>9.630000</td>\n",
       "      <td>11.440000</td>\n",
       "      <td>29.670000</td>\n",
       "      <td>17.570000</td>\n",
       "      <td>20.670000</td>\n",
       "      <td>34.870000</td>\n",
       "      <td>20.300000</td>\n",
       "      <td>24.050000</td>\n",
       "      <td>70.823926</td>\n",
       "      <td>701.865200</td>\n",
       "      <td>0.064000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>2.503200</td>\n",
       "      <td>2.438534</td>\n",
       "      <td>51.050000</td>\n",
       "      <td>34.060000</td>\n",
       "      <td>38.300000</td>\n",
       "      <td>16.780000</td>\n",
       "      <td>11.040000</td>\n",
       "      <td>12.490000</td>\n",
       "      <td>27.930000</td>\n",
       "      <td>18.760000</td>\n",
       "      <td>20.950000</td>\n",
       "      <td>33.790000</td>\n",
       "      <td>21.850000</td>\n",
       "      <td>24.830000</td>\n",
       "      <td>71.699560</td>\n",
       "      <td>825.669300</td>\n",
       "      <td>0.055000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>2.262200</td>\n",
       "      <td>2.381989</td>\n",
       "      <td>48.050000</td>\n",
       "      <td>36.870000</td>\n",
       "      <td>38.140000</td>\n",
       "      <td>14.960000</td>\n",
       "      <td>11.510000</td>\n",
       "      <td>11.880000</td>\n",
       "      <td>26.360000</td>\n",
       "      <td>20.530000</td>\n",
       "      <td>20.970000</td>\n",
       "      <td>31.640000</td>\n",
       "      <td>24.320000</td>\n",
       "      <td>25.100000</td>\n",
       "      <td>73.104674</td>\n",
       "      <td>1049.603900</td>\n",
       "      <td>0.043000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>2.249100</td>\n",
       "      <td>2.354266</td>\n",
       "      <td>51.340000</td>\n",
       "      <td>32.780000</td>\n",
       "      <td>37.670000</td>\n",
       "      <td>16.590000</td>\n",
       "      <td>10.760000</td>\n",
       "      <td>12.280000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>19.080000</td>\n",
       "      <td>21.600000</td>\n",
       "      <td>34.490000</td>\n",
       "      <td>22.020000</td>\n",
       "      <td>25.230000</td>\n",
       "      <td>73.239094</td>\n",
       "      <td>799.889100</td>\n",
       "      <td>0.056000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>2.082800</td>\n",
       "      <td>2.383488</td>\n",
       "      <td>50.490000</td>\n",
       "      <td>34.570000</td>\n",
       "      <td>38.230000</td>\n",
       "      <td>16.150000</td>\n",
       "      <td>11.120000</td>\n",
       "      <td>12.270000</td>\n",
       "      <td>29.240000</td>\n",
       "      <td>20.010000</td>\n",
       "      <td>22.010000</td>\n",
       "      <td>33.820000</td>\n",
       "      <td>22.750000</td>\n",
       "      <td>25.260000</td>\n",
       "      <td>73.963046</td>\n",
       "      <td>900.814400</td>\n",
       "      <td>0.050000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>2.040600</td>\n",
       "      <td>2.365585</td>\n",
       "      <td>50.290000</td>\n",
       "      <td>38.040000</td>\n",
       "      <td>40.920000</td>\n",
       "      <td>16.200000</td>\n",
       "      <td>12.510000</td>\n",
       "      <td>13.280000</td>\n",
       "      <td>27.510000</td>\n",
       "      <td>20.960000</td>\n",
       "      <td>22.460000</td>\n",
       "      <td>33.060000</td>\n",
       "      <td>24.590000</td>\n",
       "      <td>26.630000</td>\n",
       "      <td>74.976486</td>\n",
       "      <td>1039.729000</td>\n",
       "      <td>0.043000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>2.124800</td>\n",
       "      <td>2.347729</td>\n",
       "      <td>51.360000</td>\n",
       "      <td>33.720000</td>\n",
       "      <td>38.050000</td>\n",
       "      <td>16.470000</td>\n",
       "      <td>10.540000</td>\n",
       "      <td>11.980000</td>\n",
       "      <td>29.660000</td>\n",
       "      <td>19.760000</td>\n",
       "      <td>22.040000</td>\n",
       "      <td>34.300000</td>\n",
       "      <td>22.460000</td>\n",
       "      <td>25.200000</td>\n",
       "      <td>73.818028</td>\n",
       "      <td>888.579700</td>\n",
       "      <td>0.051000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>1.976300</td>\n",
       "      <td>2.360626</td>\n",
       "      <td>48.910000</td>\n",
       "      <td>37.220000</td>\n",
       "      <td>39.320000</td>\n",
       "      <td>15.520000</td>\n",
       "      <td>11.740000</td>\n",
       "      <td>12.470000</td>\n",
       "      <td>27.600000</td>\n",
       "      <td>21.420000</td>\n",
       "      <td>22.300000</td>\n",
       "      <td>32.270000</td>\n",
       "      <td>24.310000</td>\n",
       "      <td>25.740000</td>\n",
       "      <td>74.243903</td>\n",
       "      <td>1329.364900</td>\n",
       "      <td>0.034000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>2.012300</td>\n",
       "      <td>2.348964</td>\n",
       "      <td>51.850000</td>\n",
       "      <td>32.740000</td>\n",
       "      <td>37.120000</td>\n",
       "      <td>17.610000</td>\n",
       "      <td>11.550000</td>\n",
       "      <td>12.840000</td>\n",
       "      <td>30.680000</td>\n",
       "      <td>19.550000</td>\n",
       "      <td>22.020000</td>\n",
       "      <td>35.460000</td>\n",
       "      <td>22.160000</td>\n",
       "      <td>25.120000</td>\n",
       "      <td>73.655987</td>\n",
       "      <td>846.959300</td>\n",
       "      <td>0.053000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='13' max='23' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [13/23 08:52 < 07:23, 0.02 it/s]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n"
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "P95DxvqWi_2Y",
    "L5sXxqeNCtkN",
    "Uv7edHocbDCD",
    "CFtGA4yibG2u"
   ],
   "name": "led_finetune_karger_books.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

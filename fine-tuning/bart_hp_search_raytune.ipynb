{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "magma_dir = '/home/ubuntu/magma/'\n",
    "bucket_dir = '/home/ubuntu/s3/'\n",
    "transformers_dir = '/home/ubuntu/transformers/'\n",
    "cache_dir = bucket_dir+'.cache/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EddY1WDNsKlS"
   },
   "source": [
    "## **Fine-tuning**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "2d6M41X9AKBi"
   },
   "outputs": [],
   "source": [
    "finetune_script = '\"'+transformers_dir+'examples/seq2seq/finetune_trainer.py\"'\n",
    "eval_script = '\"'+transformers_dir+'examples/seq2seq/run_eval.py\"'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S0FByNNOIRvG"
   },
   "source": [
    "### **Config**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 67
    },
    "id": "82WSp6khIcua",
    "outputId": "6b5776d2-758b-455f-f3f5-6ff21f1b0a9f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to query for notebook name, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mmarcoabrate\u001b[0m (use `wandb login --relogin` to force relogin)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: WANDB_PROJECT=hp_search_para_wordembed\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.insert(0, magma_dir)\n",
    "import config\n",
    "\n",
    "import torch\n",
    "torch.manual_seed = config.SEED\n",
    "\n",
    "import wandb\n",
    "wandb.login()\n",
    "\n",
    "project_name = 'hp_search_para_wordembed'\n",
    "%env WANDB_PROJECT=$project_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uPZ7A-sBVOam"
   },
   "source": [
    "### HP search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "vJOYl_g6F1e2"
   },
   "outputs": [],
   "source": [
    "model_name_or_path = 'sshleifer/distilbart-cnn-12-6'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "4xs_XkbCVOar"
   },
   "outputs": [],
   "source": [
    "data_dir = '\"'+bucket_dir+'datasets/karger_books_para_wordembed/bart/st/\"'\n",
    "\n",
    "output_dir = '\"'+bucket_dir+'fine-tuning/hyperparameters_test\"'\n",
    "\n",
    "log_dir = output_dir + '/logs'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 66,
     "referenced_widgets": [
      "4dca0f8d944943a7879b3de0a2f8347a",
      "c8804e5babea4223b192bca1a9111fac",
      "bb421fdbad584767bff8da4c882fdfbf",
      "46539ad5e91e4af9860cab29a8200b53",
      "0cf5224ab8cb40198d84fa37cfcc68d5",
      "521e472af5e24843a467a768c042d6c6",
      "dad549b11e194e53af76c965e3f482a2",
      "d3095d48314a49d2b81e066c2c3fd389"
     ]
    },
    "id": "wtLC1O1ZJpU3",
    "outputId": "317a9e46-1c7b-4fba-c55a-eef2f13d243e",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44035e1ad8534e85b9d51bd288dc38c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.62k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoConfig\n",
    "model_config = AutoConfig.from_pretrained(model_name_or_path, use_cache=False)\n",
    "model_config.min_length = config.ONE_BULLET_MIN_LEN\n",
    "model_config.max_length = config.ONE_BULLET_MAX_LEN\n",
    "model_config.length_penalty = config.LENGTH_PENALTY\n",
    "model_config.no_repeat_ngram_size = config.NO_REPEAT_NGRAM_SIZE\n",
    "\n",
    "model_config.task_specific_params['summarization']['min_length'] = config.ONE_BULLET_MIN_LEN\n",
    "model_config.task_specific_params['summarization']['max_length'] = config.ONE_BULLET_MAX_LEN\n",
    "model_config.task_specific_params['summarization']['length_penalty'] = config.LENGTH_PENALTY\n",
    "model_config.task_specific_params['summarization']['no_repeat_ngram_size'] = config.NO_REPEAT_NGRAM_SIZE\n",
    "model_config_dir = '\"'+bucket_dir+'fine-tuning/'+\\\n",
    "    model_name_or_path.replace('/', '?')+'_config\"'\n",
    "model_config.save_pretrained(model_config_dir[1:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "K66kY1WOVOaw",
    "outputId": "c50158bf-7522-42c0-d9e7-164da464ba26",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "02/03/2021 15:03:21 - WARNING - __main__ -   Process rank: -1, device: cuda:0, n_gpu: 1, distributed training: False, 16-bits training: True\n",
      "02/03/2021 15:03:21 - INFO - __main__ -   Training/evaluation parameters Seq2SeqTrainingArguments(output_dir='/home/ubuntu/s3/fine-tuning/hyperparameters_test', overwrite_output_dir=True, do_train=False, do_eval=None, do_predict=False, evaluation_strategy=<EvaluationStrategy.STEPS: 'steps'>, prediction_loss_only=False, per_device_train_batch_size=1, per_device_eval_batch_size=1, per_gpu_train_batch_size=None, per_gpu_eval_batch_size=None, gradient_accumulation_steps=1, eval_accumulation_steps=None, learning_rate=5e-05, weight_decay=0.0, adam_beta1=0.9, adam_beta2=0.999, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=1.0, max_steps=-1, lr_scheduler_type=<SchedulerType.LINEAR: 'linear'>, warmup_steps=0, logging_dir='runs/Feb03_15-03-21_ip-172-31-39-35', logging_first_step=True, logging_steps=1, save_steps=500, save_total_limit=None, no_cuda=False, seed=42, fp16=True, fp16_opt_level='O1', fp16_backend='auto', local_rank=-1, tpu_num_cores=None, tpu_metrics_debug=False, debug=False, dataloader_drop_last=False, eval_steps=3, dataloader_num_workers=0, past_index=-1, run_name='/home/ubuntu/s3/fine-tuning/hyperparameters_test', disable_tqdm=False, remove_unused_columns=True, label_names=None, load_best_model_at_end=False, metric_for_best_model=None, greater_is_better=None, ignore_data_skip=False, sharded_ddp=False, deepspeed=None, label_smoothing_factor=0.0, adafactor=False, group_by_length=False, report_to=['tensorboard', 'wandb'], ddp_find_unused_parameters=None, dataloader_pin_memory=True, label_smoothing=0.0, sortish_sampler=True, predict_with_generate=True, encoder_layerdrop=None, decoder_layerdrop=None, dropout=None, attention_dropout=None, lr_scheduler='constant')\n",
      "[INFO|configuration_utils.py:445] 2021-02-03 15:03:22,016 >> loading configuration file https://huggingface.co/sshleifer/distilbart-cnn-12-6/resolve/main/config.json from cache at /home/ubuntu/s3/.cache/adac95cf641be69365b3dd7fe00d4114b3c7c77fb0572931db31a92d4995053b.9307b6cec4435559ec6e79d5a210a334b17706465329e138f335649d14f27e78\n",
      "[INFO|configuration_utils.py:481] 2021-02-03 15:03:22,017 >> Model config BartConfig {\n",
      "  \"_num_labels\": 3,\n",
      "  \"activation_dropout\": 0.0,\n",
      "  \"activation_function\": \"gelu\",\n",
      "  \"add_bias_logits\": false,\n",
      "  \"add_final_layer_norm\": false,\n",
      "  \"architectures\": [\n",
      "    \"BartForConditionalGeneration\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classif_dropout\": 0.0,\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"d_model\": 1024,\n",
      "  \"decoder_attention_heads\": 16,\n",
      "  \"decoder_ffn_dim\": 4096,\n",
      "  \"decoder_layerdrop\": 0.0,\n",
      "  \"decoder_layers\": 6,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"dropout\": 0.1,\n",
      "  \"early_stopping\": true,\n",
      "  \"encoder_attention_heads\": 16,\n",
      "  \"encoder_ffn_dim\": 4096,\n",
      "  \"encoder_layerdrop\": 0.0,\n",
      "  \"encoder_layers\": 12,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"extra_pos_embeddings\": 2,\n",
      "  \"force_bos_token_to_be_generated\": true,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\"\n",
      "  },\n",
      "  \"init_std\": 0.02,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2\n",
      "  },\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 142,\n",
      "  \"max_position_embeddings\": 1024,\n",
      "  \"min_length\": 56,\n",
      "  \"model_type\": \"bart\",\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"normalize_before\": false,\n",
      "  \"normalize_embedding\": true,\n",
      "  \"num_beams\": 4,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"prefix\": \" \",\n",
      "  \"replacing_rate\": 0,\n",
      "  \"scale_embedding\": false,\n",
      "  \"static_position_embeddings\": false,\n",
      "  \"student_decoder_layers\": null,\n",
      "  \"student_encoder_layers\": null,\n",
      "  \"task_specific_params\": {\n",
      "    \"summarization\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"length_penalty\": 2.0,\n",
      "      \"max_length\": 142,\n",
      "      \"min_length\": 56,\n",
      "      \"no_repeat_ngram_size\": 3,\n",
      "      \"num_beams\": 4\n",
      "    }\n",
      "  },\n",
      "  \"transformers_version\": \"4.3.0.dev0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50264\n",
      "}\n",
      "\n",
      "[INFO|configuration_utils.py:445] 2021-02-03 15:03:22,318 >> loading configuration file https://huggingface.co/sshleifer/distilbart-cnn-12-6/resolve/main/config.json from cache at /home/ubuntu/s3/.cache/adac95cf641be69365b3dd7fe00d4114b3c7c77fb0572931db31a92d4995053b.9307b6cec4435559ec6e79d5a210a334b17706465329e138f335649d14f27e78\n",
      "[INFO|configuration_utils.py:481] 2021-02-03 15:03:22,319 >> Model config BartConfig {\n",
      "  \"_num_labels\": 3,\n",
      "  \"activation_dropout\": 0.0,\n",
      "  \"activation_function\": \"gelu\",\n",
      "  \"add_bias_logits\": false,\n",
      "  \"add_final_layer_norm\": false,\n",
      "  \"architectures\": [\n",
      "    \"BartForConditionalGeneration\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classif_dropout\": 0.0,\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"d_model\": 1024,\n",
      "  \"decoder_attention_heads\": 16,\n",
      "  \"decoder_ffn_dim\": 4096,\n",
      "  \"decoder_layerdrop\": 0.0,\n",
      "  \"decoder_layers\": 6,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"dropout\": 0.1,\n",
      "  \"early_stopping\": true,\n",
      "  \"encoder_attention_heads\": 16,\n",
      "  \"encoder_ffn_dim\": 4096,\n",
      "  \"encoder_layerdrop\": 0.0,\n",
      "  \"encoder_layers\": 12,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"extra_pos_embeddings\": 2,\n",
      "  \"force_bos_token_to_be_generated\": true,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\"\n",
      "  },\n",
      "  \"init_std\": 0.02,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2\n",
      "  },\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 142,\n",
      "  \"max_position_embeddings\": 1024,\n",
      "  \"min_length\": 56,\n",
      "  \"model_type\": \"bart\",\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"normalize_before\": false,\n",
      "  \"normalize_embedding\": true,\n",
      "  \"num_beams\": 4,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"prefix\": \" \",\n",
      "  \"replacing_rate\": 0,\n",
      "  \"scale_embedding\": false,\n",
      "  \"static_position_embeddings\": false,\n",
      "  \"student_decoder_layers\": null,\n",
      "  \"student_encoder_layers\": null,\n",
      "  \"task_specific_params\": {\n",
      "    \"summarization\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"length_penalty\": 2.0,\n",
      "      \"max_length\": 142,\n",
      "      \"min_length\": 56,\n",
      "      \"no_repeat_ngram_size\": 3,\n",
      "      \"num_beams\": 4\n",
      "    }\n",
      "  },\n",
      "  \"transformers_version\": \"4.3.0.dev0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50264\n",
      "}\n",
      "\n",
      "[INFO|tokenization_utils_base.py:1688] 2021-02-03 15:03:22,319 >> Model name 'sshleifer/distilbart-cnn-12-6' not found in model shortcut name list (facebook/bart-base, facebook/bart-large, facebook/bart-large-mnli, facebook/bart-large-cnn, facebook/bart-large-xsum, yjernite/bart_eli5). Assuming 'sshleifer/distilbart-cnn-12-6' is a path, a model identifier, or url to a directory containing tokenizer files.\n",
      "[INFO|tokenization_utils_base.py:1786] 2021-02-03 15:03:24,004 >> loading file https://huggingface.co/sshleifer/distilbart-cnn-12-6/resolve/main/vocab.json from cache at /home/ubuntu/s3/.cache/9951e68693b9a7c583ae677e9cb53c02715d9bd0311a78706401372653cdea0a.647b4548b6d9ea817e82e7a9231a320231a1c9ea24053cc9e758f3fe68216f05\n",
      "[INFO|tokenization_utils_base.py:1786] 2021-02-03 15:03:24,005 >> loading file https://huggingface.co/sshleifer/distilbart-cnn-12-6/resolve/main/merges.txt from cache at /home/ubuntu/s3/.cache/7588c8d398d659b230a038240cc023f67b6848117d2999f06ab625af7bfc7ec1.5d12962c5ee615a4c803841266e9c3be9a691a924f72d395d3a6c6c81157788b\n",
      "[INFO|tokenization_utils_base.py:1786] 2021-02-03 15:03:24,005 >> loading file https://huggingface.co/sshleifer/distilbart-cnn-12-6/resolve/main/tokenizer.json from cache at None\n",
      "[INFO|tokenization_utils_base.py:1786] 2021-02-03 15:03:24,005 >> loading file https://huggingface.co/sshleifer/distilbart-cnn-12-6/resolve/main/added_tokens.json from cache at None\n",
      "[INFO|tokenization_utils_base.py:1786] 2021-02-03 15:03:24,005 >> loading file https://huggingface.co/sshleifer/distilbart-cnn-12-6/resolve/main/special_tokens_map.json from cache at None\n",
      "[INFO|tokenization_utils_base.py:1786] 2021-02-03 15:03:24,005 >> loading file https://huggingface.co/sshleifer/distilbart-cnn-12-6/resolve/main/tokenizer_config.json from cache at /home/ubuntu/s3/.cache/f5316f64f9716436994a7ad76a354dc20ecb2dd74eb61d278f103a9c8b80291f.67d01b18f2079bd75eac0b2f2e7235768c7f26bd728e7a855a1c5acae01a91a8\n",
      "[INFO|modeling_utils.py:1027] 2021-02-03 15:03:24,613 >> loading weights file https://huggingface.co/sshleifer/distilbart-cnn-12-6/resolve/main/pytorch_model.bin from cache at /home/ubuntu/s3/.cache/b336fa0b874ea92e3e22f07a7e6f8fa9da01221759c33abeb2679d6d98fe7755.585965cf7e82e4536033cd21d76c486af3d6b1c2a34b3a847840d4e7fe9d8844\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO|modeling_utils.py:1143] 2021-02-03 15:03:51,206 >> All model checkpoint weights were used when initializing BartForConditionalGeneration.\n",
      "\n",
      "[INFO|modeling_utils.py:1152] 2021-02-03 15:03:51,206 >> All the weights of BartForConditionalGeneration were initialized from the model checkpoint at sshleifer/distilbart-cnn-12-6.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BartForConditionalGeneration for predictions without further training.\n",
      "02/03/2021 15:03:51 - INFO - utils -   setting model.config to task specific params for summarization:\n",
      " {'early_stopping': True, 'length_penalty': 2.0, 'max_length': 142, 'min_length': 56, 'no_repeat_ngram_size': 3, 'num_beams': 4}\n",
      "02/03/2021 15:03:51 - INFO - utils -   note: command line args may override some of these\n",
      "[INFO|modeling_utils.py:1027] 2021-02-03 15:03:51,761 >> loading weights file https://huggingface.co/sshleifer/distilbart-cnn-12-6/resolve/main/pytorch_model.bin from cache at /home/ubuntu/s3/.cache/b336fa0b874ea92e3e22f07a7e6f8fa9da01221759c33abeb2679d6d98fe7755.585965cf7e82e4536033cd21d76c486af3d6b1c2a34b3a847840d4e7fe9d8844\n",
      "[INFO|modeling_utils.py:1143] 2021-02-03 15:04:17,408 >> All model checkpoint weights were used when initializing BartForConditionalGeneration.\n",
      "\n",
      "[INFO|modeling_utils.py:1152] 2021-02-03 15:04:17,408 >> All the weights of BartForConditionalGeneration were initialized from the model checkpoint at sshleifer/distilbart-cnn-12-6.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BartForConditionalGeneration for predictions without further training.\n",
      "02/03/2021 15:04:17 - INFO - utils -   setting model.config to task specific params for summarization:\n",
      " {'early_stopping': True, 'length_penalty': 2.0, 'max_length': 142, 'min_length': 56, 'no_repeat_ngram_size': 3, 'num_beams': 4}\n",
      "02/03/2021 15:04:17 - INFO - utils -   note: command line args may override some of these\n",
      "[INFO|trainer.py:345] 2021-02-03 15:04:20,220 >> Using amp fp16 backend\n",
      "02/03/2021 15:04:20 - INFO - __main__ -   ** Hyperparameter Search **\n",
      "02/03/2021 15:04:20 - INFO - ray.tune.ray_trial_executor -   Initializing Ray automatically.For cluster usage or custom Ray initialization, call `ray.init(...)` before `tune.run`.\n",
      "2021-02-03 15:04:21,529\tINFO services.py:1173 -- View the Ray dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8265\u001b[39m\u001b[22m\n",
      "2021-02-03 15:04:25,625\tWARNING function_runner.py:540 -- Function checkpointing is disabled. This may result in unexpected behavior when using checkpointing features or certain schedulers. To enable, set the train function arguments to be `func(config, checkpoint_dir=None)`.\n",
      "== Status ==\n",
      "Memory usage on this node: 7.2/15.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 1/4 CPUs, 1/1 GPUs, 0.0/5.52 GiB heap, 0.0/1.9 GiB objects (0/1.0 accelerator_type:T4)\n",
      "Result logdir: /home/ubuntu/ray_results/_inner_2021-02-03_15-04-25\n",
      "Number of trials: 1/20 (1 RUNNING)\n",
      "+--------------------+----------+-------+-------------------------------+-----------------+\n",
      "| Trial name         | status   | loc   |   gradient_accumulation_steps |   learning_rate |\n",
      "|--------------------+----------+-------+-------------------------------+-----------------|\n",
      "| _inner_1aeff_00000 | RUNNING  |       |                             4 |           1e-05 |\n",
      "+--------------------+----------+-------+-------------------------------+-----------------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=3369)\u001b[0m wandb: Currently logged in as: marcoabrate (use `wandb login --relogin` to force relogin)\n",
      "\u001b[2m\u001b[36m(pid=3369)\u001b[0m wandb: wandb version 0.10.17 is available!  To upgrade, please run:\n",
      "\u001b[2m\u001b[36m(pid=3369)\u001b[0m wandb:  $ pip install wandb --upgrade\n",
      "\u001b[2m\u001b[36m(pid=3369)\u001b[0m wandb: Tracking run with wandb version 0.10.14\n",
      "\u001b[2m\u001b[36m(pid=3369)\u001b[0m wandb: Syncing run /home/ubuntu/s3/fine-tuning/hyperparameters_test\n",
      "\u001b[2m\u001b[36m(pid=3369)\u001b[0m wandb: ⭐️ View project at https://wandb.ai/marcoabrate/hp_search_para_wordembed\n",
      "\u001b[2m\u001b[36m(pid=3369)\u001b[0m wandb: 🚀 View run at https://wandb.ai/marcoabrate/hp_search_para_wordembed/runs/1yaqmhr5\n",
      "\u001b[2m\u001b[36m(pid=3369)\u001b[0m wandb: Run data is saved locally in /home/ubuntu/ray_results/_inner_2021-02-03_15-04-25/_inner_1aeff_00000_0_gradient_accumulation_steps=4,learning_rate=1e-05_2021-02-03_15-04-25/wandb/run-20210203_150453-1yaqmhr5\n",
      "\u001b[2m\u001b[36m(pid=3369)\u001b[0m wandb: Run `wandb offline` to turn off syncing.\n",
      "\u001b[2m\u001b[36m(pid=3369)\u001b[0m \n",
      "  0%|          | 0/12 [00:00<?, ?it/s]\n",
      "\u001b[2m\u001b[36m(pid=3369)\u001b[0m /home/ubuntu/miniconda3/envs/magma/lib/python3.6/site-packages/torch/optim/lr_scheduler.py:136: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "\u001b[2m\u001b[36m(pid=3369)\u001b[0m   \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n",
      "  8%|▊         | 1/12 [00:01<00:18,  1.67s/it]\n",
      "\u001b[2m\u001b[36m(pid=3369)\u001b[0m {'loss': 6.2597, 'learning_rate': 1e-05, 'epoch': 0.08}\n",
      " 17%|█▋        | 2/12 [00:01<00:08,  1.18it/s]\n",
      "\u001b[2m\u001b[36m(pid=3369)\u001b[0m {'loss': 3.8359, 'learning_rate': 1e-05, 'epoch': 0.16}\n",
      " 25%|██▌       | 3/12 [00:02<00:05,  1.71it/s]\n",
      "\u001b[2m\u001b[36m(pid=3369)\u001b[0m {'loss': 3.249, 'learning_rate': 1e-05, 'epoch': 0.24}\n",
      "\u001b[2m\u001b[36m(pid=3369)\u001b[0m \n",
      "  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      "\u001b[2m\u001b[36m(pid=3369)\u001b[0m \n",
      " 20%|██        | 2/10 [00:00<00:02,  2.94it/s]\u001b[A\n",
      "\u001b[2m\u001b[36m(pid=3369)\u001b[0m \n",
      " 30%|███       | 3/10 [00:01<00:03,  2.07it/s]\u001b[A\n",
      "\u001b[2m\u001b[36m(pid=3369)\u001b[0m \n",
      " 40%|████      | 4/10 [00:02<00:03,  1.73it/s]\u001b[A\n",
      "\u001b[2m\u001b[36m(pid=3369)\u001b[0m \n",
      " 50%|█████     | 5/10 [00:02<00:03,  1.63it/s]\u001b[A\n",
      "\u001b[2m\u001b[36m(pid=3369)\u001b[0m \n",
      " 60%|██████    | 6/10 [00:03<00:02,  1.57it/s]\u001b[A\n",
      "\u001b[2m\u001b[36m(pid=3369)\u001b[0m \n",
      " 70%|███████   | 7/10 [00:04<00:01,  1.54it/s]\u001b[A\n",
      "\u001b[2m\u001b[36m(pid=3369)\u001b[0m \n",
      " 80%|████████  | 8/10 [00:04<00:01,  1.52it/s]\u001b[A\n",
      "\u001b[2m\u001b[36m(pid=3369)\u001b[0m \n",
      " 90%|█████████ | 9/10 [00:05<00:00,  1.51it/s]\u001b[A\n",
      "\u001b[2m\u001b[36m(pid=3369)\u001b[0m \n",
      "100%|██████████| 10/10 [00:06<00:00,  1.50it/s]\u001b[A\n",
      "Result for _inner_1aeff_00000:\n",
      "  date: 2021-02-03_15-05-04\n",
      "  done: false\n",
      "  epoch: 0.24\n",
      "  eval_gen_len: 60.0\n",
      "  eval_loss: 3.096942663192749\n",
      "  eval_rouge1_fmeasure: 0.3289\n",
      "  eval_rouge1_precision: 0.2701\n",
      "  eval_rouge1_recall: 0.4691\n",
      "  eval_rouge2_fmeasure: 0.1499\n",
      "  eval_rouge2_precision: 0.1228\n",
      "  eval_rouge2_recall: 0.2133\n",
      "  eval_rougeL_fmeasure: 0.2621\n",
      "  eval_rougeL_precision: 0.2135\n",
      "  eval_rougeL_recall: 0.3837\n",
      "  eval_rougeLsum_fmeasure: 0.2847\n",
      "  eval_rougeLsum_precision: 0.2328\n",
      "  eval_rougeLsum_recall: 0.4091\n",
      "  eval_runtime: 7.4598\n",
      "  eval_samples_per_second: 1.341\n",
      "  eval_sentence_distilroberta_cosine: 68.12149286270142\n",
      "  experiment_id: f06376db6ffd4a5985895160ff6a117b\n",
      "  hostname: ip-172-31-39-35\n",
      "  iterations_since_restore: 1\n",
      "  node_ip: 172.31.39.35\n",
      "  objective: 80.26229286270141\n",
      "  pid: 3369\n",
      "  time_since_restore: 38.68767237663269\n",
      "  time_this_iter_s: 38.68767237663269\n",
      "  time_total_s: 38.68767237663269\n",
      "  timestamp: 1612364704\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: 1aeff_00000\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 11.3/15.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 1/4 CPUs, 1/1 GPUs, 0.0/5.52 GiB heap, 0.0/1.9 GiB objects (0/1.0 accelerator_type:T4)\n",
      "Result logdir: /home/ubuntu/ray_results/_inner_2021-02-03_15-04-25\n",
      "Number of trials: 2/20 (1 PENDING, 1 RUNNING)\n",
      "+--------------------+----------+-------------------+-------------------------------+-----------------+-------------+\n",
      "| Trial name         | status   | loc               |   gradient_accumulation_steps |   learning_rate |   objective |\n",
      "|--------------------+----------+-------------------+-------------------------------+-----------------+-------------|\n",
      "| _inner_1aeff_00000 | RUNNING  | 172.31.39.35:3369 |                             4 |          1e-05  |     80.2623 |\n",
      "| _inner_1aeff_00001 | PENDING  |                   |                             8 |          0.0001 |             |\n",
      "+--------------------+----------+-------------------+-------------------------------+-----------------+-------------+\n",
      "\n",
      "\n",
      "                                              \n",
      " 25%|██▌       | 3/12 [00:09<00:05,  1.71it/s] \n",
      "100%|██████████| 10/10 [00:06<00:00,  1.50it/s]\u001b[A\n",
      "                                               \u001b[A\n",
      "\u001b[2m\u001b[36m(pid=3369)\u001b[0m {'eval_loss': 3.096942663192749, 'eval_rouge1_precision': 0.2701, 'eval_rouge1_recall': 0.4691, 'eval_rouge1_fmeasure': 0.3289, 'eval_rouge2_precision': 0.1228, 'eval_rouge2_recall': 0.2133, 'eval_rouge2_fmeasure': 0.1499, 'eval_rougeL_precision': 0.2135, 'eval_rougeL_recall': 0.3837, 'eval_rougeL_fmeasure': 0.2621, 'eval_rougeLsum_precision': 0.2328, 'eval_rougeLsum_recall': 0.4091, 'eval_rougeLsum_fmeasure': 0.2847, 'eval_gen_len': 60.0, 'eval_sentence_distilroberta_cosine': 68.12149286270142, 'eval_runtime': 7.4598, 'eval_samples_per_second': 1.341, 'epoch': 0.24}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 4/12 [00:09<00:27,  3.41s/it]\n",
      " 33%|███▎      | 4/12 [00:09<00:27,  3.41s/it]\n",
      "\u001b[2m\u001b[36m(pid=3369)\u001b[0m {'loss': 2.9396, 'learning_rate': 1e-05, 'epoch': 0.32}\n",
      " 42%|████▏     | 5/12 [00:10<00:15,  2.28s/it]\n",
      "\u001b[2m\u001b[36m(pid=3369)\u001b[0m {'loss': 4.3526, 'learning_rate': 1e-05, 'epoch': 0.4}\n",
      " 50%|█████     | 6/12 [00:10<00:09,  1.60s/it]\n",
      " 50%|█████     | 6/12 [00:10<00:09,  1.60s/it]\n",
      "\u001b[2m\u001b[36m(pid=3369)\u001b[0m {'loss': 3.207, 'learning_rate': 1e-05, 'epoch': 0.48}\n",
      "\u001b[2m\u001b[36m(pid=3369)\u001b[0m \n",
      "  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      "\u001b[2m\u001b[36m(pid=3369)\u001b[0m \n",
      " 20%|██        | 2/10 [00:00<00:02,  2.95it/s]\u001b[A\n",
      "\u001b[2m\u001b[36m(pid=3369)\u001b[0m \n",
      " 30%|███       | 3/10 [00:01<00:03,  2.05it/s]\u001b[A\n",
      "\u001b[2m\u001b[36m(pid=3369)\u001b[0m \n",
      " 40%|████      | 4/10 [00:02<00:03,  1.72it/s]\u001b[A\n",
      "\u001b[2m\u001b[36m(pid=3369)\u001b[0m \n",
      " 50%|█████     | 5/10 [00:02<00:03,  1.62it/s]\u001b[A\n",
      "\u001b[2m\u001b[36m(pid=3369)\u001b[0m \n",
      " 60%|██████    | 6/10 [00:03<00:02,  1.57it/s]\u001b[A\n",
      "\u001b[2m\u001b[36m(pid=3369)\u001b[0m \n",
      " 70%|███████   | 7/10 [00:04<00:01,  1.54it/s]\u001b[A\n",
      "\u001b[2m\u001b[36m(pid=3369)\u001b[0m \n",
      " 80%|████████  | 8/10 [00:04<00:01,  1.52it/s]\u001b[A\n",
      "\u001b[2m\u001b[36m(pid=3369)\u001b[0m \n",
      " 90%|█████████ | 9/10 [00:05<00:00,  1.50it/s]\u001b[A\n",
      "\u001b[2m\u001b[36m(pid=3369)\u001b[0m \n",
      "100%|██████████| 10/10 [00:06<00:00,  1.49it/s]\u001b[A\n",
      "Result for _inner_1aeff_00000:\n",
      "  date: 2021-02-03_15-05-12\n",
      "  done: false\n",
      "  epoch: 0.48\n",
      "  eval_gen_len: 60.0\n",
      "  eval_loss: 2.841153383255005\n",
      "  eval_rouge1_fmeasure: 0.3274\n",
      "  eval_rouge1_precision: 0.2644\n",
      "  eval_rouge1_recall: 0.47\n",
      "  eval_rouge2_fmeasure: 0.1511\n",
      "  eval_rouge2_precision: 0.1227\n",
      "  eval_rouge2_recall: 0.2202\n",
      "  eval_rougeL_fmeasure: 0.2615\n",
      "  eval_rougeL_precision: 0.2107\n",
      "  eval_rougeL_recall: 0.3797\n",
      "  eval_rougeLsum_fmeasure: 0.2819\n",
      "  eval_rougeLsum_precision: 0.2276\n",
      "  eval_rougeLsum_recall: 0.409\n",
      "  eval_runtime: 7.2303\n",
      "  eval_samples_per_second: 1.383\n",
      "  eval_sentence_distilroberta_cosine: 67.90651082992554\n",
      "  experiment_id: f06376db6ffd4a5985895160ff6a117b\n",
      "  hostname: ip-172-31-39-35\n",
      "  iterations_since_restore: 2\n",
      "  node_ip: 172.31.39.35\n",
      "  objective: 79.84601082992553\n",
      "  pid: 3369\n",
      "  time_since_restore: 46.761847257614136\n",
      "  time_this_iter_s: 8.074174880981445\n",
      "  time_total_s: 46.761847257614136\n",
      "  timestamp: 1612364712\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 2\n",
      "  trial_id: 1aeff_00000\n",
      "                                              \n",
      "\n",
      " 50%|█████     | 6/12 [00:17<00:09,  1.60s/it] \n",
      "100%|██████████| 10/10 [00:06<00:00,  1.49it/s]\u001b[A\n",
      "                                               \u001b[A\n",
      "\u001b[2m\u001b[36m(pid=3369)\u001b[0m {'eval_loss': 2.841153383255005, 'eval_rouge1_precision': 0.2644, 'eval_rouge1_recall': 0.47, 'eval_rouge1_fmeasure': 0.3274, 'eval_rouge2_precision': 0.1227, 'eval_rouge2_recall': 0.2202, 'eval_rouge2_fmeasure': 0.1511, 'eval_rougeL_precision': 0.2107, 'eval_rougeL_recall': 0.3797, 'eval_rougeL_fmeasure': 0.2615, 'eval_rougeLsum_precision': 0.2276, 'eval_rougeLsum_recall': 0.409, 'eval_rougeLsum_fmeasure': 0.2819, 'eval_gen_len': 60.0, 'eval_sentence_distilroberta_cosine': 67.90651082992554, 'eval_runtime': 7.2303, 'eval_samples_per_second': 1.383, 'epoch': 0.48}\n",
      "== Status ==\n",
      "Memory usage on this node: 11.4/15.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 1/4 CPUs, 1/1 GPUs, 0.0/5.52 GiB heap, 0.0/1.9 GiB objects (0/1.0 accelerator_type:T4)\n",
      "Result logdir: /home/ubuntu/ray_results/_inner_2021-02-03_15-04-25\n",
      "Number of trials: 2/20 (1 PENDING, 1 RUNNING)\n",
      "+--------------------+----------+-------------------+-------------------------------+-----------------+-------------+\n",
      "| Trial name         | status   | loc               |   gradient_accumulation_steps |   learning_rate |   objective |\n",
      "|--------------------+----------+-------------------+-------------------------------+-----------------+-------------|\n",
      "| _inner_1aeff_00000 | RUNNING  | 172.31.39.35:3369 |                             4 |          1e-05  |      79.846 |\n",
      "| _inner_1aeff_00001 | PENDING  |                   |                             8 |          0.0001 |             |\n",
      "+--------------------+----------+-------------------+-------------------------------+-----------------+-------------+\n",
      "\n",
      "\n",
      " 58%|█████▊    | 7/12 [00:18<00:17,  3.53s/it]\n",
      "\u001b[2m\u001b[36m(pid=3369)\u001b[0m {'loss': 4.3008, 'learning_rate': 1e-05, 'epoch': 0.56}\n",
      " 67%|██████▋   | 8/12 [00:18<00:09,  2.49s/it]\n",
      "\u001b[2m\u001b[36m(pid=3369)\u001b[0m {'loss': 3.4402, 'learning_rate': 1e-05, 'epoch': 0.64}\n",
      " 75%|███████▌  | 9/12 [00:18<00:05,  1.80s/it]\n",
      " 75%|███████▌  | 9/12 [00:18<00:05,  1.80s/it]\n",
      "\u001b[2m\u001b[36m(pid=3369)\u001b[0m {'loss': 3.0972, 'learning_rate': 1e-05, 'epoch': 0.72}\n",
      "\u001b[2m\u001b[36m(pid=3369)\u001b[0m \n",
      "  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      "\u001b[2m\u001b[36m(pid=3369)\u001b[0m \n",
      " 20%|██        | 2/10 [00:00<00:02,  2.97it/s]\u001b[A\n",
      "\u001b[2m\u001b[36m(pid=3369)\u001b[0m \n",
      " 30%|███       | 3/10 [00:01<00:03,  2.08it/s]\u001b[A\n",
      "\u001b[2m\u001b[36m(pid=3369)\u001b[0m \n",
      " 40%|████      | 4/10 [00:02<00:03,  1.73it/s]\u001b[A\n",
      "\u001b[2m\u001b[36m(pid=3369)\u001b[0m \n",
      " 50%|█████     | 5/10 [00:02<00:03,  1.63it/s]\u001b[A\n",
      "\u001b[2m\u001b[36m(pid=3369)\u001b[0m \n",
      " 60%|██████    | 6/10 [00:03<00:02,  1.57it/s]\u001b[A\n",
      "\u001b[2m\u001b[36m(pid=3369)\u001b[0m \n",
      " 70%|███████   | 7/10 [00:04<00:01,  1.54it/s]\u001b[A\n",
      "\u001b[2m\u001b[36m(pid=3369)\u001b[0m \n",
      " 80%|████████  | 8/10 [00:04<00:01,  1.52it/s]\u001b[A\n",
      "\u001b[2m\u001b[36m(pid=3369)\u001b[0m \n",
      " 90%|█████████ | 9/10 [00:05<00:00,  1.51it/s]\u001b[A\n",
      "\u001b[2m\u001b[36m(pid=3369)\u001b[0m \n",
      "100%|██████████| 10/10 [00:06<00:00,  1.50it/s]\u001b[A\n",
      "Result for _inner_1aeff_00000:\n",
      "  date: 2021-02-03_15-05-20\n",
      "  done: false\n",
      "  epoch: 0.72\n",
      "  eval_gen_len: 60.0\n",
      "  eval_loss: 2.626790761947632\n",
      "  eval_rouge1_fmeasure: 0.3172\n",
      "  eval_rouge1_precision: 0.2566\n",
      "  eval_rouge1_recall: 0.4541\n",
      "  eval_rouge2_fmeasure: 0.1421\n",
      "  eval_rouge2_precision: 0.115\n",
      "  eval_rouge2_recall: 0.2071\n",
      "  eval_rougeL_fmeasure: 0.2425\n",
      "  eval_rougeL_precision: 0.1959\n",
      "  eval_rougeL_recall: 0.353\n",
      "  eval_rougeLsum_fmeasure: 0.2719\n",
      "  eval_rougeLsum_precision: 0.2211\n",
      "  eval_rougeLsum_recall: 0.3945\n",
      "  eval_runtime: 7.2082\n",
      "  eval_samples_per_second: 1.387\n",
      "  eval_sentence_distilroberta_cosine: 66.2465751171112\n",
      "  experiment_id: f06376db6ffd4a5985895160ff6a117b\n",
      "  hostname: ip-172-31-39-35\n",
      "  iterations_since_restore: 3\n",
      "  node_ip: 172.31.39.35\n",
      "  objective: 78.01277511711122\n",
      "  pid: 3369\n",
      "  time_since_restore: 54.79506874084473\n",
      "  time_this_iter_s: 8.03322148323059\n",
      "  time_total_s: 54.79506874084473\n",
      "  timestamp: 1612364720\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 3\n",
      "  trial_id: 1aeff_00000\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 11.4/15.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 1/4 CPUs, 1/1 GPUs, 0.0/5.52 GiB heap, 0.0/1.9 GiB objects (0/1.0 accelerator_type:T4)\n",
      "Result logdir: /home/ubuntu/ray_results/_inner_2021-02-03_15-04-25\n",
      "Number of trials: 2/20 (1 PENDING, 1 RUNNING)\n",
      "+--------------------+----------+-------------------+-------------------------------+-----------------+-------------+\n",
      "| Trial name         | status   | loc               |   gradient_accumulation_steps |   learning_rate |   objective |\n",
      "|--------------------+----------+-------------------+-------------------------------+-----------------+-------------|\n",
      "| _inner_1aeff_00000 | RUNNING  | 172.31.39.35:3369 |                             4 |          1e-05  |     78.0128 |\n",
      "| _inner_1aeff_00001 | PENDING  |                   |                             8 |          0.0001 |             |\n",
      "+--------------------+----------+-------------------+-------------------------------+-----------------+-------------+\n",
      "\n",
      "\n",
      "                                              \n",
      " 75%|███████▌  | 9/12 [00:25<00:05,  1.80s/it] \n",
      "100%|██████████| 10/10 [00:06<00:00,  1.50it/s]\u001b[A\n",
      "                                               \u001b[A\n",
      "\u001b[2m\u001b[36m(pid=3369)\u001b[0m {'eval_loss': 2.626790761947632, 'eval_rouge1_precision': 0.2566, 'eval_rouge1_recall': 0.4541, 'eval_rouge1_fmeasure': 0.3172, 'eval_rouge2_precision': 0.115, 'eval_rouge2_recall': 0.2071, 'eval_rouge2_fmeasure': 0.1421, 'eval_rougeL_precision': 0.1959, 'eval_rougeL_recall': 0.353, 'eval_rougeL_fmeasure': 0.2425, 'eval_rougeLsum_precision': 0.2211, 'eval_rougeLsum_recall': 0.3945, 'eval_rougeLsum_fmeasure': 0.2719, 'eval_gen_len': 60.0, 'eval_sentence_distilroberta_cosine': 66.2465751171112, 'eval_runtime': 7.2082, 'eval_samples_per_second': 1.387, 'epoch': 0.72}\n",
      " 83%|████████▎ | 10/12 [00:26<00:07,  3.55s/it]\n",
      " 83%|████████▎ | 10/12 [00:26<00:07,  3.55s/it]\n",
      "\u001b[2m\u001b[36m(pid=3369)\u001b[0m {'loss': 3.7499, 'learning_rate': 1e-05, 'epoch': 0.8}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 11/12 [00:26<00:02,  2.55s/it]\n",
      "\u001b[2m\u001b[36m(pid=3369)\u001b[0m {'loss': 3.0125, 'learning_rate': 1e-05, 'epoch': 0.88}\n",
      "100%|██████████| 12/12 [00:26<00:00,  1.86s/it]\n",
      "\u001b[2m\u001b[36m(pid=3369)\u001b[0m {'loss': 3.2749, 'learning_rate': 1e-05, 'epoch': 0.96}\n",
      "\u001b[2m\u001b[36m(pid=3369)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=3369)\u001b[0m \n",
      "  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      "\u001b[2m\u001b[36m(pid=3369)\u001b[0m \n",
      " 20%|██        | 2/10 [00:00<00:02,  2.95it/s]\u001b[A\n",
      "\u001b[2m\u001b[36m(pid=3369)\u001b[0m \n",
      " 30%|███       | 3/10 [00:01<00:03,  2.07it/s]\u001b[A\n",
      "\u001b[2m\u001b[36m(pid=3369)\u001b[0m \n",
      " 40%|████      | 4/10 [00:02<00:03,  1.73it/s]\u001b[A\n",
      "\u001b[2m\u001b[36m(pid=3369)\u001b[0m \n",
      " 50%|█████     | 5/10 [00:02<00:03,  1.63it/s]\u001b[A\n",
      "\u001b[2m\u001b[36m(pid=3369)\u001b[0m \n",
      " 60%|██████    | 6/10 [00:03<00:02,  1.57it/s]\u001b[A\n",
      "\u001b[2m\u001b[36m(pid=3369)\u001b[0m \n",
      " 70%|███████   | 7/10 [00:04<00:01,  1.54it/s]\u001b[A\n",
      "\u001b[2m\u001b[36m(pid=3369)\u001b[0m \n",
      " 80%|████████  | 8/10 [00:04<00:01,  1.52it/s]\u001b[A\n",
      "\u001b[2m\u001b[36m(pid=3369)\u001b[0m \n",
      " 90%|█████████ | 9/10 [00:05<00:00,  1.51it/s]\u001b[A\n",
      "\u001b[2m\u001b[36m(pid=3369)\u001b[0m \n",
      "100%|██████████| 10/10 [00:06<00:00,  1.50it/s]\u001b[A\n",
      "Result for _inner_1aeff_00000:\n",
      "  date: 2021-02-03_15-05-28\n",
      "  done: false\n",
      "  epoch: 0.96\n",
      "  eval_gen_len: 60.0\n",
      "  eval_loss: 2.467834949493408\n",
      "  eval_rouge1_fmeasure: 0.3174\n",
      "  eval_rouge1_precision: 0.258\n",
      "  eval_rouge1_recall: 0.4466\n",
      "  eval_rouge2_fmeasure: 0.1479\n",
      "  eval_rouge2_precision: 0.1214\n",
      "  eval_rouge2_recall: 0.2123\n",
      "  eval_rougeL_fmeasure: 0.255\n",
      "  eval_rougeL_precision: 0.2054\n",
      "  eval_rougeL_recall: 0.3637\n",
      "  eval_rougeLsum_fmeasure: 0.2764\n",
      "  eval_rougeLsum_precision: 0.2267\n",
      "  eval_rougeLsum_recall: 0.3917\n",
      "  eval_runtime: 7.1985\n",
      "  eval_samples_per_second: 1.389\n",
      "  eval_sentence_distilroberta_cosine: 65.76568484306335\n",
      "  experiment_id: f06376db6ffd4a5985895160ff6a117b\n",
      "  hostname: ip-172-31-39-35\n",
      "  iterations_since_restore: 4\n",
      "  node_ip: 172.31.39.35\n",
      "  objective: 77.57568484306334\n",
      "  pid: 3369\n",
      "  time_since_restore: 62.81868362426758\n",
      "  time_this_iter_s: 8.023614883422852\n",
      "  time_total_s: 62.81868362426758\n",
      "  timestamp: 1612364728\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 4\n",
      "  trial_id: 1aeff_00000\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 11.4/15.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 1/4 CPUs, 1/1 GPUs, 0.0/5.52 GiB heap, 0.0/1.9 GiB objects (0/1.0 accelerator_type:T4)\n",
      "Result logdir: /home/ubuntu/ray_results/_inner_2021-02-03_15-04-25\n",
      "Number of trials: 2/20 (1 PENDING, 1 RUNNING)\n",
      "+--------------------+----------+-------------------+-------------------------------+-----------------+-------------+\n",
      "| Trial name         | status   | loc               |   gradient_accumulation_steps |   learning_rate |   objective |\n",
      "|--------------------+----------+-------------------+-------------------------------+-----------------+-------------|\n",
      "| _inner_1aeff_00000 | RUNNING  | 172.31.39.35:3369 |                             4 |          1e-05  |     77.5757 |\n",
      "| _inner_1aeff_00001 | PENDING  |                   |                             8 |          0.0001 |             |\n",
      "+--------------------+----------+-------------------+-------------------------------+-----------------+-------------+\n",
      "\n",
      "\n",
      "Result for _inner_1aeff_00000:\n",
      "  date: 2021-02-03_15-05-28\n",
      "  done: true\n",
      "  epoch: 0.96\n",
      "  eval_gen_len: 60.0\n",
      "  eval_loss: 2.467834949493408\n",
      "  eval_rouge1_fmeasure: 0.3174\n",
      "  eval_rouge1_precision: 0.258\n",
      "  eval_rouge1_recall: 0.4466\n",
      "  eval_rouge2_fmeasure: 0.1479\n",
      "  eval_rouge2_precision: 0.1214\n",
      "  eval_rouge2_recall: 0.2123\n",
      "  eval_rougeL_fmeasure: 0.255\n",
      "  eval_rougeL_precision: 0.2054\n",
      "  eval_rougeL_recall: 0.3637\n",
      "  eval_rougeLsum_fmeasure: 0.2764\n",
      "  eval_rougeLsum_precision: 0.2267\n",
      "  eval_rougeLsum_recall: 0.3917\n",
      "  eval_runtime: 7.1985\n",
      "  eval_samples_per_second: 1.389\n",
      "  eval_sentence_distilroberta_cosine: 65.76568484306335\n",
      "  experiment_id: f06376db6ffd4a5985895160ff6a117b\n",
      "  experiment_tag: 0_gradient_accumulation_steps=4,learning_rate=1e-05\n",
      "  hostname: ip-172-31-39-35\n",
      "  iterations_since_restore: 4\n",
      "  node_ip: 172.31.39.35\n",
      "  objective: 77.57568484306334\n",
      "  pid: 3369\n",
      "  time_since_restore: 62.81868362426758\n",
      "  time_this_iter_s: 8.023614883422852\n",
      "  time_total_s: 62.81868362426758\n",
      "  timestamp: 1612364728\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 4\n",
      "  trial_id: 1aeff_00000\n",
      "                                               \n",
      "\n",
      "100%|██████████| 12/12 [00:33<00:00,  1.86s/it]\n",
      "100%|██████████| 10/10 [00:06<00:00,  1.50it/s]\u001b[A\n",
      "100%|██████████| 12/12 [00:33<00:00,  2.82s/it]\u001b[A\n",
      "\u001b[2m\u001b[36m(pid=3369)\u001b[0m {'eval_loss': 2.467834949493408, 'eval_rouge1_precision': 0.258, 'eval_rouge1_recall': 0.4466, 'eval_rouge1_fmeasure': 0.3174, 'eval_rouge2_precision': 0.1214, 'eval_rouge2_recall': 0.2123, 'eval_rouge2_fmeasure': 0.1479, 'eval_rougeL_precision': 0.2054, 'eval_rougeL_recall': 0.3637, 'eval_rougeL_fmeasure': 0.255, 'eval_rougeLsum_precision': 0.2267, 'eval_rougeLsum_recall': 0.3917, 'eval_rougeLsum_fmeasure': 0.2764, 'eval_gen_len': 60.0, 'eval_sentence_distilroberta_cosine': 65.76568484306335, 'eval_runtime': 7.1985, 'eval_samples_per_second': 1.389, 'epoch': 0.96}\n",
      "\u001b[2m\u001b[36m(pid=3369)\u001b[0m {'train_runtime': 36.2209, 'train_samples_per_second': 0.331, 'epoch': 0.96}\n",
      "\u001b[2m\u001b[36m(pid=3369)\u001b[0m wandb: Waiting for W&B process to finish, PID 3634\n",
      "\u001b[2m\u001b[36m(pid=3369)\u001b[0m wandb: Program ended successfully.\n",
      "\u001b[2m\u001b[36m(pid=3369)\u001b[0m wandb: - 0.04MB of 0.04MB uploaded (0.00MB deduped)\n",
      "wandb:                                                                                \n",
      "\u001b[2m\u001b[36m(pid=3369)\u001b[0m wandb: Find user logs for this run at: /home/ubuntu/ray_results/_inner_2021-02-03_15-04-25/_inner_1aeff_00000_0_gradient_accumulation_steps=4,learning_rate=1e-05_2021-02-03_15-04-25/wandb/run-20210203_150453-1yaqmhr5/logs/debug.log\n",
      "\u001b[2m\u001b[36m(pid=3369)\u001b[0m wandb: Find internal logs for this run at: /home/ubuntu/ray_results/_inner_2021-02-03_15-04-25/_inner_1aeff_00000_0_gradient_accumulation_steps=4,learning_rate=1e-05_2021-02-03_15-04-25/wandb/run-20210203_150453-1yaqmhr5/logs/debug-internal.log\n",
      "\u001b[2m\u001b[36m(pid=3369)\u001b[0m wandb: Run summary:\n",
      "\u001b[2m\u001b[36m(pid=3369)\u001b[0m wandb:                           train/loss 3.2749\n",
      "\u001b[2m\u001b[36m(pid=3369)\u001b[0m wandb:                  train/learning_rate 1e-05\n",
      "\u001b[2m\u001b[36m(pid=3369)\u001b[0m wandb:                          train/epoch 0.96\n",
      "\u001b[2m\u001b[36m(pid=3369)\u001b[0m wandb:                                _step 12\n",
      "\u001b[2m\u001b[36m(pid=3369)\u001b[0m wandb:                             _runtime 35\n",
      "\u001b[2m\u001b[36m(pid=3369)\u001b[0m wandb:                           _timestamp 1612364728\n",
      "\u001b[2m\u001b[36m(pid=3369)\u001b[0m wandb:                            eval/loss 2.46783\n",
      "\u001b[2m\u001b[36m(pid=3369)\u001b[0m wandb:                eval/rouge1_precision 0.258\n",
      "\u001b[2m\u001b[36m(pid=3369)\u001b[0m wandb:                   eval/rouge1_recall 0.4466\n",
      "\u001b[2m\u001b[36m(pid=3369)\u001b[0m wandb:                 eval/rouge1_fmeasure 0.3174\n",
      "\u001b[2m\u001b[36m(pid=3369)\u001b[0m wandb:                eval/rouge2_precision 0.1214\n",
      "\u001b[2m\u001b[36m(pid=3369)\u001b[0m wandb:                   eval/rouge2_recall 0.2123\n",
      "\u001b[2m\u001b[36m(pid=3369)\u001b[0m wandb:                 eval/rouge2_fmeasure 0.1479\n",
      "\u001b[2m\u001b[36m(pid=3369)\u001b[0m wandb:                eval/rougeL_precision 0.2054\n",
      "\u001b[2m\u001b[36m(pid=3369)\u001b[0m wandb:                   eval/rougeL_recall 0.3637\n",
      "\u001b[2m\u001b[36m(pid=3369)\u001b[0m wandb:                 eval/rougeL_fmeasure 0.255\n",
      "\u001b[2m\u001b[36m(pid=3369)\u001b[0m wandb:             eval/rougeLsum_precision 0.2267\n",
      "\u001b[2m\u001b[36m(pid=3369)\u001b[0m wandb:                eval/rougeLsum_recall 0.3917\n",
      "\u001b[2m\u001b[36m(pid=3369)\u001b[0m wandb:              eval/rougeLsum_fmeasure 0.2764\n",
      "\u001b[2m\u001b[36m(pid=3369)\u001b[0m wandb:                         eval/gen_len 60.0\n",
      "\u001b[2m\u001b[36m(pid=3369)\u001b[0m wandb:   eval/sentence_distilroberta_cosine 65.76568\n",
      "\u001b[2m\u001b[36m(pid=3369)\u001b[0m wandb:                         eval/runtime 7.1985\n",
      "\u001b[2m\u001b[36m(pid=3369)\u001b[0m wandb:              eval/samples_per_second 1.389\n",
      "\u001b[2m\u001b[36m(pid=3369)\u001b[0m wandb:                  train/train_runtime 36.2209\n",
      "\u001b[2m\u001b[36m(pid=3369)\u001b[0m wandb:       train/train_samples_per_second 0.331\n",
      "\u001b[2m\u001b[36m(pid=3369)\u001b[0m wandb:                     train/total_flos 16767021772800\n",
      "\u001b[2m\u001b[36m(pid=3369)\u001b[0m wandb: Run history:\n",
      "\u001b[2m\u001b[36m(pid=3369)\u001b[0m wandb:                           train/loss █▃▂▁▄▂▄▂▁▃▁▂\n",
      "\u001b[2m\u001b[36m(pid=3369)\u001b[0m wandb:                  train/learning_rate ▁▁▁▁▁▁▁▁▁▁▁▁\n",
      "\u001b[2m\u001b[36m(pid=3369)\u001b[0m wandb:                          train/epoch ▁▂▂▃▄▄▅▅▆▇▇█\n",
      "\u001b[2m\u001b[36m(pid=3369)\u001b[0m wandb:                                _step ▁▂▂▃▄▄▅▅▆▇▇█\n",
      "\u001b[2m\u001b[36m(pid=3369)\u001b[0m wandb:                             _runtime ▁▁▃▃▃▅▅▅▆▆▆█\n",
      "\u001b[2m\u001b[36m(pid=3369)\u001b[0m wandb:                           _timestamp ▁▁▃▃▃▅▅▅▆▆▆█\n",
      "\u001b[2m\u001b[36m(pid=3369)\u001b[0m wandb:                            eval/loss █▅▃▁\n",
      "\u001b[2m\u001b[36m(pid=3369)\u001b[0m wandb:                eval/rouge1_precision █▅▁▂\n",
      "\u001b[2m\u001b[36m(pid=3369)\u001b[0m wandb:                   eval/rouge1_recall ██▃▁\n",
      "\u001b[2m\u001b[36m(pid=3369)\u001b[0m wandb:                 eval/rouge1_fmeasure █▇▁▁\n",
      "\u001b[2m\u001b[36m(pid=3369)\u001b[0m wandb:                eval/rouge2_precision ██▁▇\n",
      "\u001b[2m\u001b[36m(pid=3369)\u001b[0m wandb:                   eval/rouge2_recall ▄█▁▄\n",
      "\u001b[2m\u001b[36m(pid=3369)\u001b[0m wandb:                 eval/rouge2_fmeasure ▇█▁▆\n",
      "\u001b[2m\u001b[36m(pid=3369)\u001b[0m wandb:                eval/rougeL_precision █▇▁▅\n",
      "\u001b[2m\u001b[36m(pid=3369)\u001b[0m wandb:                   eval/rougeL_recall █▇▁▃\n",
      "\u001b[2m\u001b[36m(pid=3369)\u001b[0m wandb:                 eval/rougeL_fmeasure ██▁▅\n",
      "\u001b[2m\u001b[36m(pid=3369)\u001b[0m wandb:             eval/rougeLsum_precision █▅▁▄\n",
      "\u001b[2m\u001b[36m(pid=3369)\u001b[0m wandb:                eval/rougeLsum_recall ██▂▁\n",
      "\u001b[2m\u001b[36m(pid=3369)\u001b[0m wandb:              eval/rougeLsum_fmeasure █▆▁▃\n",
      "\u001b[2m\u001b[36m(pid=3369)\u001b[0m wandb:                         eval/gen_len ▁▁▁▁\n",
      "\u001b[2m\u001b[36m(pid=3369)\u001b[0m wandb:   eval/sentence_distilroberta_cosine █▇▂▁\n",
      "\u001b[2m\u001b[36m(pid=3369)\u001b[0m wandb:                         eval/runtime █▂▁▁\n",
      "\u001b[2m\u001b[36m(pid=3369)\u001b[0m wandb:              eval/samples_per_second ▁▇██\n",
      "\u001b[2m\u001b[36m(pid=3369)\u001b[0m wandb:                  train/train_runtime ▁\n",
      "\u001b[2m\u001b[36m(pid=3369)\u001b[0m wandb:       train/train_samples_per_second ▁\n",
      "\u001b[2m\u001b[36m(pid=3369)\u001b[0m wandb:                     train/total_flos ▁\n",
      "\u001b[2m\u001b[36m(pid=3369)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(pid=3369)\u001b[0m wandb: Synced 5 W&B file(s), 1 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[2m\u001b[36m(pid=3369)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(pid=3369)\u001b[0m wandb: Synced /home/ubuntu/s3/fine-tuning/hyperparameters_test: https://wandb.ai/marcoabrate/hp_search_para_wordembed/runs/1yaqmhr5\n",
      "\u001b[2m\u001b[36m(pid=3369)\u001b[0m \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=3368)\u001b[0m wandb: Currently logged in as: marcoabrate (use `wandb login --relogin` to force relogin)\n",
      "\u001b[2m\u001b[36m(pid=3368)\u001b[0m wandb: wandb version 0.10.17 is available!  To upgrade, please run:\n",
      "\u001b[2m\u001b[36m(pid=3368)\u001b[0m wandb:  $ pip install wandb --upgrade\n",
      "\u001b[2m\u001b[36m(pid=3368)\u001b[0m wandb: Tracking run with wandb version 0.10.14\n",
      "\u001b[2m\u001b[36m(pid=3368)\u001b[0m wandb: Syncing run /home/ubuntu/s3/fine-tuning/hyperparameters_test\n",
      "\u001b[2m\u001b[36m(pid=3368)\u001b[0m wandb: ⭐️ View project at https://wandb.ai/marcoabrate/hp_search_para_wordembed\n",
      "\u001b[2m\u001b[36m(pid=3368)\u001b[0m wandb: 🚀 View run at https://wandb.ai/marcoabrate/hp_search_para_wordembed/runs/ja04x0p3\n",
      "\u001b[2m\u001b[36m(pid=3368)\u001b[0m wandb: Run data is saved locally in /home/ubuntu/ray_results/_inner_2021-02-03_15-04-25/_inner_1aeff_00001_1_gradient_accumulation_steps=8,learning_rate=0.0001_2021-02-03_15-05-28/wandb/run-20210203_150558-ja04x0p3\n",
      "\u001b[2m\u001b[36m(pid=3368)\u001b[0m wandb: Run `wandb offline` to turn off syncing.\n",
      "  0%|          | 0/6 [00:00<?, ?it/s]\n",
      "\u001b[2m\u001b[36m(pid=3368)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=3368)\u001b[0m /home/ubuntu/miniconda3/envs/magma/lib/python3.6/site-packages/torch/optim/lr_scheduler.py:136: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "\u001b[2m\u001b[36m(pid=3368)\u001b[0m   \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n",
      " 17%|█▋        | 1/6 [00:01<00:09,  1.81s/it]\n",
      "\u001b[2m\u001b[36m(pid=3368)\u001b[0m {'loss': 5.0478, 'learning_rate': 0.0001, 'epoch': 0.16}\n",
      " 33%|███▎      | 2/6 [00:02<00:04,  1.04s/it]\n",
      "\u001b[2m\u001b[36m(pid=3368)\u001b[0m {'loss': 3.189, 'learning_rate': 0.0001, 'epoch': 0.32}\n",
      " 50%|█████     | 3/6 [00:02<00:02,  1.26it/s]\n",
      "\u001b[2m\u001b[36m(pid=3368)\u001b[0m {'loss': 3.3061, 'learning_rate': 0.0001, 'epoch': 0.48}\n",
      "\u001b[2m\u001b[36m(pid=3368)\u001b[0m \n",
      "  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      "\u001b[2m\u001b[36m(pid=3368)\u001b[0m \n",
      " 20%|██        | 2/10 [00:00<00:02,  2.91it/s]\u001b[A\n",
      "\u001b[2m\u001b[36m(pid=3368)\u001b[0m \n",
      " 30%|███       | 3/10 [00:01<00:03,  2.03it/s]\u001b[A\n",
      "\u001b[2m\u001b[36m(pid=3368)\u001b[0m \n",
      " 40%|████      | 4/10 [00:02<00:03,  1.69it/s]\u001b[A\n",
      "\u001b[2m\u001b[36m(pid=3368)\u001b[0m \n",
      " 50%|█████     | 5/10 [00:02<00:03,  1.59it/s]\u001b[A\n",
      "\u001b[2m\u001b[36m(pid=3368)\u001b[0m \n",
      " 60%|██████    | 6/10 [00:03<00:02,  1.53it/s]\u001b[A\n",
      "\u001b[2m\u001b[36m(pid=3368)\u001b[0m \n",
      " 70%|███████   | 7/10 [00:04<00:01,  1.50it/s]\u001b[A\n",
      "\u001b[2m\u001b[36m(pid=3368)\u001b[0m \n",
      " 80%|████████  | 8/10 [00:04<00:01,  1.49it/s]\u001b[A\n",
      "\u001b[2m\u001b[36m(pid=3368)\u001b[0m \n",
      " 90%|█████████ | 9/10 [00:05<00:00,  1.47it/s]\u001b[A\n",
      "\u001b[2m\u001b[36m(pid=3368)\u001b[0m \n",
      "100%|██████████| 10/10 [00:06<00:00,  1.46it/s]\u001b[A\n",
      "Result for _inner_1aeff_00001:\n",
      "  date: 2021-02-03_15-06-09\n",
      "  done: false\n",
      "  epoch: 0.48\n",
      "  eval_gen_len: 58.6\n",
      "  eval_loss: 2.444920063018799\n",
      "  eval_rouge1_fmeasure: 0.3565\n",
      "  eval_rouge1_precision: 0.2977\n",
      "  eval_rouge1_recall: 0.49\n",
      "  eval_rouge2_fmeasure: 0.1903\n",
      "  eval_rouge2_precision: 0.1596\n",
      "  eval_rouge2_recall: 0.2605\n",
      "  eval_rougeL_fmeasure: 0.2952\n",
      "  eval_rougeL_precision: 0.2434\n",
      "  eval_rougeL_recall: 0.4089\n",
      "  eval_rougeLsum_fmeasure: 0.3116\n",
      "  eval_rougeLsum_precision: 0.258\n",
      "  eval_rougeLsum_recall: 0.4228\n",
      "  eval_runtime: 7.5776\n",
      "  eval_samples_per_second: 1.32\n",
      "  eval_sentence_distilroberta_cosine: 69.56726312637329\n",
      "  experiment_id: d15599776b624b5f86525eb7320b40d5\n",
      "  hostname: ip-172-31-39-35\n",
      "  iterations_since_restore: 1\n",
      "  node_ip: 172.31.39.35\n",
      "  objective: 82.1593631263733\n",
      "  pid: 3368\n",
      "  time_since_restore: 40.669219970703125\n",
      "  time_this_iter_s: 40.669219970703125\n",
      "  time_total_s: 40.669219970703125\n",
      "  timestamp: 1612364769\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: 1aeff_00001\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 11.3/15.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 1/4 CPUs, 1/1 GPUs, 0.0/5.52 GiB heap, 0.0/1.9 GiB objects (0/1.0 accelerator_type:T4)\n",
      "Result logdir: /home/ubuntu/ray_results/_inner_2021-02-03_15-04-25\n",
      "Number of trials: 3/20 (1 PENDING, 1 RUNNING, 1 TERMINATED)\n",
      "+--------------------+------------+-------------------+-------------------------------+-----------------+-------------+\n",
      "| Trial name         | status     | loc               |   gradient_accumulation_steps |   learning_rate |   objective |\n",
      "|--------------------+------------+-------------------+-------------------------------+-----------------+-------------|\n",
      "| _inner_1aeff_00001 | RUNNING    | 172.31.39.35:3368 |                             8 |          0.0001 |     82.1594 |\n",
      "| _inner_1aeff_00002 | PENDING    |                   |                             4 |          0.0001 |             |\n",
      "| _inner_1aeff_00000 | TERMINATED |                   |                             4 |          1e-05  |     77.5757 |\n",
      "+--------------------+------------+-------------------+-------------------------------+-----------------+-------------+\n",
      "\n",
      "\n",
      "                                             \n",
      " 50%|█████     | 3/6 [00:10<00:02,  1.26it/s]  \n",
      "100%|██████████| 10/10 [00:06<00:00,  1.46it/s]\u001b[A\n",
      "                                               \u001b[A\n",
      "\u001b[2m\u001b[36m(pid=3368)\u001b[0m {'eval_loss': 2.444920063018799, 'eval_rouge1_precision': 0.2977, 'eval_rouge1_recall': 0.49, 'eval_rouge1_fmeasure': 0.3565, 'eval_rouge2_precision': 0.1596, 'eval_rouge2_recall': 0.2605, 'eval_rouge2_fmeasure': 0.1903, 'eval_rougeL_precision': 0.2434, 'eval_rougeL_recall': 0.4089, 'eval_rougeL_fmeasure': 0.2952, 'eval_rougeLsum_precision': 0.258, 'eval_rougeLsum_recall': 0.4228, 'eval_rougeLsum_fmeasure': 0.3116, 'eval_gen_len': 58.6, 'eval_sentence_distilroberta_cosine': 69.56726312637329, 'eval_runtime': 7.5776, 'eval_samples_per_second': 1.32, 'epoch': 0.48}\n",
      " 67%|██████▋   | 4/6 [00:10<00:07,  3.68s/it]\n",
      "\u001b[2m\u001b[36m(pid=3368)\u001b[0m {'loss': 3.4623, 'learning_rate': 0.0001, 'epoch': 0.64}\n",
      " 83%|████████▎ | 5/6 [00:11<00:02,  2.53s/it]\n",
      "\u001b[2m\u001b[36m(pid=3368)\u001b[0m {'loss': 2.7732, 'learning_rate': 0.0001, 'epoch': 0.8}\n",
      "100%|██████████| 6/6 [00:11<00:00,  1.84s/it]\n",
      "100%|██████████| 6/6 [00:11<00:00,  1.84s/it]\n",
      "\u001b[2m\u001b[36m(pid=3368)\u001b[0m {'loss': 2.9249, 'learning_rate': 0.0001, 'epoch': 0.96}\n",
      "\u001b[2m\u001b[36m(pid=3368)\u001b[0m \n",
      "  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      "\u001b[2m\u001b[36m(pid=3368)\u001b[0m \n",
      " 20%|██        | 2/10 [00:00<00:02,  2.94it/s]\u001b[A\n",
      "\u001b[2m\u001b[36m(pid=3368)\u001b[0m \n",
      " 30%|███       | 3/10 [00:01<00:03,  2.05it/s]\u001b[A\n",
      "\u001b[2m\u001b[36m(pid=3368)\u001b[0m \n",
      " 40%|████      | 4/10 [00:02<00:03,  1.70it/s]\u001b[A\n",
      "\u001b[2m\u001b[36m(pid=3368)\u001b[0m \n",
      " 50%|█████     | 5/10 [00:02<00:03,  1.59it/s]\u001b[A\n",
      "\u001b[2m\u001b[36m(pid=3368)\u001b[0m \n",
      " 60%|██████    | 6/10 [00:03<00:02,  1.54it/s]\u001b[A\n",
      "\u001b[2m\u001b[36m(pid=3368)\u001b[0m \n",
      " 70%|███████   | 7/10 [00:04<00:01,  1.50it/s]\u001b[A\n",
      "\u001b[2m\u001b[36m(pid=3368)\u001b[0m \n",
      " 80%|████████  | 8/10 [00:04<00:01,  1.48it/s]\u001b[A\n",
      "\u001b[2m\u001b[36m(pid=3368)\u001b[0m \n",
      " 90%|█████████ | 9/10 [00:05<00:00,  1.47it/s]\u001b[A\n",
      "\u001b[2m\u001b[36m(pid=3368)\u001b[0m \n",
      "100%|██████████| 10/10 [00:06<00:00,  1.46it/s]\u001b[A\n",
      "Result for _inner_1aeff_00001:\n",
      "  date: 2021-02-03_15-06-18\n",
      "  done: false\n",
      "  epoch: 0.96\n",
      "  eval_gen_len: 59.4\n",
      "  eval_loss: 2.4559273719787598\n",
      "  eval_rouge1_fmeasure: 0.3614\n",
      "  eval_rouge1_precision: 0.2984\n",
      "  eval_rouge1_recall: 0.5005\n",
      "  eval_rouge2_fmeasure: 0.1916\n",
      "  eval_rouge2_precision: 0.162\n",
      "  eval_rouge2_recall: 0.2615\n",
      "  eval_rougeL_fmeasure: 0.2993\n",
      "  eval_rougeL_precision: 0.248\n",
      "  eval_rougeL_recall: 0.4115\n",
      "  eval_rougeLsum_fmeasure: 0.3125\n",
      "  eval_rougeLsum_precision: 0.2552\n",
      "  eval_rougeLsum_recall: 0.4379\n",
      "  eval_runtime: 7.3713\n",
      "  eval_samples_per_second: 1.357\n",
      "  eval_sentence_distilroberta_cosine: 67.87294149398804\n",
      "  experiment_id: d15599776b624b5f86525eb7320b40d5\n",
      "  hostname: ip-172-31-39-35\n",
      "  iterations_since_restore: 2\n",
      "  node_ip: 172.31.39.35\n",
      "  objective: 80.34104149398804\n",
      "  pid: 3368\n",
      "  time_since_restore: 49.538039684295654\n",
      "  time_this_iter_s: 8.86881971359253\n",
      "  time_total_s: 49.538039684295654\n",
      "  timestamp: 1612364778\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 2\n",
      "  trial_id: 1aeff_00001\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 11.3/15.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 1/4 CPUs, 1/1 GPUs, 0.0/5.52 GiB heap, 0.0/1.9 GiB objects (0/1.0 accelerator_type:T4)\n",
      "Result logdir: /home/ubuntu/ray_results/_inner_2021-02-03_15-04-25\n",
      "Number of trials: 3/20 (1 PENDING, 1 RUNNING, 1 TERMINATED)\n",
      "+--------------------+------------+-------------------+-------------------------------+-----------------+-------------+\n",
      "| Trial name         | status     | loc               |   gradient_accumulation_steps |   learning_rate |   objective |\n",
      "|--------------------+------------+-------------------+-------------------------------+-----------------+-------------|\n",
      "| _inner_1aeff_00001 | RUNNING    | 172.31.39.35:3368 |                             8 |          0.0001 |     80.341  |\n",
      "| _inner_1aeff_00002 | PENDING    |                   |                             4 |          0.0001 |             |\n",
      "| _inner_1aeff_00000 | TERMINATED |                   |                             4 |          1e-05  |     77.5757 |\n",
      "+--------------------+------------+-------------------+-------------------------------+-----------------+-------------+\n",
      "\n",
      "\n",
      "Result for _inner_1aeff_00001:\n",
      "  date: 2021-02-03_15-06-18\n",
      "  done: true\n",
      "  epoch: 0.96\n",
      "  eval_gen_len: 59.4\n",
      "  eval_loss: 2.4559273719787598\n",
      "  eval_rouge1_fmeasure: 0.3614\n",
      "  eval_rouge1_precision: 0.2984\n",
      "  eval_rouge1_recall: 0.5005\n",
      "  eval_rouge2_fmeasure: 0.1916\n",
      "  eval_rouge2_precision: 0.162\n",
      "  eval_rouge2_recall: 0.2615\n",
      "  eval_rougeL_fmeasure: 0.2993\n",
      "  eval_rougeL_precision: 0.248\n",
      "  eval_rougeL_recall: 0.4115\n",
      "  eval_rougeLsum_fmeasure: 0.3125\n",
      "  eval_rougeLsum_precision: 0.2552\n",
      "  eval_rougeLsum_recall: 0.4379\n",
      "  eval_runtime: 7.3713\n",
      "  eval_samples_per_second: 1.357\n",
      "  eval_sentence_distilroberta_cosine: 67.87294149398804\n",
      "  experiment_id: d15599776b624b5f86525eb7320b40d5\n",
      "  experiment_tag: 1_gradient_accumulation_steps=8,learning_rate=0.0001\n",
      "  hostname: ip-172-31-39-35\n",
      "  iterations_since_restore: 2\n",
      "  node_ip: 172.31.39.35\n",
      "  objective: 80.34104149398804\n",
      "  pid: 3368\n",
      "  time_since_restore: 49.538039684295654\n",
      "  time_this_iter_s: 8.86881971359253\n",
      "  time_total_s: 49.538039684295654\n",
      "  timestamp: 1612364778\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 2\n",
      "  trial_id: 1aeff_00001\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                             \n",
      "100%|██████████| 6/6 [00:19<00:00,  1.84s/it]  \n",
      "100%|██████████| 10/10 [00:06<00:00,  1.46it/s]\u001b[A\n",
      "100%|██████████| 6/6 [00:19<00:00,  3.22s/it]  \u001b[A\n",
      "\u001b[2m\u001b[36m(pid=3368)\u001b[0m {'eval_loss': 2.4559273719787598, 'eval_rouge1_precision': 0.2984, 'eval_rouge1_recall': 0.5005, 'eval_rouge1_fmeasure': 0.3614, 'eval_rouge2_precision': 0.162, 'eval_rouge2_recall': 0.2615, 'eval_rouge2_fmeasure': 0.1916, 'eval_rougeL_precision': 0.248, 'eval_rougeL_recall': 0.4115, 'eval_rougeL_fmeasure': 0.2993, 'eval_rougeLsum_precision': 0.2552, 'eval_rougeLsum_recall': 0.4379, 'eval_rougeLsum_fmeasure': 0.3125, 'eval_gen_len': 59.4, 'eval_sentence_distilroberta_cosine': 67.87294149398804, 'eval_runtime': 7.3713, 'eval_samples_per_second': 1.357, 'epoch': 0.96}\n",
      "\u001b[2m\u001b[36m(pid=3368)\u001b[0m {'train_runtime': 21.4116, 'train_samples_per_second': 0.28, 'epoch': 0.96}\n",
      "\u001b[2m\u001b[36m(pid=3368)\u001b[0m wandb: Waiting for W&B process to finish, PID 3799\n",
      "\u001b[2m\u001b[36m(pid=3368)\u001b[0m wandb: Program ended successfully.\n",
      "\u001b[2m\u001b[36m(pid=3368)\u001b[0m wandb: - 0.04MB of 0.04MB uploaded (0.00MB deduped)\n",
      "wandb:                                                                                \n",
      "\u001b[2m\u001b[36m(pid=3368)\u001b[0m wandb: Find user logs for this run at: /home/ubuntu/ray_results/_inner_2021-02-03_15-04-25/_inner_1aeff_00001_1_gradient_accumulation_steps=8,learning_rate=0.0001_2021-02-03_15-05-28/wandb/run-20210203_150558-ja04x0p3/logs/debug.log\n",
      "\u001b[2m\u001b[36m(pid=3368)\u001b[0m wandb: Find internal logs for this run at: /home/ubuntu/ray_results/_inner_2021-02-03_15-04-25/_inner_1aeff_00001_1_gradient_accumulation_steps=8,learning_rate=0.0001_2021-02-03_15-05-28/wandb/run-20210203_150558-ja04x0p3/logs/debug-internal.log\n",
      "\u001b[2m\u001b[36m(pid=3368)\u001b[0m wandb: Run summary:\n",
      "\u001b[2m\u001b[36m(pid=3368)\u001b[0m wandb:                           train/loss 2.9249\n",
      "\u001b[2m\u001b[36m(pid=3368)\u001b[0m wandb:                  train/learning_rate 0.0001\n",
      "\u001b[2m\u001b[36m(pid=3368)\u001b[0m wandb:                          train/epoch 0.96\n",
      "\u001b[2m\u001b[36m(pid=3368)\u001b[0m wandb:                                _step 6\n",
      "\u001b[2m\u001b[36m(pid=3368)\u001b[0m wandb:                             _runtime 20\n",
      "\u001b[2m\u001b[36m(pid=3368)\u001b[0m wandb:                           _timestamp 1612364778\n",
      "\u001b[2m\u001b[36m(pid=3368)\u001b[0m wandb:                            eval/loss 2.45593\n",
      "\u001b[2m\u001b[36m(pid=3368)\u001b[0m wandb:                eval/rouge1_precision 0.2984\n",
      "\u001b[2m\u001b[36m(pid=3368)\u001b[0m wandb:                   eval/rouge1_recall 0.5005\n",
      "\u001b[2m\u001b[36m(pid=3368)\u001b[0m wandb:                 eval/rouge1_fmeasure 0.3614\n",
      "\u001b[2m\u001b[36m(pid=3368)\u001b[0m wandb:                eval/rouge2_precision 0.162\n",
      "\u001b[2m\u001b[36m(pid=3368)\u001b[0m wandb:                   eval/rouge2_recall 0.2615\n",
      "\u001b[2m\u001b[36m(pid=3368)\u001b[0m wandb:                 eval/rouge2_fmeasure 0.1916\n",
      "\u001b[2m\u001b[36m(pid=3368)\u001b[0m wandb:                eval/rougeL_precision 0.248\n",
      "\u001b[2m\u001b[36m(pid=3368)\u001b[0m wandb:                   eval/rougeL_recall 0.4115\n",
      "\u001b[2m\u001b[36m(pid=3368)\u001b[0m wandb:                 eval/rougeL_fmeasure 0.2993\n",
      "\u001b[2m\u001b[36m(pid=3368)\u001b[0m wandb:             eval/rougeLsum_precision 0.2552\n",
      "\u001b[2m\u001b[36m(pid=3368)\u001b[0m wandb:                eval/rougeLsum_recall 0.4379\n",
      "\u001b[2m\u001b[36m(pid=3368)\u001b[0m wandb:              eval/rougeLsum_fmeasure 0.3125\n",
      "\u001b[2m\u001b[36m(pid=3368)\u001b[0m wandb:                         eval/gen_len 59.4\n",
      "\u001b[2m\u001b[36m(pid=3368)\u001b[0m wandb:   eval/sentence_distilroberta_cosine 67.87294\n",
      "\u001b[2m\u001b[36m(pid=3368)\u001b[0m wandb:                         eval/runtime 7.3713\n",
      "\u001b[2m\u001b[36m(pid=3368)\u001b[0m wandb:              eval/samples_per_second 1.357\n",
      "\u001b[2m\u001b[36m(pid=3368)\u001b[0m wandb:                  train/train_runtime 21.4116\n",
      "\u001b[2m\u001b[36m(pid=3368)\u001b[0m wandb:       train/train_samples_per_second 0.28\n",
      "\u001b[2m\u001b[36m(pid=3368)\u001b[0m wandb:                     train/total_flos 16767021772800\n",
      "\u001b[2m\u001b[36m(pid=3368)\u001b[0m wandb: Run history:\n",
      "\u001b[2m\u001b[36m(pid=3368)\u001b[0m wandb:                           train/loss █▂▃▃▁▁\n",
      "\u001b[2m\u001b[36m(pid=3368)\u001b[0m wandb:                  train/learning_rate ▁▁▁▁▁▁\n",
      "\u001b[2m\u001b[36m(pid=3368)\u001b[0m wandb:                          train/epoch ▁▂▄▅▇█\n",
      "\u001b[2m\u001b[36m(pid=3368)\u001b[0m wandb:                                _step ▁▂▄▅▇█\n",
      "\u001b[2m\u001b[36m(pid=3368)\u001b[0m wandb:                             _runtime ▁▁▅▅▅█\n",
      "\u001b[2m\u001b[36m(pid=3368)\u001b[0m wandb:                           _timestamp ▁▁▅▅▅█\n",
      "\u001b[2m\u001b[36m(pid=3368)\u001b[0m wandb:                            eval/loss ▁█\n",
      "\u001b[2m\u001b[36m(pid=3368)\u001b[0m wandb:                eval/rouge1_precision ▁█\n",
      "\u001b[2m\u001b[36m(pid=3368)\u001b[0m wandb:                   eval/rouge1_recall ▁█\n",
      "\u001b[2m\u001b[36m(pid=3368)\u001b[0m wandb:                 eval/rouge1_fmeasure ▁█\n",
      "\u001b[2m\u001b[36m(pid=3368)\u001b[0m wandb:                eval/rouge2_precision ▁█\n",
      "\u001b[2m\u001b[36m(pid=3368)\u001b[0m wandb:                   eval/rouge2_recall ▁█\n",
      "\u001b[2m\u001b[36m(pid=3368)\u001b[0m wandb:                 eval/rouge2_fmeasure ▁█\n",
      "\u001b[2m\u001b[36m(pid=3368)\u001b[0m wandb:                eval/rougeL_precision ▁█\n",
      "\u001b[2m\u001b[36m(pid=3368)\u001b[0m wandb:                   eval/rougeL_recall ▁█\n",
      "\u001b[2m\u001b[36m(pid=3368)\u001b[0m wandb:                 eval/rougeL_fmeasure ▁█\n",
      "\u001b[2m\u001b[36m(pid=3368)\u001b[0m wandb:             eval/rougeLsum_precision █▁\n",
      "\u001b[2m\u001b[36m(pid=3368)\u001b[0m wandb:                eval/rougeLsum_recall ▁█\n",
      "\u001b[2m\u001b[36m(pid=3368)\u001b[0m wandb:              eval/rougeLsum_fmeasure ▁█\n",
      "\u001b[2m\u001b[36m(pid=3368)\u001b[0m wandb:                         eval/gen_len ▁█\n",
      "\u001b[2m\u001b[36m(pid=3368)\u001b[0m wandb:   eval/sentence_distilroberta_cosine █▁\n",
      "\u001b[2m\u001b[36m(pid=3368)\u001b[0m wandb:                         eval/runtime █▁\n",
      "\u001b[2m\u001b[36m(pid=3368)\u001b[0m wandb:              eval/samples_per_second ▁█\n",
      "\u001b[2m\u001b[36m(pid=3368)\u001b[0m wandb:                  train/train_runtime ▁\n",
      "\u001b[2m\u001b[36m(pid=3368)\u001b[0m wandb:       train/train_samples_per_second ▁\n",
      "\u001b[2m\u001b[36m(pid=3368)\u001b[0m wandb:                     train/total_flos ▁\n",
      "\u001b[2m\u001b[36m(pid=3368)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(pid=3368)\u001b[0m wandb: Synced 5 W&B file(s), 1 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[2m\u001b[36m(pid=3368)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(pid=3368)\u001b[0m wandb: Synced /home/ubuntu/s3/fine-tuning/hyperparameters_test: https://wandb.ai/marcoabrate/hp_search_para_wordembed/runs/ja04x0p3\n",
      "\u001b[2m\u001b[36m(pid=3368)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=3370)\u001b[0m wandb: Currently logged in as: marcoabrate (use `wandb login --relogin` to force relogin)\n",
      "\u001b[2m\u001b[36m(pid=3370)\u001b[0m wandb: wandb version 0.10.17 is available!  To upgrade, please run:\n",
      "\u001b[2m\u001b[36m(pid=3370)\u001b[0m wandb:  $ pip install wandb --upgrade\n",
      "\u001b[2m\u001b[36m(pid=3370)\u001b[0m wandb: Tracking run with wandb version 0.10.14\n",
      "\u001b[2m\u001b[36m(pid=3370)\u001b[0m wandb: Syncing run /home/ubuntu/s3/fine-tuning/hyperparameters_test\n",
      "\u001b[2m\u001b[36m(pid=3370)\u001b[0m wandb: ⭐️ View project at https://wandb.ai/marcoabrate/hp_search_para_wordembed\n",
      "\u001b[2m\u001b[36m(pid=3370)\u001b[0m wandb: 🚀 View run at https://wandb.ai/marcoabrate/hp_search_para_wordembed/runs/2wx99tx3\n",
      "\u001b[2m\u001b[36m(pid=3370)\u001b[0m wandb: Run data is saved locally in /home/ubuntu/ray_results/_inner_2021-02-03_15-04-25/_inner_1aeff_00002_2_gradient_accumulation_steps=4,learning_rate=0.0001_2021-02-03_15-06-18/wandb/run-20210203_150647-2wx99tx3\n",
      "\u001b[2m\u001b[36m(pid=3370)\u001b[0m wandb: Run `wandb offline` to turn off syncing.\n",
      "\u001b[2m\u001b[36m(pid=3370)\u001b[0m \n",
      "  0%|          | 0/12 [00:00<?, ?it/s]\n",
      "\u001b[2m\u001b[36m(pid=3370)\u001b[0m /home/ubuntu/miniconda3/envs/magma/lib/python3.6/site-packages/torch/optim/lr_scheduler.py:136: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "\u001b[2m\u001b[36m(pid=3370)\u001b[0m   \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n",
      "  8%|▊         | 1/12 [00:00<00:09,  1.13it/s]\n",
      "\u001b[2m\u001b[36m(pid=3370)\u001b[0m {'loss': 6.2597, 'learning_rate': 0.0001, 'epoch': 0.08}\n",
      " 17%|█▋        | 2/12 [00:01<00:05,  1.88it/s]\n",
      "\u001b[2m\u001b[36m(pid=3370)\u001b[0m {'loss': 3.8359, 'learning_rate': 0.0001, 'epoch': 0.16}\n",
      " 25%|██▌       | 3/12 [00:01<00:03,  2.39it/s]\n",
      "\u001b[2m\u001b[36m(pid=3370)\u001b[0m {'loss': 2.6121, 'learning_rate': 0.0001, 'epoch': 0.24}\n",
      "\u001b[2m\u001b[36m(pid=3370)\u001b[0m \n",
      "  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      "\u001b[2m\u001b[36m(pid=3370)\u001b[0m \n",
      " 20%|██        | 2/10 [00:00<00:02,  2.87it/s]\u001b[A\n",
      "\u001b[2m\u001b[36m(pid=3370)\u001b[0m \n",
      " 30%|███       | 3/10 [00:01<00:03,  2.00it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=3370)\u001b[0m \n",
      " 40%|████      | 4/10 [00:02<00:03,  1.67it/s]\u001b[A\n",
      "\u001b[2m\u001b[36m(pid=3370)\u001b[0m \n",
      " 50%|█████     | 5/10 [00:02<00:03,  1.57it/s]\u001b[A\n",
      "\u001b[2m\u001b[36m(pid=3370)\u001b[0m \n",
      " 60%|██████    | 6/10 [00:03<00:02,  1.52it/s]\u001b[A\n",
      "\u001b[2m\u001b[36m(pid=3370)\u001b[0m \n",
      " 70%|███████   | 7/10 [00:04<00:02,  1.50it/s]\u001b[A\n",
      "\u001b[2m\u001b[36m(pid=3370)\u001b[0m \n",
      " 80%|████████  | 8/10 [00:04<00:01,  1.48it/s]\u001b[A\n",
      "\u001b[2m\u001b[36m(pid=3370)\u001b[0m \n",
      " 90%|█████████ | 9/10 [00:05<00:00,  1.46it/s]\u001b[A\n",
      "\u001b[2m\u001b[36m(pid=3370)\u001b[0m \n",
      "100%|██████████| 10/10 [00:06<00:00,  1.45it/s]\u001b[A\n",
      "Result for _inner_1aeff_00002:\n",
      "  date: 2021-02-03_15-06-57\n",
      "  done: false\n",
      "  epoch: 0.24\n",
      "  eval_gen_len: 59.8\n",
      "  eval_loss: 2.5498046875\n",
      "  eval_rouge1_fmeasure: 0.3174\n",
      "  eval_rouge1_precision: 0.2654\n",
      "  eval_rouge1_recall: 0.4285\n",
      "  eval_rouge2_fmeasure: 0.1462\n",
      "  eval_rouge2_precision: 0.1205\n",
      "  eval_rouge2_recall: 0.2037\n",
      "  eval_rougeL_fmeasure: 0.2561\n",
      "  eval_rougeL_precision: 0.2123\n",
      "  eval_rougeL_recall: 0.3535\n",
      "  eval_rougeLsum_fmeasure: 0.2504\n",
      "  eval_rougeLsum_precision: 0.2059\n",
      "  eval_rougeLsum_recall: 0.343\n",
      "  eval_runtime: 7.5998\n",
      "  eval_samples_per_second: 1.316\n",
      "  eval_sentence_distilroberta_cosine: 61.60591244697571\n",
      "  experiment_id: 5289568eca8d4fdabacf7644fd10299e\n",
      "  hostname: ip-172-31-39-35\n",
      "  iterations_since_restore: 1\n",
      "  node_ip: 172.31.39.35\n",
      "  objective: 73.62461244697572\n",
      "  pid: 3370\n",
      "  time_since_restore: 38.684734582901\n",
      "  time_this_iter_s: 38.684734582901\n",
      "  time_total_s: 38.684734582901\n",
      "  timestamp: 1612364817\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: 1aeff_00002\n",
      "  \n",
      "                                              \n",
      " 25%|██▌       | 3/12 [00:09<00:03,  2.39it/s] \n",
      "100%|██████████| 10/10 [00:06<00:00,  1.45it/s]\u001b[A\n",
      "                                               \u001b[A\n",
      "\u001b[2m\u001b[36m(pid=3370)\u001b[0m {'eval_loss': 2.5498046875, 'eval_rouge1_precision': 0.2654, 'eval_rouge1_recall': 0.4285, 'eval_rouge1_fmeasure': 0.3174, 'eval_rouge2_precision': 0.1205, 'eval_rouge2_recall': 0.2037, 'eval_rouge2_fmeasure': 0.1462, 'eval_rougeL_precision': 0.2123, 'eval_rougeL_recall': 0.3535, 'eval_rougeL_fmeasure': 0.2561, 'eval_rougeLsum_precision': 0.2059, 'eval_rougeLsum_recall': 0.343, 'eval_rougeLsum_fmeasure': 0.2504, 'eval_gen_len': 59.8, 'eval_sentence_distilroberta_cosine': 61.60591244697571, 'eval_runtime': 7.5998, 'eval_samples_per_second': 1.316, 'epoch': 0.24}\n",
      "== Status ==\n",
      "Memory usage on this node: 11.4/15.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 1/4 CPUs, 1/1 GPUs, 0.0/5.52 GiB heap, 0.0/1.9 GiB objects (0/1.0 accelerator_type:T4)\n",
      "Result logdir: /home/ubuntu/ray_results/_inner_2021-02-03_15-04-25\n",
      "Number of trials: 4/20 (1 PENDING, 1 RUNNING, 2 TERMINATED)\n",
      "+--------------------+------------+-------------------+-------------------------------+-----------------+-------------+\n",
      "| Trial name         | status     | loc               |   gradient_accumulation_steps |   learning_rate |   objective |\n",
      "|--------------------+------------+-------------------+-------------------------------+-----------------+-------------|\n",
      "| _inner_1aeff_00002 | RUNNING    | 172.31.39.35:3370 |                             4 |          0.0001 |     73.6246 |\n",
      "| _inner_1aeff_00003 | PENDING    |                   |                             4 |          1e-05  |             |\n",
      "| _inner_1aeff_00000 | TERMINATED |                   |                             4 |          1e-05  |     77.5757 |\n",
      "| _inner_1aeff_00001 | TERMINATED |                   |                             8 |          0.0001 |     80.341  |\n",
      "+--------------------+------------+-------------------+-------------------------------+-----------------+-------------+\n",
      "\n",
      "\n",
      " 33%|███▎      | 4/12 [00:09<00:26,  3.37s/it]\n",
      "\u001b[2m\u001b[36m(pid=3370)\u001b[0m {'loss': 2.4654, 'learning_rate': 0.0001, 'epoch': 0.32}\n",
      " 42%|████▏     | 5/12 [00:09<00:15,  2.25s/it]\n",
      " 42%|████▏     | 5/12 [00:09<00:15,  2.25s/it]\n",
      "\u001b[2m\u001b[36m(pid=3370)\u001b[0m {'loss': 3.8621, 'learning_rate': 0.0001, 'epoch': 0.4}\n",
      " 50%|█████     | 6/12 [00:09<00:09,  1.58s/it]\n",
      "\u001b[2m\u001b[36m(pid=3370)\u001b[0m {'loss': 2.8656, 'learning_rate': 0.0001, 'epoch': 0.48}\n",
      "\u001b[2m\u001b[36m(pid=3370)\u001b[0m \n",
      "  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      "\u001b[2m\u001b[36m(pid=3370)\u001b[0m \n",
      " 20%|██        | 2/10 [00:00<00:02,  2.87it/s]\u001b[A\n",
      "\u001b[2m\u001b[36m(pid=3370)\u001b[0m \n",
      " 30%|███       | 3/10 [00:01<00:03,  2.01it/s]\u001b[A\n",
      "\u001b[2m\u001b[36m(pid=3370)\u001b[0m \n",
      " 40%|████      | 4/10 [00:02<00:03,  1.67it/s]\u001b[A\n",
      "\u001b[2m\u001b[36m(pid=3370)\u001b[0m \n",
      " 50%|█████     | 5/10 [00:02<00:03,  1.60it/s]\u001b[A\n",
      "\u001b[2m\u001b[36m(pid=3370)\u001b[0m \n",
      " 60%|██████    | 6/10 [00:03<00:02,  1.54it/s]\u001b[A\n",
      "\u001b[2m\u001b[36m(pid=3370)\u001b[0m \n",
      " 70%|███████   | 7/10 [00:04<00:01,  1.51it/s]\u001b[A\n",
      "\u001b[2m\u001b[36m(pid=3370)\u001b[0m \n",
      " 80%|████████  | 8/10 [00:04<00:01,  1.49it/s]\u001b[A\n",
      "\u001b[2m\u001b[36m(pid=3370)\u001b[0m \n",
      " 90%|█████████ | 9/10 [00:05<00:00,  1.47it/s]\u001b[A\n",
      "\u001b[2m\u001b[36m(pid=3370)\u001b[0m \n",
      "100%|██████████| 10/10 [00:06<00:00,  1.46it/s]\u001b[A\n",
      "Result for _inner_1aeff_00002:\n",
      "  date: 2021-02-03_15-07-05\n",
      "  done: false\n",
      "  epoch: 0.48\n",
      "  eval_gen_len: 58.8\n",
      "  eval_loss: 2.4523048400878906\n",
      "  eval_rouge1_fmeasure: 0.3447\n",
      "  eval_rouge1_precision: 0.2815\n",
      "  eval_rouge1_recall: 0.4873\n",
      "  eval_rouge2_fmeasure: 0.168\n",
      "  eval_rouge2_precision: 0.1382\n",
      "  eval_rouge2_recall: 0.2411\n",
      "  eval_rougeL_fmeasure: 0.2724\n",
      "  eval_rougeL_precision: 0.2192\n",
      "  eval_rougeL_recall: 0.3915\n",
      "  eval_rougeLsum_fmeasure: 0.2917\n",
      "  eval_rougeLsum_precision: 0.2362\n",
      "  eval_rougeLsum_recall: 0.4149\n",
      "  eval_runtime: 7.3808\n",
      "  eval_samples_per_second: 1.355\n",
      "  eval_sentence_distilroberta_cosine: 68.52725744247437\n",
      "  experiment_id: 5289568eca8d4fdabacf7644fd10299e\n",
      "  hostname: ip-172-31-39-35\n",
      "  iterations_since_restore: 2\n",
      "  node_ip: 172.31.39.35\n",
      "  objective: 80.74975744247436\n",
      "  pid: 3370\n",
      "  time_since_restore: 46.913822174072266\n",
      "  time_this_iter_s: 8.229087591171265\n",
      "  time_total_s: 46.913822174072266\n",
      "  timestamp: 1612364825\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 2\n",
      "  trial_id: 1aeff_00002\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 11.4/15.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 1/4 CPUs, 1/1 GPUs, 0.0/5.52 GiB heap, 0.0/1.9 GiB objects (0/1.0 accelerator_type:T4)\n",
      "Result logdir: /home/ubuntu/ray_results/_inner_2021-02-03_15-04-25\n",
      "Number of trials: 4/20 (1 PENDING, 1 RUNNING, 2 TERMINATED)\n",
      "+--------------------+------------+-------------------+-------------------------------+-----------------+-------------+\n",
      "| Trial name         | status     | loc               |   gradient_accumulation_steps |   learning_rate |   objective |\n",
      "|--------------------+------------+-------------------+-------------------------------+-----------------+-------------|\n",
      "| _inner_1aeff_00002 | RUNNING    | 172.31.39.35:3370 |                             4 |          0.0001 |     80.7498 |\n",
      "| _inner_1aeff_00003 | PENDING    |                   |                             4 |          1e-05  |             |\n",
      "| _inner_1aeff_00000 | TERMINATED |                   |                             4 |          1e-05  |     77.5757 |\n",
      "| _inner_1aeff_00001 | TERMINATED |                   |                             8 |          0.0001 |     80.341  |\n",
      "+--------------------+------------+-------------------+-------------------------------+-----------------+-------------+\n",
      "\n",
      "\n",
      "                                              \n",
      " 50%|█████     | 6/12 [00:17<00:09,  1.58s/it] \n",
      "100%|██████████| 10/10 [00:06<00:00,  1.46it/s]\u001b[A\n",
      "                                               \u001b[A\n",
      "\u001b[2m\u001b[36m(pid=3370)\u001b[0m {'eval_loss': 2.4523048400878906, 'eval_rouge1_precision': 0.2815, 'eval_rouge1_recall': 0.4873, 'eval_rouge1_fmeasure': 0.3447, 'eval_rouge2_precision': 0.1382, 'eval_rouge2_recall': 0.2411, 'eval_rouge2_fmeasure': 0.168, 'eval_rougeL_precision': 0.2192, 'eval_rougeL_recall': 0.3915, 'eval_rougeL_fmeasure': 0.2724, 'eval_rougeLsum_precision': 0.2362, 'eval_rougeLsum_recall': 0.4149, 'eval_rougeLsum_fmeasure': 0.2917, 'eval_gen_len': 58.8, 'eval_sentence_distilroberta_cosine': 68.52725744247437, 'eval_runtime': 7.3808, 'eval_samples_per_second': 1.355, 'epoch': 0.48}\n",
      " 58%|█████▊    | 7/12 [00:17<00:17,  3.57s/it]\n",
      "\u001b[2m\u001b[36m(pid=3370)\u001b[0m {'loss': 3.8248, 'learning_rate': 0.0001, 'epoch': 0.56}\n",
      " 67%|██████▋   | 8/12 [00:17<00:10,  2.52s/it]\n",
      "\u001b[2m\u001b[36m(pid=3370)\u001b[0m {'loss': 3.167, 'learning_rate': 0.0001, 'epoch': 0.64}\n",
      " 75%|███████▌  | 9/12 [00:18<00:05,  1.82s/it]\n",
      "\u001b[2m\u001b[36m(pid=3370)\u001b[0m {'loss': 2.2797, 'learning_rate': 0.0001, 'epoch': 0.72}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=3370)\u001b[0m \n",
      "  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      "\u001b[2m\u001b[36m(pid=3370)\u001b[0m \n",
      " 20%|██        | 2/10 [00:00<00:02,  2.85it/s]\u001b[A\n",
      "\u001b[2m\u001b[36m(pid=3370)\u001b[0m \n",
      " 30%|███       | 3/10 [00:01<00:03,  1.99it/s]\u001b[A\n",
      "\u001b[2m\u001b[36m(pid=3370)\u001b[0m \n",
      " 40%|████      | 4/10 [00:02<00:03,  1.67it/s]\u001b[A\n",
      "\u001b[2m\u001b[36m(pid=3370)\u001b[0m \n",
      " 50%|█████     | 5/10 [00:02<00:03,  1.58it/s]\u001b[A\n",
      "\u001b[2m\u001b[36m(pid=3370)\u001b[0m \n",
      " 60%|██████    | 6/10 [00:03<00:02,  1.54it/s]\u001b[A\n",
      "\u001b[2m\u001b[36m(pid=3370)\u001b[0m \n",
      " 70%|███████   | 7/10 [00:04<00:01,  1.51it/s]\u001b[A\n",
      "\u001b[2m\u001b[36m(pid=3370)\u001b[0m \n",
      " 80%|████████  | 8/10 [00:04<00:01,  1.48it/s]\u001b[A\n",
      "\u001b[2m\u001b[36m(pid=3370)\u001b[0m \n",
      " 90%|█████████ | 9/10 [00:05<00:00,  1.47it/s]\u001b[A\n",
      "\u001b[2m\u001b[36m(pid=3370)\u001b[0m \n",
      "100%|██████████| 10/10 [00:06<00:00,  1.46it/s]\u001b[A\n",
      "Result for _inner_1aeff_00002:\n",
      "  date: 2021-02-03_15-07-14\n",
      "  done: false\n",
      "  epoch: 0.72\n",
      "  eval_gen_len: 59.7\n",
      "  eval_loss: 2.4825830459594727\n",
      "  eval_rouge1_fmeasure: 0.3324\n",
      "  eval_rouge1_precision: 0.2729\n",
      "  eval_rouge1_recall: 0.4666\n",
      "  eval_rouge2_fmeasure: 0.1713\n",
      "  eval_rouge2_precision: 0.1423\n",
      "  eval_rouge2_recall: 0.2368\n",
      "  eval_rougeL_fmeasure: 0.2758\n",
      "  eval_rougeL_precision: 0.2266\n",
      "  eval_rougeL_recall: 0.3908\n",
      "  eval_rougeLsum_fmeasure: 0.27\n",
      "  eval_rougeLsum_precision: 0.2212\n",
      "  eval_rougeLsum_recall: 0.3844\n",
      "  eval_runtime: 7.4093\n",
      "  eval_samples_per_second: 1.35\n",
      "  eval_sentence_distilroberta_cosine: 66.97741150856018\n",
      "  experiment_id: 5289568eca8d4fdabacf7644fd10299e\n",
      "  hostname: ip-172-31-39-35\n",
      "  iterations_since_restore: 3\n",
      "  node_ip: 172.31.39.35\n",
      "  objective: 79.12781150856017\n",
      "  pid: 3370\n",
      "  time_since_restore: 55.13868427276611\n",
      "  time_this_iter_s: 8.224862098693848\n",
      "  time_total_s: 55.13868427276611\n",
      "  timestamp: 1612364834\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 3\n",
      "  trial_id: 1aeff_00002\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 11.4/15.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 1/4 CPUs, 1/1 GPUs, 0.0/5.52 GiB heap, 0.0/1.9 GiB objects (0/1.0 accelerator_type:T4)\n",
      "Result logdir: /home/ubuntu/ray_results/_inner_2021-02-03_15-04-25\n",
      "Number of trials: 4/20 (1 PENDING, 1 RUNNING, 2 TERMINATED)\n",
      "+--------------------+------------+-------------------+-------------------------------+-----------------+-------------+\n",
      "| Trial name         | status     | loc               |   gradient_accumulation_steps |   learning_rate |   objective |\n",
      "|--------------------+------------+-------------------+-------------------------------+-----------------+-------------|\n",
      "| _inner_1aeff_00002 | RUNNING    | 172.31.39.35:3370 |                             4 |          0.0001 |     79.1278 |\n",
      "| _inner_1aeff_00003 | PENDING    |                   |                             4 |          1e-05  |             |\n",
      "| _inner_1aeff_00000 | TERMINATED |                   |                             4 |          1e-05  |     77.5757 |\n",
      "| _inner_1aeff_00001 | TERMINATED |                   |                             8 |          0.0001 |     80.341  |\n",
      "+--------------------+------------+-------------------+-------------------------------+-----------------+-------------+\n",
      "\n",
      "\n",
      "                                              \n",
      " 75%|███████▌  | 9/12 [00:25<00:05,  1.82s/it] \n",
      "100%|██████████| 10/10 [00:06<00:00,  1.46it/s]\u001b[A\n",
      "                                               \u001b[A\n",
      "\u001b[2m\u001b[36m(pid=3370)\u001b[0m {'eval_loss': 2.4825830459594727, 'eval_rouge1_precision': 0.2729, 'eval_rouge1_recall': 0.4666, 'eval_rouge1_fmeasure': 0.3324, 'eval_rouge2_precision': 0.1423, 'eval_rouge2_recall': 0.2368, 'eval_rouge2_fmeasure': 0.1713, 'eval_rougeL_precision': 0.2266, 'eval_rougeL_recall': 0.3908, 'eval_rougeL_fmeasure': 0.2758, 'eval_rougeLsum_precision': 0.2212, 'eval_rougeLsum_recall': 0.3844, 'eval_rougeLsum_fmeasure': 0.27, 'eval_gen_len': 59.7, 'eval_sentence_distilroberta_cosine': 66.97741150856018, 'eval_runtime': 7.4093, 'eval_samples_per_second': 1.35, 'epoch': 0.72}\n",
      " 83%|████████▎ | 10/12 [00:25<00:07,  3.63s/it]\n",
      " 83%|████████▎ | 10/12 [00:25<00:07,  3.63s/it]\n",
      "\u001b[2m\u001b[36m(pid=3370)\u001b[0m {'loss': 3.4682, 'learning_rate': 0.0001, 'epoch': 0.8}\n",
      " 92%|█████████▏| 11/12 [00:26<00:02,  2.60s/it]\n",
      "\u001b[2m\u001b[36m(pid=3370)\u001b[0m {'loss': 2.7332, 'learning_rate': 0.0001, 'epoch': 0.88}\n",
      "100%|██████████| 12/12 [00:26<00:00,  1.90s/it]\n",
      "100%|██████████| 12/12 [00:26<00:00,  1.90s/it]\n",
      "\u001b[2m\u001b[36m(pid=3370)\u001b[0m {'loss': 3.0884, 'learning_rate': 0.0001, 'epoch': 0.96}\n",
      "\u001b[2m\u001b[36m(pid=3370)\u001b[0m \n",
      "  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      "\u001b[2m\u001b[36m(pid=3370)\u001b[0m \n",
      " 20%|██        | 2/10 [00:00<00:02,  2.89it/s]\u001b[A\n",
      "\u001b[2m\u001b[36m(pid=3370)\u001b[0m \n",
      " 30%|███       | 3/10 [00:01<00:03,  2.03it/s]\u001b[A\n",
      "\u001b[2m\u001b[36m(pid=3370)\u001b[0m \n",
      " 40%|████      | 4/10 [00:02<00:03,  1.69it/s]\u001b[A\n",
      "\u001b[2m\u001b[36m(pid=3370)\u001b[0m \n",
      " 50%|█████     | 5/10 [00:02<00:03,  1.59it/s]\u001b[A\n",
      "\u001b[2m\u001b[36m(pid=3370)\u001b[0m \n",
      " 60%|██████    | 6/10 [00:03<00:02,  1.53it/s]\u001b[A\n",
      "\u001b[2m\u001b[36m(pid=3370)\u001b[0m \n",
      " 70%|███████   | 7/10 [00:04<00:01,  1.50it/s]\u001b[A\n",
      "\u001b[2m\u001b[36m(pid=3370)\u001b[0m \n",
      " 80%|████████  | 8/10 [00:04<00:01,  1.49it/s]\u001b[A\n",
      "\u001b[2m\u001b[36m(pid=3370)\u001b[0m \n",
      " 90%|█████████ | 9/10 [00:05<00:00,  1.47it/s]\u001b[A\n",
      "\u001b[2m\u001b[36m(pid=3370)\u001b[0m \n",
      "100%|██████████| 10/10 [00:06<00:00,  1.46it/s]\u001b[A\n",
      "Result for _inner_1aeff_00002:\n",
      "  date: 2021-02-03_15-07-22\n",
      "  done: false\n",
      "  epoch: 0.96\n",
      "  eval_gen_len: 59.7\n",
      "  eval_loss: 2.453468084335327\n",
      "  eval_rouge1_fmeasure: 0.3106\n",
      "  eval_rouge1_precision: 0.2542\n",
      "  eval_rouge1_recall: 0.4347\n",
      "  eval_rouge2_fmeasure: 0.1465\n",
      "  eval_rouge2_precision: 0.1165\n",
      "  eval_rouge2_recall: 0.2121\n",
      "  eval_rougeL_fmeasure: 0.2598\n",
      "  eval_rougeL_precision: 0.2089\n",
      "  eval_rougeL_recall: 0.3674\n",
      "  eval_rougeLsum_fmeasure: 0.2637\n",
      "  eval_rougeLsum_precision: 0.2141\n",
      "  eval_rougeLsum_recall: 0.3673\n",
      "  eval_runtime: 7.4007\n",
      "  eval_samples_per_second: 1.351\n",
      "  eval_sentence_distilroberta_cosine: 68.26246976852417\n",
      "  experiment_id: 5289568eca8d4fdabacf7644fd10299e\n",
      "  hostname: ip-172-31-39-35\n",
      "  iterations_since_restore: 4\n",
      "  node_ip: 172.31.39.35\n",
      "  objective: 80.16996976852417\n",
      "  pid: 3370\n",
      "  time_since_restore: 63.3898138999939\n",
      "  time_this_iter_s: 8.251129627227783\n",
      "  time_total_s: 63.3898138999939\n",
      "  timestamp: 1612364842\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 4\n",
      "  trial_id: 1aeff_00002\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 11.4/15.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 1/4 CPUs, 1/1 GPUs, 0.0/5.52 GiB heap, 0.0/1.9 GiB objects (0/1.0 accelerator_type:T4)\n",
      "Result logdir: /home/ubuntu/ray_results/_inner_2021-02-03_15-04-25\n",
      "Number of trials: 4/20 (1 PENDING, 1 RUNNING, 2 TERMINATED)\n",
      "+--------------------+------------+-------------------+-------------------------------+-----------------+-------------+\n",
      "| Trial name         | status     | loc               |   gradient_accumulation_steps |   learning_rate |   objective |\n",
      "|--------------------+------------+-------------------+-------------------------------+-----------------+-------------|\n",
      "| _inner_1aeff_00002 | RUNNING    | 172.31.39.35:3370 |                             4 |          0.0001 |     80.17   |\n",
      "| _inner_1aeff_00003 | PENDING    |                   |                             4 |          1e-05  |             |\n",
      "| _inner_1aeff_00000 | TERMINATED |                   |                             4 |          1e-05  |     77.5757 |\n",
      "| _inner_1aeff_00001 | TERMINATED |                   |                             8 |          0.0001 |     80.341  |\n",
      "+--------------------+------------+-------------------+-------------------------------+-----------------+-------------+\n",
      "\n",
      "\n",
      "                                               \n",
      "100%|██████████| 12/12 [00:33<00:00,  1.90s/it]\n",
      "100%|██████████| 10/10 [00:06<00:00,  1.46it/s]\u001b[A\n",
      "100%|██████████| 12/12 [00:33<00:00,  1.90s/it]\u001b[A\n",
      "\u001b[2m\u001b[36m(pid=3370)\u001b[0m {'eval_loss': 2.453468084335327, 'eval_rouge1_precision': 0.2542, 'eval_rouge1_recall': 0.4347, 'eval_rouge1_fmeasure': 0.3106, 'eval_rouge2_precision': 0.1165, 'eval_rouge2_recall': 0.2121, 'eval_rouge2_fmeasure': 0.1465, 'eval_rougeL_precision': 0.2089, 'eval_rougeL_recall': 0.3674, 'eval_rougeL_fmeasure': 0.2598, 'eval_rougeLsum_precision': 0.2141, 'eval_rougeLsum_recall': 0.3673, 'eval_rougeLsum_fmeasure': 0.2637, 'eval_gen_len': 59.7, 'eval_sentence_distilroberta_cosine': 68.26246976852417, 'eval_runtime': 7.4007, 'eval_samples_per_second': 1.351, 'epoch': 0.96}\n",
      "\u001b[2m\u001b[36m(pid=3370)\u001b[0m {'train_runtime': 35.4606, 'train_samples_per_second': 0.338, 'epoch': 0.96}\n",
      "100%|██████████| 12/12 [00:33<00:00,  2.82s/it]\n",
      "Result for _inner_1aeff_00002:\n",
      "  date: 2021-02-03_15-07-22\n",
      "  done: true\n",
      "  epoch: 0.96\n",
      "  eval_gen_len: 59.7\n",
      "  eval_loss: 2.453468084335327\n",
      "  eval_rouge1_fmeasure: 0.3106\n",
      "  eval_rouge1_precision: 0.2542\n",
      "  eval_rouge1_recall: 0.4347\n",
      "  eval_rouge2_fmeasure: 0.1465\n",
      "  eval_rouge2_precision: 0.1165\n",
      "  eval_rouge2_recall: 0.2121\n",
      "  eval_rougeL_fmeasure: 0.2598\n",
      "  eval_rougeL_precision: 0.2089\n",
      "  eval_rougeL_recall: 0.3674\n",
      "  eval_rougeLsum_fmeasure: 0.2637\n",
      "  eval_rougeLsum_precision: 0.2141\n",
      "  eval_rougeLsum_recall: 0.3673\n",
      "  eval_runtime: 7.4007\n",
      "  eval_samples_per_second: 1.351\n",
      "  eval_sentence_distilroberta_cosine: 68.26246976852417\n",
      "  experiment_id: 5289568eca8d4fdabacf7644fd10299e\n",
      "  experiment_tag: 2_gradient_accumulation_steps=4,learning_rate=0.0001\n",
      "  hostname: ip-172-31-39-35\n",
      "  iterations_since_restore: 4\n",
      "  node_ip: 172.31.39.35\n",
      "  objective: 80.16996976852417\n",
      "  pid: 3370\n",
      "  time_since_restore: 63.3898138999939\n",
      "  time_this_iter_s: 8.251129627227783\n",
      "  time_total_s: 63.3898138999939\n",
      "  timestamp: 1612364842\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 4\n",
      "  trial_id: 1aeff_00002\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=3370)\u001b[0m wandb: Waiting for W&B process to finish, PID 3962\n",
      "\u001b[2m\u001b[36m(pid=3370)\u001b[0m wandb: Program ended successfully.\n",
      "\u001b[2m\u001b[36m(pid=3370)\u001b[0m wandb: - 0.04MB of 0.04MB uploaded (0.00MB deduped)\n",
      "wandb:                                                                                \n",
      "\u001b[2m\u001b[36m(pid=3370)\u001b[0m wandb: Find user logs for this run at: /home/ubuntu/ray_results/_inner_2021-02-03_15-04-25/_inner_1aeff_00002_2_gradient_accumulation_steps=4,learning_rate=0.0001_2021-02-03_15-06-18/wandb/run-20210203_150647-2wx99tx3/logs/debug.log\n",
      "\u001b[2m\u001b[36m(pid=3370)\u001b[0m wandb: Find internal logs for this run at: /home/ubuntu/ray_results/_inner_2021-02-03_15-04-25/_inner_1aeff_00002_2_gradient_accumulation_steps=4,learning_rate=0.0001_2021-02-03_15-06-18/wandb/run-20210203_150647-2wx99tx3/logs/debug-internal.log\n",
      "\u001b[2m\u001b[36m(pid=3370)\u001b[0m wandb: Run summary:\n",
      "\u001b[2m\u001b[36m(pid=3370)\u001b[0m wandb:                           train/loss 3.0884\n",
      "\u001b[2m\u001b[36m(pid=3370)\u001b[0m wandb:                  train/learning_rate 0.0001\n",
      "\u001b[2m\u001b[36m(pid=3370)\u001b[0m wandb:                          train/epoch 0.96\n",
      "\u001b[2m\u001b[36m(pid=3370)\u001b[0m wandb:                                _step 12\n",
      "\u001b[2m\u001b[36m(pid=3370)\u001b[0m wandb:                             _runtime 35\n",
      "\u001b[2m\u001b[36m(pid=3370)\u001b[0m wandb:                           _timestamp 1612364842\n",
      "\u001b[2m\u001b[36m(pid=3370)\u001b[0m wandb:                            eval/loss 2.45347\n",
      "\u001b[2m\u001b[36m(pid=3370)\u001b[0m wandb:                eval/rouge1_precision 0.2542\n",
      "\u001b[2m\u001b[36m(pid=3370)\u001b[0m wandb:                   eval/rouge1_recall 0.4347\n",
      "\u001b[2m\u001b[36m(pid=3370)\u001b[0m wandb:                 eval/rouge1_fmeasure 0.3106\n",
      "\u001b[2m\u001b[36m(pid=3370)\u001b[0m wandb:                eval/rouge2_precision 0.1165\n",
      "\u001b[2m\u001b[36m(pid=3370)\u001b[0m wandb:                   eval/rouge2_recall 0.2121\n",
      "\u001b[2m\u001b[36m(pid=3370)\u001b[0m wandb:                 eval/rouge2_fmeasure 0.1465\n",
      "\u001b[2m\u001b[36m(pid=3370)\u001b[0m wandb:                eval/rougeL_precision 0.2089\n",
      "\u001b[2m\u001b[36m(pid=3370)\u001b[0m wandb:                   eval/rougeL_recall 0.3674\n",
      "\u001b[2m\u001b[36m(pid=3370)\u001b[0m wandb:                 eval/rougeL_fmeasure 0.2598\n",
      "\u001b[2m\u001b[36m(pid=3370)\u001b[0m wandb:             eval/rougeLsum_precision 0.2141\n",
      "\u001b[2m\u001b[36m(pid=3370)\u001b[0m wandb:                eval/rougeLsum_recall 0.3673\n",
      "\u001b[2m\u001b[36m(pid=3370)\u001b[0m wandb:              eval/rougeLsum_fmeasure 0.2637\n",
      "\u001b[2m\u001b[36m(pid=3370)\u001b[0m wandb:                         eval/gen_len 59.7\n",
      "\u001b[2m\u001b[36m(pid=3370)\u001b[0m wandb:   eval/sentence_distilroberta_cosine 68.26247\n",
      "\u001b[2m\u001b[36m(pid=3370)\u001b[0m wandb:                         eval/runtime 7.4007\n",
      "\u001b[2m\u001b[36m(pid=3370)\u001b[0m wandb:              eval/samples_per_second 1.351\n",
      "\u001b[2m\u001b[36m(pid=3370)\u001b[0m wandb:                  train/train_runtime 35.4606\n",
      "\u001b[2m\u001b[36m(pid=3370)\u001b[0m wandb:       train/train_samples_per_second 0.338\n",
      "\u001b[2m\u001b[36m(pid=3370)\u001b[0m wandb:                     train/total_flos 16767021772800\n",
      "\u001b[2m\u001b[36m(pid=3370)\u001b[0m wandb: Run history:\n",
      "\u001b[2m\u001b[36m(pid=3370)\u001b[0m wandb:                           train/loss █▄▂▁▄▂▄▃▁▃▂▂\n",
      "\u001b[2m\u001b[36m(pid=3370)\u001b[0m wandb:                  train/learning_rate ▁▁▁▁▁▁▁▁▁▁▁▁\n",
      "\u001b[2m\u001b[36m(pid=3370)\u001b[0m wandb:                          train/epoch ▁▂▂▃▄▄▅▅▆▇▇█\n",
      "\u001b[2m\u001b[36m(pid=3370)\u001b[0m wandb:                                _step ▁▂▂▃▄▄▅▅▆▇▇█\n",
      "\u001b[2m\u001b[36m(pid=3370)\u001b[0m wandb:                             _runtime ▁▁▃▃▃▅▅▅▆▆▇█\n",
      "\u001b[2m\u001b[36m(pid=3370)\u001b[0m wandb:                           _timestamp ▁▁▃▃▃▅▅▅▆▆▇█\n",
      "\u001b[2m\u001b[36m(pid=3370)\u001b[0m wandb:                            eval/loss █▁▃▁\n",
      "\u001b[2m\u001b[36m(pid=3370)\u001b[0m wandb:                eval/rouge1_precision ▄█▆▁\n",
      "\u001b[2m\u001b[36m(pid=3370)\u001b[0m wandb:                   eval/rouge1_recall ▁█▆▂\n",
      "\u001b[2m\u001b[36m(pid=3370)\u001b[0m wandb:                 eval/rouge1_fmeasure ▂█▅▁\n",
      "\u001b[2m\u001b[36m(pid=3370)\u001b[0m wandb:                eval/rouge2_precision ▂▇█▁\n",
      "\u001b[2m\u001b[36m(pid=3370)\u001b[0m wandb:                   eval/rouge2_recall ▁█▇▃\n",
      "\u001b[2m\u001b[36m(pid=3370)\u001b[0m wandb:                 eval/rouge2_fmeasure ▁▇█▁\n",
      "\u001b[2m\u001b[36m(pid=3370)\u001b[0m wandb:                eval/rougeL_precision ▂▅█▁\n",
      "\u001b[2m\u001b[36m(pid=3370)\u001b[0m wandb:                   eval/rougeL_recall ▁██▄\n",
      "\u001b[2m\u001b[36m(pid=3370)\u001b[0m wandb:                 eval/rougeL_fmeasure ▁▇█▂\n",
      "\u001b[2m\u001b[36m(pid=3370)\u001b[0m wandb:             eval/rougeLsum_precision ▁█▅▃\n",
      "\u001b[2m\u001b[36m(pid=3370)\u001b[0m wandb:                eval/rougeLsum_recall ▁█▅▃\n",
      "\u001b[2m\u001b[36m(pid=3370)\u001b[0m wandb:              eval/rougeLsum_fmeasure ▁█▄▃\n",
      "\u001b[2m\u001b[36m(pid=3370)\u001b[0m wandb:                         eval/gen_len █▁▇▇\n",
      "\u001b[2m\u001b[36m(pid=3370)\u001b[0m wandb:   eval/sentence_distilroberta_cosine ▁█▆█\n",
      "\u001b[2m\u001b[36m(pid=3370)\u001b[0m wandb:                         eval/runtime █▁▂▂\n",
      "\u001b[2m\u001b[36m(pid=3370)\u001b[0m wandb:              eval/samples_per_second ▁█▇▇\n",
      "\u001b[2m\u001b[36m(pid=3370)\u001b[0m wandb:                  train/train_runtime ▁\n",
      "\u001b[2m\u001b[36m(pid=3370)\u001b[0m wandb:       train/train_samples_per_second ▁\n",
      "\u001b[2m\u001b[36m(pid=3370)\u001b[0m wandb:                     train/total_flos ▁\n",
      "\u001b[2m\u001b[36m(pid=3370)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(pid=3370)\u001b[0m wandb: Synced 5 W&B file(s), 1 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[2m\u001b[36m(pid=3370)\u001b[0m wandb: \n",
      "\u001b[2m\u001b[36m(pid=3370)\u001b[0m wandb: Synced /home/ubuntu/s3/fine-tuning/hyperparameters_test: https://wandb.ai/marcoabrate/hp_search_para_wordembed/runs/2wx99tx3\n",
      "\u001b[2m\u001b[36m(pid=3370)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=3367)\u001b[0m wandb: Currently logged in as: marcoabrate (use `wandb login --relogin` to force relogin)\n",
      "\u001b[2m\u001b[36m(pid=3367)\u001b[0m wandb: wandb version 0.10.17 is available!  To upgrade, please run:\n",
      "\u001b[2m\u001b[36m(pid=3367)\u001b[0m wandb:  $ pip install wandb --upgrade\n",
      "\u001b[2m\u001b[36m(pid=3367)\u001b[0m wandb: Tracking run with wandb version 0.10.14\n",
      "\u001b[2m\u001b[36m(pid=3367)\u001b[0m wandb: Syncing run /home/ubuntu/s3/fine-tuning/hyperparameters_test\n",
      "\u001b[2m\u001b[36m(pid=3367)\u001b[0m wandb: ⭐️ View project at https://wandb.ai/marcoabrate/hp_search_para_wordembed\n",
      "\u001b[2m\u001b[36m(pid=3367)\u001b[0m wandb: 🚀 View run at https://wandb.ai/marcoabrate/hp_search_para_wordembed/runs/16iqy25f\n",
      "\u001b[2m\u001b[36m(pid=3367)\u001b[0m wandb: Run data is saved locally in /home/ubuntu/ray_results/_inner_2021-02-03_15-04-25/_inner_1aeff_00003_3_gradient_accumulation_steps=4,learning_rate=1e-05_2021-02-03_15-07-22/wandb/run-20210203_150750-16iqy25f\n",
      "\u001b[2m\u001b[36m(pid=3367)\u001b[0m wandb: Run `wandb offline` to turn off syncing.\n",
      "  0%|          | 0/12 [00:00<?, ?it/s]\n",
      "\u001b[2m\u001b[36m(pid=3367)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=3367)\u001b[0m /home/ubuntu/miniconda3/envs/magma/lib/python3.6/site-packages/torch/optim/lr_scheduler.py:136: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "\u001b[2m\u001b[36m(pid=3367)\u001b[0m   \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n",
      "  8%|▊         | 1/12 [00:00<00:09,  1.16it/s]\n",
      "\u001b[2m\u001b[36m(pid=3367)\u001b[0m {'loss': 6.2597, 'learning_rate': 1e-05, 'epoch': 0.08}\n",
      " 17%|█▋        | 2/12 [00:01<00:05,  1.91it/s]\n",
      "\u001b[2m\u001b[36m(pid=3367)\u001b[0m {'loss': 3.8359, 'learning_rate': 1e-05, 'epoch': 0.16}\n",
      " 25%|██▌       | 3/12 [00:01<00:03,  2.47it/s]\n",
      "\u001b[2m\u001b[36m(pid=3367)\u001b[0m {'loss': 3.249, 'learning_rate': 1e-05, 'epoch': 0.24}\n",
      "\u001b[2m\u001b[36m(pid=3367)\u001b[0m \n",
      "  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      "\u001b[2m\u001b[36m(pid=3367)\u001b[0m \n",
      " 20%|██        | 2/10 [00:00<00:02,  2.92it/s]\u001b[A\n",
      "\u001b[2m\u001b[36m(pid=3367)\u001b[0m \n",
      " 30%|███       | 3/10 [00:01<00:03,  2.04it/s]\u001b[A\n",
      "\u001b[2m\u001b[36m(pid=3367)\u001b[0m \n",
      " 40%|████      | 4/10 [00:02<00:03,  1.69it/s]\u001b[A\n",
      "\u001b[2m\u001b[36m(pid=3367)\u001b[0m \n",
      " 50%|█████     | 5/10 [00:02<00:03,  1.60it/s]\u001b[A\n",
      "\u001b[2m\u001b[36m(pid=3367)\u001b[0m \n",
      " 60%|██████    | 6/10 [00:03<00:02,  1.54it/s]\u001b[A\n",
      "\u001b[2m\u001b[36m(pid=3367)\u001b[0m \n",
      " 70%|███████   | 7/10 [00:04<00:01,  1.51it/s]\u001b[A\n",
      "\u001b[2m\u001b[36m(pid=3367)\u001b[0m \n",
      " 80%|████████  | 8/10 [00:04<00:01,  1.49it/s]\u001b[A\n",
      "\u001b[2m\u001b[36m(pid=3367)\u001b[0m \n",
      " 90%|█████████ | 9/10 [00:05<00:00,  1.48it/s]\u001b[A\n",
      "\u001b[2m\u001b[36m(pid=3367)\u001b[0m \n",
      "100%|██████████| 10/10 [00:06<00:00,  1.47it/s]\u001b[A\n",
      "Result for _inner_1aeff_00003:\n",
      "  date: 2021-02-03_15-08-00\n",
      "  done: false\n",
      "  epoch: 0.24\n",
      "  eval_gen_len: 60.0\n",
      "  eval_loss: 3.096942663192749\n",
      "  eval_rouge1_fmeasure: 0.3289\n",
      "  eval_rouge1_precision: 0.2701\n",
      "  eval_rouge1_recall: 0.4691\n",
      "  eval_rouge2_fmeasure: 0.1499\n",
      "  eval_rouge2_precision: 0.1228\n",
      "  eval_rouge2_recall: 0.2133\n",
      "  eval_rougeL_fmeasure: 0.2621\n",
      "  eval_rougeL_precision: 0.2135\n",
      "  eval_rougeL_recall: 0.3837\n",
      "  eval_rougeLsum_fmeasure: 0.2847\n",
      "  eval_rougeLsum_precision: 0.2328\n",
      "  eval_rougeLsum_recall: 0.4091\n",
      "  eval_runtime: 7.5149\n",
      "  eval_samples_per_second: 1.331\n",
      "  eval_sentence_distilroberta_cosine: 68.12149286270142\n",
      "  experiment_id: f1337927036d4a39b874a1fe4dc569ab\n",
      "  hostname: ip-172-31-39-35\n",
      "  iterations_since_restore: 1\n",
      "  node_ip: 172.31.39.35\n",
      "  objective: 80.30739286270142\n",
      "  pid: 3367\n",
      "  time_since_restore: 37.74880266189575\n",
      "  time_this_iter_s: 37.74880266189575\n",
      "  time_total_s: 37.74880266189575\n",
      "  timestamp: 1612364880\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: 1aeff_00003\n",
      "  \n",
      "                                              \n",
      " 25%|██▌       | 3/12 [00:08<00:03,  2.47it/s] \n",
      "100%|██████████| 10/10 [00:06<00:00,  1.47it/s]\u001b[A\n",
      "                                               \u001b[A\n",
      "\u001b[2m\u001b[36m(pid=3367)\u001b[0m {'eval_loss': 3.096942663192749, 'eval_rouge1_precision': 0.2701, 'eval_rouge1_recall': 0.4691, 'eval_rouge1_fmeasure': 0.3289, 'eval_rouge2_precision': 0.1228, 'eval_rouge2_recall': 0.2133, 'eval_rouge2_fmeasure': 0.1499, 'eval_rougeL_precision': 0.2135, 'eval_rougeL_recall': 0.3837, 'eval_rougeL_fmeasure': 0.2621, 'eval_rougeLsum_precision': 0.2328, 'eval_rougeLsum_recall': 0.4091, 'eval_rougeLsum_fmeasure': 0.2847, 'eval_gen_len': 60.0, 'eval_sentence_distilroberta_cosine': 68.12149286270142, 'eval_runtime': 7.5149, 'eval_samples_per_second': 1.331, 'epoch': 0.24}\n",
      "== Status ==\n",
      "Memory usage on this node: 11.2/15.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 1/4 CPUs, 1/1 GPUs, 0.0/5.52 GiB heap, 0.0/1.9 GiB objects (0/1.0 accelerator_type:T4)\n",
      "Result logdir: /home/ubuntu/ray_results/_inner_2021-02-03_15-04-25\n",
      "Number of trials: 5/20 (1 PENDING, 1 RUNNING, 3 TERMINATED)\n",
      "+--------------------+------------+-------------------+-------------------------------+-----------------+-------------+\n",
      "| Trial name         | status     | loc               |   gradient_accumulation_steps |   learning_rate |   objective |\n",
      "|--------------------+------------+-------------------+-------------------------------+-----------------+-------------|\n",
      "| _inner_1aeff_00003 | RUNNING    | 172.31.39.35:3367 |                             4 |          1e-05  |     80.3074 |\n",
      "| _inner_1aeff_00004 | PENDING    |                   |                             8 |          1e-05  |             |\n",
      "| _inner_1aeff_00000 | TERMINATED |                   |                             4 |          1e-05  |     77.5757 |\n",
      "| _inner_1aeff_00001 | TERMINATED |                   |                             8 |          0.0001 |     80.341  |\n",
      "| _inner_1aeff_00002 | TERMINATED |                   |                             4 |          0.0001 |     80.17   |\n",
      "+--------------------+------------+-------------------+-------------------------------+-----------------+-------------+\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 4/12 [00:09<00:26,  3.32s/it]\n",
      "\u001b[2m\u001b[36m(pid=3367)\u001b[0m {'loss': 2.9396, 'learning_rate': 1e-05, 'epoch': 0.32}\n",
      " 42%|████▏     | 5/12 [00:09<00:15,  2.23s/it]\n",
      "\u001b[2m\u001b[36m(pid=3367)\u001b[0m {'loss': 4.3526, 'learning_rate': 1e-05, 'epoch': 0.4}\n",
      " 50%|█████     | 6/12 [00:09<00:09,  1.56s/it]\n",
      "\u001b[2m\u001b[36m(pid=3367)\u001b[0m {'loss': 3.207, 'learning_rate': 1e-05, 'epoch': 0.48}\n",
      "\u001b[2m\u001b[36m(pid=3367)\u001b[0m \n",
      "  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      "\u001b[2m\u001b[36m(pid=3367)\u001b[0m \n",
      " 20%|██        | 2/10 [00:00<00:02,  2.90it/s]\u001b[A\n",
      "\u001b[2m\u001b[36m(pid=3367)\u001b[0m \n",
      " 30%|███       | 3/10 [00:01<00:03,  2.03it/s]\u001b[A\n",
      "\u001b[2m\u001b[36m(pid=3367)\u001b[0m \n",
      " 40%|████      | 4/10 [00:02<00:03,  1.69it/s]\u001b[A\n",
      "\u001b[2m\u001b[36m(pid=3367)\u001b[0m \n",
      " 50%|█████     | 5/10 [00:02<00:03,  1.60it/s]\u001b[A\n",
      "\u001b[2m\u001b[36m(pid=3367)\u001b[0m \n",
      " 60%|██████    | 6/10 [00:03<00:02,  1.54it/s]\u001b[A\n",
      "\u001b[2m\u001b[36m(pid=3367)\u001b[0m \n",
      " 70%|███████   | 7/10 [00:04<00:01,  1.51it/s]\u001b[A\n",
      "\u001b[2m\u001b[36m(pid=3367)\u001b[0m \n",
      " 80%|████████  | 8/10 [00:04<00:01,  1.49it/s]\u001b[A\n",
      "\u001b[2m\u001b[36m(pid=3367)\u001b[0m \n",
      " 90%|█████████ | 9/10 [00:05<00:00,  1.48it/s]\u001b[A\n",
      "\u001b[2m\u001b[36m(pid=3367)\u001b[0m \n",
      "100%|██████████| 10/10 [00:06<00:00,  1.47it/s]\u001b[A\n",
      "Result for _inner_1aeff_00003:\n",
      "  date: 2021-02-03_15-08-08\n",
      "  done: false\n",
      "  epoch: 0.48\n",
      "  eval_gen_len: 60.0\n",
      "  eval_loss: 2.841153383255005\n",
      "  eval_rouge1_fmeasure: 0.3274\n",
      "  eval_rouge1_precision: 0.2644\n",
      "  eval_rouge1_recall: 0.47\n",
      "  eval_rouge2_fmeasure: 0.1511\n",
      "  eval_rouge2_precision: 0.1227\n",
      "  eval_rouge2_recall: 0.2202\n",
      "  eval_rougeL_fmeasure: 0.2615\n",
      "  eval_rougeL_precision: 0.2107\n",
      "  eval_rougeL_recall: 0.3797\n",
      "  eval_rougeLsum_fmeasure: 0.2819\n",
      "  eval_rougeLsum_precision: 0.2276\n",
      "  eval_rougeLsum_recall: 0.409\n",
      "  eval_runtime: 7.3527\n",
      "  eval_samples_per_second: 1.36\n",
      "  eval_sentence_distilroberta_cosine: 67.90651082992554\n",
      "  experiment_id: f1337927036d4a39b874a1fe4dc569ab\n",
      "  hostname: ip-172-31-39-35\n",
      "  iterations_since_restore: 2\n",
      "  node_ip: 172.31.39.35\n",
      "  objective: 79.94541082992554\n",
      "  pid: 3367\n",
      "  time_since_restore: 45.953656911849976\n",
      "  time_this_iter_s: 8.204854249954224\n",
      "  time_total_s: 45.953656911849976\n",
      "  timestamp: 1612364888\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 2\n",
      "  trial_id: 1aeff_00003\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 11.2/15.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 1/4 CPUs, 1/1 GPUs, 0.0/5.52 GiB heap, 0.0/1.9 GiB objects (0/1.0 accelerator_type:T4)\n",
      "Result logdir: /home/ubuntu/ray_results/_inner_2021-02-03_15-04-25\n",
      "Number of trials: 5/20 (1 PENDING, 1 RUNNING, 3 TERMINATED)\n",
      "+--------------------+------------+-------------------+-------------------------------+-----------------+-------------+\n",
      "| Trial name         | status     | loc               |   gradient_accumulation_steps |   learning_rate |   objective |\n",
      "|--------------------+------------+-------------------+-------------------------------+-----------------+-------------|\n",
      "| _inner_1aeff_00003 | RUNNING    | 172.31.39.35:3367 |                             4 |          1e-05  |     79.9454 |\n",
      "| _inner_1aeff_00004 | PENDING    |                   |                             8 |          1e-05  |             |\n",
      "| _inner_1aeff_00000 | TERMINATED |                   |                             4 |          1e-05  |     77.5757 |\n",
      "| _inner_1aeff_00001 | TERMINATED |                   |                             8 |          0.0001 |     80.341  |\n",
      "| _inner_1aeff_00002 | TERMINATED |                   |                             4 |          0.0001 |     80.17   |\n",
      "+--------------------+------------+-------------------+-------------------------------+-----------------+-------------+\n",
      "\n",
      "\n",
      "                                              \n",
      " 50%|█████     | 6/12 [00:17<00:09,  1.56s/it] \n",
      "100%|██████████| 10/10 [00:06<00:00,  1.47it/s]\u001b[A\n",
      "                                               \u001b[A\n",
      "\u001b[2m\u001b[36m(pid=3367)\u001b[0m {'eval_loss': 2.841153383255005, 'eval_rouge1_precision': 0.2644, 'eval_rouge1_recall': 0.47, 'eval_rouge1_fmeasure': 0.3274, 'eval_rouge2_precision': 0.1227, 'eval_rouge2_recall': 0.2202, 'eval_rouge2_fmeasure': 0.1511, 'eval_rougeL_precision': 0.2107, 'eval_rougeL_recall': 0.3797, 'eval_rougeL_fmeasure': 0.2615, 'eval_rougeLsum_precision': 0.2276, 'eval_rougeLsum_recall': 0.409, 'eval_rougeLsum_fmeasure': 0.2819, 'eval_gen_len': 60.0, 'eval_sentence_distilroberta_cosine': 67.90651082992554, 'eval_runtime': 7.3527, 'eval_samples_per_second': 1.36, 'epoch': 0.48}\n",
      " 58%|█████▊    | 7/12 [00:17<00:17,  3.55s/it]\n",
      "\u001b[2m\u001b[36m(pid=3367)\u001b[0m {'loss': 4.3008, 'learning_rate': 1e-05, 'epoch': 0.56}\n",
      " 67%|██████▋   | 8/12 [00:17<00:10,  2.51s/it]\n",
      " 67%|██████▋   | 8/12 [00:17<00:10,  2.51s/it]\n",
      "\u001b[2m\u001b[36m(pid=3367)\u001b[0m {'loss': 3.4402, 'learning_rate': 1e-05, 'epoch': 0.64}\n",
      " 75%|███████▌  | 9/12 [00:17<00:05,  1.81s/it]\n",
      "\u001b[2m\u001b[36m(pid=3367)\u001b[0m {'loss': 3.0972, 'learning_rate': 1e-05, 'epoch': 0.72}\n",
      "\u001b[2m\u001b[36m(pid=3367)\u001b[0m \n",
      "  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      "\u001b[2m\u001b[36m(pid=3367)\u001b[0m \n",
      " 20%|██        | 2/10 [00:00<00:02,  2.88it/s]\u001b[A\n",
      "\u001b[2m\u001b[36m(pid=3367)\u001b[0m \n",
      " 30%|███       | 3/10 [00:01<00:03,  2.03it/s]\u001b[A\n",
      "\u001b[2m\u001b[36m(pid=3367)\u001b[0m \n",
      " 40%|████      | 4/10 [00:02<00:03,  1.69it/s]\u001b[A\n",
      "\u001b[2m\u001b[36m(pid=3367)\u001b[0m \n",
      " 50%|█████     | 5/10 [00:02<00:03,  1.58it/s]\u001b[A\n",
      "\u001b[2m\u001b[36m(pid=3367)\u001b[0m \n",
      " 60%|██████    | 6/10 [00:03<00:02,  1.53it/s]\u001b[A\n",
      "\u001b[2m\u001b[36m(pid=3367)\u001b[0m \n",
      " 70%|███████   | 7/10 [00:04<00:01,  1.50it/s]\u001b[A\n",
      "\u001b[2m\u001b[36m(pid=3367)\u001b[0m \n",
      " 80%|████████  | 8/10 [00:04<00:01,  1.48it/s]\u001b[A\n",
      "\u001b[2m\u001b[36m(pid=3367)\u001b[0m \n",
      " 90%|█████████ | 9/10 [00:05<00:00,  1.47it/s]\u001b[A\n",
      "\u001b[2m\u001b[36m(pid=3367)\u001b[0m \n",
      "100%|██████████| 10/10 [00:06<00:00,  1.47it/s]\u001b[A\n",
      "Result for _inner_1aeff_00003:\n",
      "  date: 2021-02-03_15-08-16\n",
      "  done: false\n",
      "  epoch: 0.72\n",
      "  eval_gen_len: 60.0\n",
      "  eval_loss: 2.626790761947632\n",
      "  eval_rouge1_fmeasure: 0.3172\n",
      "  eval_rouge1_precision: 0.2566\n",
      "  eval_rouge1_recall: 0.4541\n",
      "  eval_rouge2_fmeasure: 0.1421\n",
      "  eval_rouge2_precision: 0.115\n",
      "  eval_rouge2_recall: 0.2071\n",
      "  eval_rougeL_fmeasure: 0.2425\n",
      "  eval_rougeL_precision: 0.1959\n",
      "  eval_rougeL_recall: 0.353\n",
      "  eval_rougeLsum_fmeasure: 0.2719\n",
      "  eval_rougeLsum_precision: 0.2211\n",
      "  eval_rougeLsum_recall: 0.3945\n",
      "  eval_runtime: 7.3807\n",
      "  eval_samples_per_second: 1.355\n",
      "  eval_sentence_distilroberta_cosine: 66.2465751171112\n",
      "  experiment_id: f1337927036d4a39b874a1fe4dc569ab\n",
      "  hostname: ip-172-31-39-35\n",
      "  iterations_since_restore: 3\n",
      "  node_ip: 172.31.39.35\n",
      "  objective: 78.15327511711122\n",
      "  pid: 3367\n",
      "  time_since_restore: 54.17433023452759\n",
      "  time_this_iter_s: 8.220673322677612\n",
      "  time_total_s: 54.17433023452759\n",
      "  timestamp: 1612364896\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 3\n",
      "  trial_id: 1aeff_00003\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 11.2/15.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 1/4 CPUs, 1/1 GPUs, 0.0/5.52 GiB heap, 0.0/1.9 GiB objects (0/1.0 accelerator_type:T4)\n",
      "Result logdir: /home/ubuntu/ray_results/_inner_2021-02-03_15-04-25\n",
      "Number of trials: 5/20 (1 PENDING, 1 RUNNING, 3 TERMINATED)\n",
      "+--------------------+------------+-------------------+-------------------------------+-----------------+-------------+\n",
      "| Trial name         | status     | loc               |   gradient_accumulation_steps |   learning_rate |   objective |\n",
      "|--------------------+------------+-------------------+-------------------------------+-----------------+-------------|\n",
      "| _inner_1aeff_00003 | RUNNING    | 172.31.39.35:3367 |                             4 |          1e-05  |     78.1533 |\n",
      "| _inner_1aeff_00004 | PENDING    |                   |                             8 |          1e-05  |             |\n",
      "| _inner_1aeff_00000 | TERMINATED |                   |                             4 |          1e-05  |     77.5757 |\n",
      "| _inner_1aeff_00001 | TERMINATED |                   |                             8 |          0.0001 |     80.341  |\n",
      "| _inner_1aeff_00002 | TERMINATED |                   |                             4 |          0.0001 |     80.17   |\n",
      "+--------------------+------------+-------------------+-------------------------------+-----------------+-------------+\n",
      "\n",
      "\n",
      "                                              \n",
      " 75%|███████▌  | 9/12 [00:25<00:05,  1.81s/it] \n",
      "100%|██████████| 10/10 [00:06<00:00,  1.47it/s]\u001b[A\n",
      "                                               \u001b[A\n",
      "\u001b[2m\u001b[36m(pid=3367)\u001b[0m {'eval_loss': 2.626790761947632, 'eval_rouge1_precision': 0.2566, 'eval_rouge1_recall': 0.4541, 'eval_rouge1_fmeasure': 0.3172, 'eval_rouge2_precision': 0.115, 'eval_rouge2_recall': 0.2071, 'eval_rouge2_fmeasure': 0.1421, 'eval_rougeL_precision': 0.1959, 'eval_rougeL_recall': 0.353, 'eval_rougeL_fmeasure': 0.2425, 'eval_rougeLsum_precision': 0.2211, 'eval_rougeLsum_recall': 0.3945, 'eval_rougeLsum_fmeasure': 0.2719, 'eval_gen_len': 60.0, 'eval_sentence_distilroberta_cosine': 66.2465751171112, 'eval_runtime': 7.3807, 'eval_samples_per_second': 1.355, 'epoch': 0.72}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 10/12 [00:25<00:07,  3.62s/it]\n",
      "\u001b[2m\u001b[36m(pid=3367)\u001b[0m {'loss': 3.7499, 'learning_rate': 1e-05, 'epoch': 0.8}\n",
      " 92%|█████████▏| 11/12 [00:25<00:02,  2.60s/it]\n",
      "\u001b[2m\u001b[36m(pid=3367)\u001b[0m {'loss': 3.0125, 'learning_rate': 1e-05, 'epoch': 0.88}\n",
      "100%|██████████| 12/12 [00:26<00:00,  1.89s/it]\n",
      "\u001b[2m\u001b[36m(pid=3367)\u001b[0m {'loss': 3.2749, 'learning_rate': 1e-05, 'epoch': 0.96}\n",
      "\u001b[2m\u001b[36m(pid=3367)\u001b[0m \n",
      "  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      "\u001b[2m\u001b[36m(pid=3367)\u001b[0m \n",
      " 20%|██        | 2/10 [00:00<00:02,  2.91it/s]\u001b[A\n",
      "\u001b[2m\u001b[36m(pid=3367)\u001b[0m \n",
      " 30%|███       | 3/10 [00:01<00:03,  2.02it/s]\u001b[A\n",
      "\u001b[2m\u001b[36m(pid=3367)\u001b[0m \n",
      " 40%|████      | 4/10 [00:02<00:03,  1.68it/s]\u001b[A\n",
      "\u001b[2m\u001b[36m(pid=3367)\u001b[0m \n",
      " 50%|█████     | 5/10 [00:02<00:03,  1.59it/s]\u001b[A\n",
      "\u001b[2m\u001b[36m(pid=3367)\u001b[0m \n",
      " 60%|██████    | 6/10 [00:03<00:02,  1.53it/s]\u001b[A\n",
      "^C\n",
      "\u001b[2m\u001b[36m(pid=3367)\u001b[0m \n",
      " 70%|███████   | 7/10 [00:04<00:01,  1.51it/s]\u001b[A\n"
     ]
    }
   ],
   "source": [
    "!python3 $finetune_script \\\n",
    "--model_name_or_path $model_name_or_path \\\n",
    "--config_name $model_name_or_path \\\n",
    "--tokenizer_name $model_name_or_path \\\n",
    "--cache_dir $cache_dir \\\n",
    "--data_dir $data_dir \\\n",
    "--hp_search \\\n",
    "--fp16 \\\n",
    "--freeze_embeds --freeze_encoder \\\n",
    "--lr_scheduler constant \\\n",
    "--sortish_sampler \\\n",
    "--task summarization \\\n",
    "--max_source_length 512 \\\n",
    "--max_target_length 60 \\\n",
    "--val_max_target_length 60 \\\n",
    "--num_train_epochs 1 \\\n",
    "--n_train 50 \\\n",
    "--n_val 10 \\\n",
    "--logging_steps 1 --logging_first_step \\\n",
    "--per_device_train_batch_size 1 --per_device_eval_batch_size 1 \\\n",
    "--evaluation_strategy steps --eval_steps 3 \\\n",
    "--predict_with_generate \\\n",
    "--output_dir $output_dir \\\n",
    "--overwrite_output_dir \\\n",
    "--seed $config.SEED \\\n",
    "--run_name $output_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "66ynxjmYEB5P"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_LevExsI7oNF"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "P95DxvqWi_2Y",
    "L5sXxqeNCtkN"
   ],
   "name": "bart_hyperparameters_search.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "0cf5224ab8cb40198d84fa37cfcc68d5": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "46539ad5e91e4af9860cab29a8200b53": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d3095d48314a49d2b81e066c2c3fd389",
      "placeholder": "​",
      "style": "IPY_MODEL_dad549b11e194e53af76c965e3f482a2",
      "value": " 1.52k/1.52k [00:00&lt;00:00, 50.8kB/s]"
     }
    },
    "4dca0f8d944943a7879b3de0a2f8347a": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_bb421fdbad584767bff8da4c882fdfbf",
       "IPY_MODEL_46539ad5e91e4af9860cab29a8200b53"
      ],
      "layout": "IPY_MODEL_c8804e5babea4223b192bca1a9111fac"
     }
    },
    "521e472af5e24843a467a768c042d6c6": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "bb421fdbad584767bff8da4c882fdfbf": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_521e472af5e24843a467a768c042d6c6",
      "max": 1525,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_0cf5224ab8cb40198d84fa37cfcc68d5",
      "value": 1525
     }
    },
    "c8804e5babea4223b192bca1a9111fac": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d3095d48314a49d2b81e066c2c3fd389": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "dad549b11e194e53af76c965e3f482a2": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 30194,
     "status": "ok",
     "timestamp": 1610616621856,
     "user": {
      "displayName": "Marco Pietro Abrate",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gjh-8YF-8BlnrkN9mLZ0xfVOWfOh7kYncpYRv-Y=s64",
      "userId": "15422244832836998434"
     },
     "user_tz": -60
    },
    "id": "au5Z9XQAC7C-"
   },
   "outputs": [],
   "source": [
    "magma_dir = '/home/ubuntu/magma/'\n",
    "bucket_dir = '/home/ubuntu/s3/'\n",
    "transformers_dir = '/home/ubuntu/transformers/'\n",
    "cache_dir = bucket_dir+'.cache/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EddY1WDNsKlS"
   },
   "source": [
    "## **Fine-tuning**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 85455,
     "status": "ok",
     "timestamp": 1610616677129,
     "user": {
      "displayName": "Marco Pietro Abrate",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gjh-8YF-8BlnrkN9mLZ0xfVOWfOh7kYncpYRv-Y=s64",
      "userId": "15422244832836998434"
     },
     "user_tz": -60
    },
    "id": "2d6M41X9AKBi"
   },
   "outputs": [],
   "source": [
    "finetune_script = '\"'+transformers_dir+'examples/seq2seq/finetune_trainer.py\"'\n",
    "eval_script = '\"'+transformers_dir+'examples/seq2seq/run_eval.py\"'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S0FByNNOIRvG"
   },
   "source": [
    "### **Config**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 104
    },
    "executionInfo": {
     "elapsed": 113930,
     "status": "ok",
     "timestamp": 1610616705611,
     "user": {
      "displayName": "Marco Pietro Abrate",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gjh-8YF-8BlnrkN9mLZ0xfVOWfOh7kYncpYRv-Y=s64",
      "userId": "15422244832836998434"
     },
     "user_tz": -60
    },
    "id": "82WSp6khIcua",
    "outputId": "54de6794-ef3c-41f4-b0e3-e108cfc4e333",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to query for notebook name, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mmarcoabrate\u001b[0m (use `wandb login --relogin` to force relogin)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: WANDB_PROJECT=ft_pegasus_para_wordembed\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.insert(0, magma_dir)\n",
    "import config\n",
    "\n",
    "import wandb\n",
    "wandb.login()\n",
    "\n",
    "project_name = 'ft_pegasus_para_wordembed'\n",
    "%env WANDB_PROJECT=$project_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uPZ7A-sBVOam"
   },
   "source": [
    "### Karger Books Para Wordembed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 113928,
     "status": "ok",
     "timestamp": 1610616705613,
     "user": {
      "displayName": "Marco Pietro Abrate",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gjh-8YF-8BlnrkN9mLZ0xfVOWfOh7kYncpYRv-Y=s64",
      "userId": "15422244832836998434"
     },
     "user_tz": -60
    },
    "id": "vJOYl_g6F1e2"
   },
   "outputs": [],
   "source": [
    "model_name_or_path = 'google/pegasus-large'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 113926,
     "status": "ok",
     "timestamp": 1610616705616,
     "user": {
      "displayName": "Marco Pietro Abrate",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gjh-8YF-8BlnrkN9mLZ0xfVOWfOh7kYncpYRv-Y=s64",
      "userId": "15422244832836998434"
     },
     "user_tz": -60
    },
    "id": "4xs_XkbCVOar"
   },
   "outputs": [],
   "source": [
    "data_dir = '\"'+bucket_dir+'datasets/karger_books_para_wordembed/pegasus/st/\"'\n",
    "\n",
    "output_dir = '\"'+bucket_dir+'fine-tuning/'+project_name+'\"'\n",
    "\n",
    "log_dir = output_dir + '/logs'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoConfig\n",
    "model_config = AutoConfig.from_pretrained(model_name_or_path)\n",
    "model_config.min_length = config.ONE_BULLET_MIN_LEN\n",
    "model_config.max_length = config.ONE_BULLET_MAX_LEN\n",
    "model_config.num_beams = 2\n",
    "\n",
    "model_config_dir = '\"'+bucket_dir+'fine-tuning/'+\\\n",
    "    model_name_or_path.replace('/', '?')+'_config\"'\n",
    "model_config.save_pretrained(model_config_dir[1:-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M58yiP1yVOav"
   },
   "source": [
    "##### Fine tune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nmodel_name_or_path = output_dir[:-1] + \\'checkpoint-325\"\\'\\nprint(model_name_or_path)\\n\\nfrom transformers import AutoTokenizer\\ntok = AutoTokenizer.from_pretrained(\\'sshleifer/distilbart-cnn-12-6\\', use_cache=False)\\ntok.save_pretrained(model_name_or_path[1:-1])\\n'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "model_name_or_path = output_dir[:-1] + 'checkpoint-325\"'\n",
    "print(model_name_or_path)\n",
    "\n",
    "from transformers import AutoTokenizer\n",
    "tok = AutoTokenizer.from_pretrained('sshleifer/distilbart-cnn-12-6', use_cache=False)\n",
    "tok.save_pretrained(model_name_or_path[1:-1])\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2522396,
     "status": "ok",
     "timestamp": 1610555308072,
     "user": {
      "displayName": "Marco Pietro Abrate",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gjh-8YF-8BlnrkN9mLZ0xfVOWfOh7kYncpYRv-Y=s64",
      "userId": "15422244832836998434"
     },
     "user_tz": -60
    },
    "id": "K66kY1WOVOaw",
    "outputId": "11421fe6-93e5-461f-8b97-0615b4c2e7af",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "02/12/2021 11:44:10 - WARNING - __main__ -   Process rank: -1, device: cuda:0, n_gpu: 1, distributed training: False, 16-bits training: True\n",
      "02/12/2021 11:44:10 - INFO - __main__ -   Training/evaluation parameters Seq2SeqTrainingArguments(output_dir='/home/ubuntu/s3/fine-tuning/ft_pegasus_para_wordembed', overwrite_output_dir=True, do_train=True, do_eval=None, do_predict=False, evaluation_strategy=<EvaluationStrategy.STEPS: 'steps'>, prediction_loss_only=False, per_device_train_batch_size=4, per_device_eval_batch_size=8, per_gpu_train_batch_size=None, per_gpu_eval_batch_size=None, gradient_accumulation_steps=16, eval_accumulation_steps=None, learning_rate=0.0001, weight_decay=0.0, adam_beta1=0.9, adam_beta2=0.999, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=10.0, max_steps=-1, lr_scheduler_type=<SchedulerType.LINEAR: 'linear'>, warmup_steps=0, logging_dir='runs/Feb12_11-44-10_ip-172-31-39-35', logging_first_step=True, logging_steps=20, save_steps=5000, save_total_limit=None, no_cuda=False, seed=42, fp16=True, fp16_opt_level='O1', fp16_backend='auto', local_rank=-1, tpu_num_cores=None, tpu_metrics_debug=False, debug=False, dataloader_drop_last=False, eval_steps=14, dataloader_num_workers=0, past_index=-1, run_name='/home/ubuntu/s3/fine-tuning/ft_pegasus_para_wordembed', disable_tqdm=False, remove_unused_columns=True, label_names=None, load_best_model_at_end=False, metric_for_best_model=None, greater_is_better=None, ignore_data_skip=False, sharded_ddp=False, deepspeed=None, label_smoothing_factor=0.1, adafactor=True, group_by_length=False, report_to=['tensorboard', 'wandb'], ddp_find_unused_parameters=None, dataloader_pin_memory=True, label_smoothing=0.0, sortish_sampler=True, predict_with_generate=True, encoder_layerdrop=None, decoder_layerdrop=None, dropout=None, attention_dropout=None, lr_scheduler='linear')\n",
      "[INFO|configuration_utils.py:447] 2021-02-12 11:44:10,911 >> loading configuration file /home/ubuntu/s3/fine-tuning/google?pegasus-large_config/config.json\n",
      "[INFO|configuration_utils.py:485] 2021-02-12 11:44:10,912 >> Model config PegasusConfig {\n",
      "  \"activation_dropout\": 0.1,\n",
      "  \"activation_function\": \"relu\",\n",
      "  \"add_bias_logits\": false,\n",
      "  \"add_final_layer_norm\": true,\n",
      "  \"architectures\": [\n",
      "    \"PegasusForConditionalGeneration\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classif_dropout\": 0.0,\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"d_model\": 1024,\n",
      "  \"decoder_attention_heads\": 16,\n",
      "  \"decoder_ffn_dim\": 4096,\n",
      "  \"decoder_layerdrop\": 0.0,\n",
      "  \"decoder_layers\": 16,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"dropout\": 0.1,\n",
      "  \"encoder_attention_heads\": 16,\n",
      "  \"encoder_ffn_dim\": 4096,\n",
      "  \"encoder_layerdrop\": 0.0,\n",
      "  \"encoder_layers\": 16,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"extra_pos_embeddings\": 1,\n",
      "  \"force_bos_token_to_be_generated\": false,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\"\n",
      "  },\n",
      "  \"init_std\": 0.02,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2\n",
      "  },\n",
      "  \"length_penalty\": 0.8,\n",
      "  \"max_length\": 150,\n",
      "  \"max_position_embeddings\": 1024,\n",
      "  \"min_length\": 10,\n",
      "  \"model_type\": \"pegasus\",\n",
      "  \"normalize_before\": true,\n",
      "  \"normalize_embedding\": false,\n",
      "  \"num_beams\": 2,\n",
      "  \"num_hidden_layers\": 16,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"scale_embedding\": true,\n",
      "  \"static_position_embeddings\": true,\n",
      "  \"task_specific_params\": {\n",
      "    \"summarization_aeslc\": {\n",
      "      \"length_penalty\": 0.6,\n",
      "      \"max_length\": 32,\n",
      "      \"max_position_embeddings\": 512\n",
      "    },\n",
      "    \"summarization_arxiv\": {\n",
      "      \"length_penalty\": 0.8,\n",
      "      \"max_length\": 256,\n",
      "      \"max_position_embeddings\": 1024\n",
      "    },\n",
      "    \"summarization_big_patent\": {\n",
      "      \"length_penalty\": 0.7,\n",
      "      \"max_length\": 256,\n",
      "      \"max_position_embeddings\": 1024\n",
      "    },\n",
      "    \"summarization_billsum\": {\n",
      "      \"length_penalty\": 0.6,\n",
      "      \"max_length\": 256,\n",
      "      \"max_position_embeddings\": 1024\n",
      "    },\n",
      "    \"summarization_cnn_dailymail\": {\n",
      "      \"length_penalty\": 0.8,\n",
      "      \"max_length\": 128,\n",
      "      \"max_position_embeddings\": 1024\n",
      "    },\n",
      "    \"summarization_gigaword\": {\n",
      "      \"length_penalty\": 0.6,\n",
      "      \"max_length\": 32,\n",
      "      \"max_position_embeddings\": 128\n",
      "    },\n",
      "    \"summarization_large\": {\n",
      "      \"length_penalty\": 0.8,\n",
      "      \"max_length\": 256,\n",
      "      \"max_position_embeddings\": 1024\n",
      "    },\n",
      "    \"summarization_multi_news\": {\n",
      "      \"length_penalty\": 0.8,\n",
      "      \"max_length\": 256,\n",
      "      \"max_position_embeddings\": 1024\n",
      "    },\n",
      "    \"summarization_newsroom\": {\n",
      "      \"length_penalty\": 0.8,\n",
      "      \"max_length\": 128,\n",
      "      \"max_position_embeddings\": 512\n",
      "    },\n",
      "    \"summarization_pubmed\": {\n",
      "      \"length_penalty\": 0.8,\n",
      "      \"max_length\": 256,\n",
      "      \"max_position_embeddings\": 1024\n",
      "    },\n",
      "    \"summarization_reddit_tifu\": {\n",
      "      \"length_penalty\": 0.6,\n",
      "      \"max_length\": 128,\n",
      "      \"max_position_embeddings\": 512\n",
      "    },\n",
      "    \"summarization_wikihow\": {\n",
      "      \"length_penalty\": 0.6,\n",
      "      \"max_length\": 256,\n",
      "      \"max_position_embeddings\": 512\n",
      "    },\n",
      "    \"summarization_xsum\": {\n",
      "      \"length_penalty\": 0.8,\n",
      "      \"max_length\": 64,\n",
      "      \"max_position_embeddings\": 512\n",
      "    }\n",
      "  },\n",
      "  \"transformers_version\": \"4.4.0.dev0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 96103\n",
      "}\n",
      "\n",
      "[INFO|configuration_utils.py:449] 2021-02-12 11:44:11,302 >> loading configuration file https://huggingface.co/google/pegasus-large/resolve/main/config.json from cache at /home/ubuntu/s3/.cache/3fa0446657dd3714a950ba400a3fa72686d0f815da436514e4823a973ef23e20.3e972bf1f2190a9968e7ede5f5e211b25c8551c53e7f1215ddb2103fb3c74e70\n",
      "[INFO|configuration_utils.py:485] 2021-02-12 11:44:11,303 >> Model config PegasusConfig {\n",
      "  \"activation_dropout\": 0.1,\n",
      "  \"activation_function\": \"relu\",\n",
      "  \"add_bias_logits\": false,\n",
      "  \"add_final_layer_norm\": true,\n",
      "  \"architectures\": [\n",
      "    \"PegasusForConditionalGeneration\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classif_dropout\": 0.0,\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"d_model\": 1024,\n",
      "  \"decoder_attention_heads\": 16,\n",
      "  \"decoder_ffn_dim\": 4096,\n",
      "  \"decoder_layerdrop\": 0.0,\n",
      "  \"decoder_layers\": 16,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"dropout\": 0.1,\n",
      "  \"encoder_attention_heads\": 16,\n",
      "  \"encoder_ffn_dim\": 4096,\n",
      "  \"encoder_layerdrop\": 0.0,\n",
      "  \"encoder_layers\": 16,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"extra_pos_embeddings\": 1,\n",
      "  \"force_bos_token_to_be_generated\": false,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\"\n",
      "  },\n",
      "  \"init_std\": 0.02,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2\n",
      "  },\n",
      "  \"length_penalty\": 0.8,\n",
      "  \"max_length\": 256,\n",
      "  \"max_position_embeddings\": 1024,\n",
      "  \"model_type\": \"pegasus\",\n",
      "  \"normalize_before\": true,\n",
      "  \"normalize_embedding\": false,\n",
      "  \"num_beams\": 8,\n",
      "  \"num_hidden_layers\": 16,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"scale_embedding\": true,\n",
      "  \"static_position_embeddings\": true,\n",
      "  \"task_specific_params\": {\n",
      "    \"summarization_aeslc\": {\n",
      "      \"length_penalty\": 0.6,\n",
      "      \"max_length\": 32,\n",
      "      \"max_position_embeddings\": 512\n",
      "    },\n",
      "    \"summarization_arxiv\": {\n",
      "      \"length_penalty\": 0.8,\n",
      "      \"max_length\": 256,\n",
      "      \"max_position_embeddings\": 1024\n",
      "    },\n",
      "    \"summarization_big_patent\": {\n",
      "      \"length_penalty\": 0.7,\n",
      "      \"max_length\": 256,\n",
      "      \"max_position_embeddings\": 1024\n",
      "    },\n",
      "    \"summarization_billsum\": {\n",
      "      \"length_penalty\": 0.6,\n",
      "      \"max_length\": 256,\n",
      "      \"max_position_embeddings\": 1024\n",
      "    },\n",
      "    \"summarization_cnn_dailymail\": {\n",
      "      \"length_penalty\": 0.8,\n",
      "      \"max_length\": 128,\n",
      "      \"max_position_embeddings\": 1024\n",
      "    },\n",
      "    \"summarization_gigaword\": {\n",
      "      \"length_penalty\": 0.6,\n",
      "      \"max_length\": 32,\n",
      "      \"max_position_embeddings\": 128\n",
      "    },\n",
      "    \"summarization_large\": {\n",
      "      \"length_penalty\": 0.8,\n",
      "      \"max_length\": 256,\n",
      "      \"max_position_embeddings\": 1024\n",
      "    },\n",
      "    \"summarization_multi_news\": {\n",
      "      \"length_penalty\": 0.8,\n",
      "      \"max_length\": 256,\n",
      "      \"max_position_embeddings\": 1024\n",
      "    },\n",
      "    \"summarization_newsroom\": {\n",
      "      \"length_penalty\": 0.8,\n",
      "      \"max_length\": 128,\n",
      "      \"max_position_embeddings\": 512\n",
      "    },\n",
      "    \"summarization_pubmed\": {\n",
      "      \"length_penalty\": 0.8,\n",
      "      \"max_length\": 256,\n",
      "      \"max_position_embeddings\": 1024\n",
      "    },\n",
      "    \"summarization_reddit_tifu\": {\n",
      "      \"length_penalty\": 0.6,\n",
      "      \"max_length\": 128,\n",
      "      \"max_position_embeddings\": 512\n",
      "    },\n",
      "    \"summarization_wikihow\": {\n",
      "      \"length_penalty\": 0.6,\n",
      "      \"max_length\": 256,\n",
      "      \"max_position_embeddings\": 512\n",
      "    },\n",
      "    \"summarization_xsum\": {\n",
      "      \"length_penalty\": 0.8,\n",
      "      \"max_length\": 64,\n",
      "      \"max_position_embeddings\": 512\n",
      "    }\n",
      "  },\n",
      "  \"transformers_version\": \"4.4.0.dev0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 96103\n",
      "}\n",
      "\n",
      "[INFO|tokenization_utils_base.py:1688] 2021-02-12 11:44:11,303 >> Model name 'google/pegasus-large' not found in model shortcut name list (google/pegasus-xsum). Assuming 'google/pegasus-large' is a path, a model identifier, or url to a directory containing tokenizer files.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO|tokenization_utils_base.py:1786] 2021-02-12 11:44:12,714 >> loading file https://huggingface.co/google/pegasus-large/resolve/main/spiece.model from cache at /home/ubuntu/s3/.cache/66f187d645734a6204f3fd24593fbf0d9e36b528dd85b3adae9a566b17b4768f.1acf68c74589da6c7fa3548093824dfc450a54637f4356929bbfea7e294a68f8\n",
      "[INFO|tokenization_utils_base.py:1786] 2021-02-12 11:44:12,715 >> loading file https://huggingface.co/google/pegasus-large/resolve/main/tokenizer.json from cache at None\n",
      "[INFO|tokenization_utils_base.py:1786] 2021-02-12 11:44:12,715 >> loading file https://huggingface.co/google/pegasus-large/resolve/main/added_tokens.json from cache at None\n",
      "[INFO|tokenization_utils_base.py:1786] 2021-02-12 11:44:12,715 >> loading file https://huggingface.co/google/pegasus-large/resolve/main/special_tokens_map.json from cache at /home/ubuntu/s3/.cache/fbf9c7cf2d49b24712b53a2760e7c62a2acecd1496908822df00b8ec2683ca6d.294ebaa4cd17bb284635004c92d2c4d522ec488c828dcce0c2471b6f28e3fe82\n",
      "[INFO|tokenization_utils_base.py:1786] 2021-02-12 11:44:12,715 >> loading file https://huggingface.co/google/pegasus-large/resolve/main/tokenizer_config.json from cache at /home/ubuntu/s3/.cache/74256fafbb3cb536e351e6731914d42f732e77d33e537b6c19fb72f4b74f50ea.43f396f0ee3b974f9128267d49f69a26b11f3ed290851ac5788a549cc2979671\n",
      "[INFO|modeling_utils.py:1027] 2021-02-12 11:44:13,632 >> loading weights file https://huggingface.co/google/pegasus-large/resolve/main/pytorch_model.bin from cache at /home/ubuntu/s3/.cache/ef3a8274e003ba4d3ae63f2728378e73affec0029e797c0bbb80be8856130c4f.a99cb24bd92c7087e95d96a1c3eb660b51e498705f8bd068a58c69c20616f514\n",
      "[INFO|modeling_utils.py:1143] 2021-02-12 11:45:06,760 >> All model checkpoint weights were used when initializing PegasusForConditionalGeneration.\n",
      "\n",
      "[INFO|modeling_utils.py:1152] 2021-02-12 11:45:06,760 >> All the weights of PegasusForConditionalGeneration were initialized from the model checkpoint at google/pegasus-large.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use PegasusForConditionalGeneration for predictions without further training.\n",
      "02/12/2021 11:45:06 - INFO - utils -   setting model.config to task specific params for summarization:\n",
      " {}\n",
      "02/12/2021 11:45:06 - INFO - utils -   note: command line args may override some of these\n",
      "[INFO|trainer.py:348] 2021-02-12 11:45:10,172 >> Using amp fp16 backend\n",
      "02/12/2021 11:45:10 - INFO - __main__ -   *** Train ***\n",
      "/home/ubuntu/transformers/src/transformers/trainer.py:705: FutureWarning: `model_path` is deprecated and will be removed in a future version. Use `resume_from_checkpoint` instead.\n",
      "  FutureWarning,\n",
      "[INFO|trainer.py:837] 2021-02-12 11:45:10,186 >> ***** Running training *****\n",
      "[INFO|trainer.py:838] 2021-02-12 11:45:10,186 >>   Num examples = 2046\n",
      "[INFO|trainer.py:839] 2021-02-12 11:45:10,186 >>   Num Epochs = 10\n",
      "[INFO|trainer.py:840] 2021-02-12 11:45:10,186 >>   Instantaneous batch size per device = 4\n",
      "[INFO|trainer.py:841] 2021-02-12 11:45:10,186 >>   Total train batch size (w. parallel, distributed & accumulation) = 64\n",
      "[INFO|trainer.py:842] 2021-02-12 11:45:10,186 >>   Gradient Accumulation steps = 16\n",
      "[INFO|trainer.py:843] 2021-02-12 11:45:10,186 >>   Total optimization steps = 320\n",
      "[INFO|integrations.py:565] 2021-02-12 11:45:10,203 >> Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mmarcoabrate\u001b[0m (use `wandb login --relogin` to force relogin)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.10.18 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.10.14\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33m/home/ubuntu/s3/fine-tuning/ft_pegasus_para_wordembed\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/marcoabrate/ft_pegasus_para_wordembed\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/marcoabrate/ft_pegasus_para_wordembed/runs/2a0vbrbz\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in /home/ubuntu/magma/fine-tuning/wandb/run-20210212_114510-2a0vbrbz\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run `wandb offline` to turn off syncing.\n",
      "\n",
      "  0%|          | 0/320 [00:00<?, ?it/s]/home/ubuntu/miniconda3/envs/magma/lib/python3.6/site-packages/torch/optim/lr_scheduler.py:136: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n",
      "  0%|          | 1/320 [00:04<22:03,  4.15s/it]{'loss': 3.3785, 'learning_rate': 9.96875e-05, 'epoch': 0.03}\n",
      "/home/ubuntu/transformers/src/transformers/optimization.py:557: UserWarning: This overload of add_ is deprecated:\n",
      "\tadd_(Number alpha, Tensor other)\n",
      "Consider using one of the following signatures instead:\n",
      "\tadd_(Tensor other, *, Number alpha) (Triggered internally at  /opt/conda/conda-bld/pytorch_1607370120218/work/torch/csrc/utils/python_arg_parser.cpp:882.)\n",
      "  exp_avg_sq_row.mul_(beta2t).add_(1.0 - beta2t, update.mean(dim=-1))\n",
      "  1%|          | 2/320 [00:08<21:36,  4.08s/it]Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/transformers/examples/seq2seq/finetune_trainer.py\", line 450, in <module>\n",
      "    main()\n",
      "  File \"/home/ubuntu/transformers/examples/seq2seq/finetune_trainer.py\", line 388, in main\n",
      "    model_path=model_args.model_name_or_path if os.path.isdir(model_args.model_name_or_path) else None\n",
      "  File \"/home/ubuntu/transformers/src/transformers/trainer.py\", line 940, in train\n",
      "    tr_loss += self.training_step(model, inputs)\n",
      "  File \"/home/ubuntu/transformers/src/transformers/trainer.py\", line 1314, in training_step\n",
      "    loss = self.compute_loss(model, inputs)\n",
      "  File \"/home/ubuntu/transformers/examples/seq2seq/seq2seq_trainer.py\", line 180, in compute_loss\n",
      "    loss, _ = self._compute_loss(model, inputs, labels)\n",
      "  File \"/home/ubuntu/transformers/examples/seq2seq/seq2seq_trainer.py\", line 166, in _compute_loss\n",
      "    logits = model(**inputs, use_cache=False)[0]\n",
      "  File \"/home/ubuntu/miniconda3/envs/magma/lib/python3.6/site-packages/torch/nn/modules/module.py\", line 727, in _call_impl\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"/home/ubuntu/transformers/src/transformers/models/pegasus/modeling_pegasus.py\", line 1278, in forward\n",
      "    return_dict=return_dict,\n",
      "  File \"/home/ubuntu/miniconda3/envs/magma/lib/python3.6/site-packages/torch/nn/modules/module.py\", line 727, in _call_impl\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"/home/ubuntu/transformers/src/transformers/models/pegasus/modeling_pegasus.py\", line 1138, in forward\n",
      "    return_dict=return_dict,\n",
      "  File \"/home/ubuntu/miniconda3/envs/magma/lib/python3.6/site-packages/torch/nn/modules/module.py\", line 727, in _call_impl\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"/home/ubuntu/transformers/src/transformers/models/pegasus/modeling_pegasus.py\", line 769, in forward\n",
      "    output_attentions=output_attentions,\n",
      "  File \"/home/ubuntu/miniconda3/envs/magma/lib/python3.6/site-packages/torch/nn/modules/module.py\", line 727, in _call_impl\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"/home/ubuntu/transformers/src/transformers/models/pegasus/modeling_pegasus.py\", line 327, in forward\n",
      "    output_attentions=output_attentions,\n",
      "  File \"/home/ubuntu/miniconda3/envs/magma/lib/python3.6/site-packages/torch/nn/modules/module.py\", line 727, in _call_impl\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"/home/ubuntu/transformers/src/transformers/models/pegasus/modeling_pegasus.py\", line 242, in forward\n",
      "    attn_weights = attn_weights.view(bsz, self.num_heads, tgt_len, src_len) + attention_mask\n",
      "RuntimeError: CUDA out of memory. Tried to allocate 240.00 MiB (GPU 0; 14.76 GiB total capacity; 13.37 GiB already allocated; 91.75 MiB free; 13.75 GiB reserved in total by PyTorch)\n",
      "\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish, PID 6023\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Program failed with code 1.  Press ctrl-c to abort syncing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find user logs for this run at: /home/ubuntu/magma/fine-tuning/wandb/run-20210212_114510-2a0vbrbz/logs/debug.log\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find internal logs for this run at: /home/ubuntu/magma/fine-tuning/wandb/run-20210212_114510-2a0vbrbz/logs/debug-internal.log\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            train/loss 3.3785\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   train/learning_rate 0.0001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           train/epoch 0.03\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                 _step 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              _runtime 13\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            _timestamp 1613130323\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            train/loss ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   train/learning_rate ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           train/epoch ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                 _step ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              _runtime ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            _timestamp ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 1 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33m/home/ubuntu/s3/fine-tuning/ft_pegasus_para_wordembed\u001b[0m: \u001b[34mhttps://wandb.ai/marcoabrate/ft_pegasus_para_wordembed/runs/2a0vbrbz\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!python3 $finetune_script \\\n",
    "--model_name_or_path $model_name_or_path \\\n",
    "--config_name $model_config_dir \\\n",
    "--tokenizer_name $model_name_or_path \\\n",
    "--cache_dir $cache_dir \\\n",
    "--data_dir $data_dir \\\n",
    "--freeze_embeds \\\n",
    "--adafactor \\\n",
    "--do_train \\\n",
    "--learning_rate 1e-4 \\\n",
    "--label_smoothing_factor 0.1 \\\n",
    "--warmup_steps 0 \\\n",
    "--fp16 \\\n",
    "--sortish_sampler \\\n",
    "--task summarization \\\n",
    "--max_source_length 1024 \\\n",
    "--max_target_length $config.ONE_BULLET_MAX_LEN \\\n",
    "--val_max_target_length $config.ONE_BULLET_MAX_LEN \\\n",
    "--num_train_epochs 10 \\\n",
    "--logging_steps 20 --logging_first_step \\\n",
    "--per_device_train_batch_size 2 --per_device_eval_batch_size 8 \\\n",
    "--gradient_accumulation_steps 16 \\\n",
    "--evaluation_strategy steps --eval_steps 14 --eval_beams 2 \\\n",
    "--predict_with_generate \\\n",
    "--save_steps 5000 \\\n",
    "--output_dir $output_dir \\\n",
    "--overwrite_output_dir \\\n",
    "--seed $config.SEED \\\n",
    "--run_name $output_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1bbRUTtNDHth"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyNa0Dk3mImrCcZO3VdQRayI",
   "collapsed_sections": [
    "P95DxvqWi_2Y",
    "L5sXxqeNCtkN",
    "S0FByNNOIRvG",
    "GPbOrCLWACbm",
    "siT4m5aYCFSh",
    "Dk1uGO5SCDNa",
    "WdDCBiMOBWiO",
    "pr_0J4xgBWiW",
    "l8hQT6ksBWin",
    "d5V0QCdf04Yx",
    "KQj3gt6s5ACz",
    "ah9sssub5DXX",
    "M58yiP1yVOav",
    "aeSSMVZwVOa1"
   ],
   "name": "bart_finetune.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "88734567ccb2435091eeab9f30b2de9b": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_bd07faa8d1534ff9b1967f18e6fca2c2",
       "IPY_MODEL_43ac5522170c45f7856f7097ff9fee58"
      ],
      "layout": "IPY_MODEL_431d75cb2dd2403e88015f4e009080d4"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

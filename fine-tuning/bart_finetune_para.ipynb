{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "executionInfo": {
     "elapsed": 30194,
     "status": "ok",
     "timestamp": 1610616621856,
     "user": {
      "displayName": "Marco Pietro Abrate",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gjh-8YF-8BlnrkN9mLZ0xfVOWfOh7kYncpYRv-Y=s64",
      "userId": "15422244832836998434"
     },
     "user_tz": -60
    },
    "id": "au5Z9XQAC7C-"
   },
   "outputs": [],
   "source": [
    "magma_dir = '/home/ubuntu/magma/'\n",
    "transformers_dir = '/home/ubuntu/transformers/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EddY1WDNsKlS"
   },
   "source": [
    "## **Fine-tuning**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "executionInfo": {
     "elapsed": 85455,
     "status": "ok",
     "timestamp": 1610616677129,
     "user": {
      "displayName": "Marco Pietro Abrate",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gjh-8YF-8BlnrkN9mLZ0xfVOWfOh7kYncpYRv-Y=s64",
      "userId": "15422244832836998434"
     },
     "user_tz": -60
    },
    "id": "2d6M41X9AKBi"
   },
   "outputs": [],
   "source": [
    "finetune_script = '\"'+transformers_dir+'examples/seq2seq/finetune_trainer.py\"'\n",
    "eval_script = '\"'+transformers_dir+'examples/seq2seq/run_eval.py\"'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S0FByNNOIRvG"
   },
   "source": [
    "### **Config**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 104
    },
    "executionInfo": {
     "elapsed": 113930,
     "status": "ok",
     "timestamp": 1610616705611,
     "user": {
      "displayName": "Marco Pietro Abrate",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gjh-8YF-8BlnrkN9mLZ0xfVOWfOh7kYncpYRv-Y=s64",
      "userId": "15422244832836998434"
     },
     "user_tz": -60
    },
    "id": "82WSp6khIcua",
    "outputId": "54de6794-ef3c-41f4-b0e3-e108cfc4e333"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mmarcoabrate\u001b[0m (use `wandb login --relogin` to force relogin)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.insert(0, magma_dir)\n",
    "import config\n",
    "\n",
    "import torch\n",
    "torch.manual_seed = config.SEED\n",
    "\n",
    "import wandb\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uPZ7A-sBVOam"
   },
   "source": [
    "### Karger Books Para"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "executionInfo": {
     "elapsed": 113928,
     "status": "ok",
     "timestamp": 1610616705613,
     "user": {
      "displayName": "Marco Pietro Abrate",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gjh-8YF-8BlnrkN9mLZ0xfVOWfOh7kYncpYRv-Y=s64",
      "userId": "15422244832836998434"
     },
     "user_tz": -60
    },
    "id": "vJOYl_g6F1e2"
   },
   "outputs": [],
   "source": [
    "model_name_or_path = 'sshleifer/bart-tiny-random'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "executionInfo": {
     "elapsed": 113926,
     "status": "ok",
     "timestamp": 1610616705616,
     "user": {
      "displayName": "Marco Pietro Abrate",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gjh-8YF-8BlnrkN9mLZ0xfVOWfOh7kYncpYRv-Y=s64",
      "userId": "15422244832836998434"
     },
     "user_tz": -60
    },
    "id": "4xs_XkbCVOar"
   },
   "outputs": [],
   "source": [
    "data_dir = '\"'+magma_dir+'datasets/karger_books_para/bart\"'\n",
    "\n",
    "output_dir = '\"'+magma_dir+'fine-tuning/'+\\\n",
    "    model_name_or_path.replace('/', '?')+'_karger_books_para_train\"'\n",
    "\n",
    "log_dir = output_dir + '/logs'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34,
     "referenced_widgets": [
      "88734567ccb2435091eeab9f30b2de9b"
     ]
    },
    "executionInfo": {
     "elapsed": 120037,
     "status": "ok",
     "timestamp": 1610616711730,
     "user": {
      "displayName": "Marco Pietro Abrate",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gjh-8YF-8BlnrkN9mLZ0xfVOWfOh7kYncpYRv-Y=s64",
      "userId": "15422244832836998434"
     },
     "user_tz": -60
    },
    "id": "wtLC1O1ZJpU3",
    "outputId": "16632326-7ab5-4ef4-aa65-44efbdf45fb3"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ded0b89cdfc443fa5bc34a2debb5846",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.15k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoConfig\n",
    "model_config = AutoConfig.from_pretrained(model_name_or_path)\n",
    "model_config.min_length = config.ONE_BULLET_MIN_LEN\n",
    "model_config.max_length = config.ONE_BULLET_MAX_LEN\n",
    "model_config.length_penalty = config.LENGTH_PENALTY\n",
    "model_config.no_repeat_ngram_size = config.NO_REPEAT_NGRAM_SIZE\n",
    "\n",
    "model_config.task_specific_params['summarization']['min_length'] = config.ONE_BULLET_MIN_LEN\n",
    "model_config.task_specific_params['summarization']['max_length'] = config.ONE_BULLET_MAX_LEN\n",
    "model_config.task_specific_params['summarization']['length_penalty'] = config.LENGTH_PENALTY\n",
    "model_config.task_specific_params['summarization']['no_repeat_ngram_size'] = config.NO_REPEAT_NGRAM_SIZE\n",
    "model_config_dir = '\"'+magma_dir+'fine-tuning/'+\\\n",
    "    model_name_or_path.replace('/', '?')+'_config\"'\n",
    "model_config.save_pretrained(model_config_dir[1:-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M58yiP1yVOav"
   },
   "source": [
    "##### Fine tune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2522396,
     "status": "ok",
     "timestamp": 1610555308072,
     "user": {
      "displayName": "Marco Pietro Abrate",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gjh-8YF-8BlnrkN9mLZ0xfVOWfOh7kYncpYRv-Y=s64",
      "userId": "15422244832836998434"
     },
     "user_tz": -60
    },
    "id": "K66kY1WOVOaw",
    "outputId": "11421fe6-93e5-461f-8b97-0615b4c2e7af"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "01/14/2021 14:47:01 - WARNING - __main__ -   Process rank: -1, device: cpu, n_gpu: 0, distributed training: False, 16-bits training: False\n",
      "01/14/2021 14:47:01 - INFO - __main__ -   Training/evaluation parameters Seq2SeqTrainingArguments(output_dir='/home/marco/epfl/magma/fine-tuning/sshleifer?bart-tiny-random_karger_books_para_train', overwrite_output_dir=True, do_train=True, do_eval=True, do_predict=False, model_parallel=False, evaluation_strategy=<EvaluationStrategy.STEPS: 'steps'>, prediction_loss_only=False, per_device_train_batch_size=4, per_device_eval_batch_size=4, per_gpu_train_batch_size=None, per_gpu_eval_batch_size=None, gradient_accumulation_steps=1, eval_accumulation_steps=None, learning_rate=3e-05, weight_decay=0.0, adam_beta1=0.9, adam_beta2=0.999, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=10.0, max_steps=-1, warmup_steps=0, logging_dir='runs/Jan14_14-47-01_calcolatore', logging_first_step=False, logging_steps=10, save_steps=1000, save_total_limit=3, no_cuda=False, seed=42, fp16=False, fp16_opt_level='O1', local_rank=-1, tpu_num_cores=None, tpu_metrics_debug=False, debug=False, dataloader_drop_last=False, eval_steps=1000, dataloader_num_workers=0, past_index=-1, run_name='/home/marco/epfl/magma/fine-tuning/sshleifer?bart-tiny-random_karger_books_para_train', disable_tqdm=False, remove_unused_columns=True, label_names=None, load_best_model_at_end=False, metric_for_best_model='rougeL', greater_is_better='True', ignore_data_skip=False, fp16_backend='auto', sharded_ddp=False, label_smoothing=0.1, sortish_sampler=True, predict_with_generate=True, adafactor=True, encoder_layerdrop=None, decoder_layerdrop=None, dropout=None, attention_dropout=None, lr_scheduler='linear')\n",
      "[INFO|configuration_utils.py:429] 2021-01-14 14:47:01,359 >> loading configuration file /home/marco/epfl/magma/fine-tuning/sshleifer?bart-tiny-random_config/config.json\n",
      "[INFO|configuration_utils.py:467] 2021-01-14 14:47:01,360 >> Model config BartConfig {\n",
      "  \"_num_labels\": 3,\n",
      "  \"activation_dropout\": 0.0,\n",
      "  \"activation_function\": \"gelu\",\n",
      "  \"add_bias_logits\": false,\n",
      "  \"add_final_layer_norm\": false,\n",
      "  \"architectures\": [\n",
      "    \"BartForConditionalGeneration\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classif_dropout\": 0.0,\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"d_model\": 24,\n",
      "  \"decoder_attention_heads\": 2,\n",
      "  \"decoder_ffn_dim\": 16,\n",
      "  \"decoder_layerdrop\": 0.0,\n",
      "  \"decoder_layers\": 2,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"do_blenderbot_90_layernorm\": false,\n",
      "  \"dropout\": 0.1,\n",
      "  \"encoder_attention_heads\": 2,\n",
      "  \"encoder_ffn_dim\": 16,\n",
      "  \"encoder_layerdrop\": 0.0,\n",
      "  \"encoder_layers\": 2,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"extra_pos_embeddings\": 2,\n",
      "  \"force_bos_token_to_be_generated\": false,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\"\n",
      "  },\n",
      "  \"init_std\": 0.02,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2\n",
      "  },\n",
      "  \"max_length\": 150,\n",
      "  \"max_position_embeddings\": 1024,\n",
      "  \"min_length\": 10,\n",
      "  \"model_type\": \"bart\",\n",
      "  \"no_repeat_ngram_size\": 5,\n",
      "  \"normalize_before\": false,\n",
      "  \"normalize_embedding\": true,\n",
      "  \"num_hidden_layers\": 2,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"prefix\": \" \",\n",
      "  \"scale_embedding\": false,\n",
      "  \"static_position_embeddings\": false,\n",
      "  \"task_specific_params\": {\n",
      "    \"summarization\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"length_penalty\": 1,\n",
      "      \"max_length\": 150,\n",
      "      \"min_length\": 10,\n",
      "      \"no_repeat_ngram_size\": 5,\n",
      "      \"num_beams\": 1\n",
      "    }\n",
      "  },\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "[INFO|configuration_utils.py:431] 2021-01-14 14:47:01,709 >> loading configuration file https://huggingface.co/sshleifer/bart-tiny-random/resolve/main/config.json from cache at /home/marco/.cache/huggingface/transformers/d8da4d5b573fc14e71d1ccfef673e4d1bc1877d4488cbcacf0416c23fc30a3f3.9e2b1e8a205de2082b8ab3d9b358d32d0a5aa36c28ca62d9a21a3057fa42d78b\n",
      "[INFO|configuration_utils.py:467] 2021-01-14 14:47:01,712 >> Model config BartConfig {\n",
      "  \"_num_labels\": 3,\n",
      "  \"activation_dropout\": 0.0,\n",
      "  \"activation_function\": \"gelu\",\n",
      "  \"add_bias_logits\": false,\n",
      "  \"add_final_layer_norm\": false,\n",
      "  \"architectures\": [\n",
      "    \"BartForConditionalGeneration\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classif_dropout\": 0.0,\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"d_model\": 24,\n",
      "  \"decoder_attention_heads\": 2,\n",
      "  \"decoder_ffn_dim\": 16,\n",
      "  \"decoder_layerdrop\": 0.0,\n",
      "  \"decoder_layers\": 2,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"do_blenderbot_90_layernorm\": false,\n",
      "  \"dropout\": 0.1,\n",
      "  \"encoder_attention_heads\": 2,\n",
      "  \"encoder_ffn_dim\": 16,\n",
      "  \"encoder_layerdrop\": 0.0,\n",
      "  \"encoder_layers\": 2,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"extra_pos_embeddings\": 2,\n",
      "  \"force_bos_token_to_be_generated\": false,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\"\n",
      "  },\n",
      "  \"init_std\": 0.02,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2\n",
      "  },\n",
      "  \"max_position_embeddings\": 1024,\n",
      "  \"model_type\": \"bart\",\n",
      "  \"normalize_before\": false,\n",
      "  \"normalize_embedding\": true,\n",
      "  \"num_hidden_layers\": 2,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"prefix\": \" \",\n",
      "  \"scale_embedding\": false,\n",
      "  \"static_position_embeddings\": false,\n",
      "  \"task_specific_params\": {\n",
      "    \"summarization\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"max_length\": 10,\n",
      "      \"min_length\": 2,\n",
      "      \"num_beams\": 1\n",
      "    }\n",
      "  },\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "[INFO|tokenization_utils_base.py:1721] 2021-01-14 14:47:01,713 >> Model name 'sshleifer/bart-tiny-random' not found in model shortcut name list (facebook/bart-base, facebook/bart-large, facebook/bart-large-mnli, facebook/bart-large-cnn, facebook/bart-large-xsum, yjernite/bart_eli5). Assuming 'sshleifer/bart-tiny-random' is a path, a model identifier, or url to a directory containing tokenizer files.\n",
      "01/14/2021 14:47:02 - INFO - filelock -   Lock 140577237102888 acquired on /home/marco/.cache/huggingface/transformers/6c6a5c8768403bcf7d2da061e943e18fa6d570179aac8951d8df0a45e5e8071e.d67d6b367eb24ab43b08ad55e014cf254076934f71d832bbab9ad35644a375ab.lock\n",
      "[INFO|file_utils.py:1301] 2021-01-14 14:47:02,058 >> https://huggingface.co/sshleifer/bart-tiny-random/resolve/main/vocab.json not found in cache or force_download set to True, downloading to /home/marco/.cache/huggingface/transformers/tmpnb_xd0yu\n",
      "Downloading: 100%|███████████████████████████| 899k/899k [00:00<00:00, 1.46MB/s]\n",
      "[INFO|file_utils.py:1305] 2021-01-14 14:47:03,071 >> storing https://huggingface.co/sshleifer/bart-tiny-random/resolve/main/vocab.json in cache at /home/marco/.cache/huggingface/transformers/6c6a5c8768403bcf7d2da061e943e18fa6d570179aac8951d8df0a45e5e8071e.d67d6b367eb24ab43b08ad55e014cf254076934f71d832bbab9ad35644a375ab\n",
      "[INFO|file_utils.py:1308] 2021-01-14 14:47:03,071 >> creating metadata file for /home/marco/.cache/huggingface/transformers/6c6a5c8768403bcf7d2da061e943e18fa6d570179aac8951d8df0a45e5e8071e.d67d6b367eb24ab43b08ad55e014cf254076934f71d832bbab9ad35644a375ab\n",
      "01/14/2021 14:47:03 - INFO - filelock -   Lock 140577237102888 released on /home/marco/.cache/huggingface/transformers/6c6a5c8768403bcf7d2da061e943e18fa6d570179aac8951d8df0a45e5e8071e.d67d6b367eb24ab43b08ad55e014cf254076934f71d832bbab9ad35644a375ab.lock\n",
      "01/14/2021 14:47:03 - INFO - filelock -   Lock 140577236947800 acquired on /home/marco/.cache/huggingface/transformers/19b7b337f8ee4dea92f336e87e5a4e785eef3ba09323cda02617d338ec06eee0.5d12962c5ee615a4c803841266e9c3be9a691a924f72d395d3a6c6c81157788b.lock\n",
      "[INFO|file_utils.py:1301] 2021-01-14 14:47:03,412 >> https://huggingface.co/sshleifer/bart-tiny-random/resolve/main/merges.txt not found in cache or force_download set to True, downloading to /home/marco/.cache/huggingface/transformers/tmpx0qlnh3_\n",
      "Downloading: 100%|████████████████████████████| 456k/456k [00:00<00:00, 895kB/s]\n",
      "[INFO|file_utils.py:1305] 2021-01-14 14:47:04,259 >> storing https://huggingface.co/sshleifer/bart-tiny-random/resolve/main/merges.txt in cache at /home/marco/.cache/huggingface/transformers/19b7b337f8ee4dea92f336e87e5a4e785eef3ba09323cda02617d338ec06eee0.5d12962c5ee615a4c803841266e9c3be9a691a924f72d395d3a6c6c81157788b\n",
      "[INFO|file_utils.py:1308] 2021-01-14 14:47:04,260 >> creating metadata file for /home/marco/.cache/huggingface/transformers/19b7b337f8ee4dea92f336e87e5a4e785eef3ba09323cda02617d338ec06eee0.5d12962c5ee615a4c803841266e9c3be9a691a924f72d395d3a6c6c81157788b\n",
      "01/14/2021 14:47:04 - INFO - filelock -   Lock 140577236947800 released on /home/marco/.cache/huggingface/transformers/19b7b337f8ee4dea92f336e87e5a4e785eef3ba09323cda02617d338ec06eee0.5d12962c5ee615a4c803841266e9c3be9a691a924f72d395d3a6c6c81157788b.lock\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO|tokenization_utils_base.py:1802] 2021-01-14 14:47:05,621 >> loading file https://huggingface.co/sshleifer/bart-tiny-random/resolve/main/vocab.json from cache at /home/marco/.cache/huggingface/transformers/6c6a5c8768403bcf7d2da061e943e18fa6d570179aac8951d8df0a45e5e8071e.d67d6b367eb24ab43b08ad55e014cf254076934f71d832bbab9ad35644a375ab\n",
      "[INFO|tokenization_utils_base.py:1802] 2021-01-14 14:47:05,621 >> loading file https://huggingface.co/sshleifer/bart-tiny-random/resolve/main/merges.txt from cache at /home/marco/.cache/huggingface/transformers/19b7b337f8ee4dea92f336e87e5a4e785eef3ba09323cda02617d338ec06eee0.5d12962c5ee615a4c803841266e9c3be9a691a924f72d395d3a6c6c81157788b\n",
      "[INFO|tokenization_utils_base.py:1802] 2021-01-14 14:47:05,622 >> loading file https://huggingface.co/sshleifer/bart-tiny-random/resolve/main/tokenizer.json from cache at None\n",
      "[INFO|tokenization_utils_base.py:1802] 2021-01-14 14:47:05,622 >> loading file https://huggingface.co/sshleifer/bart-tiny-random/resolve/main/added_tokens.json from cache at None\n",
      "[INFO|tokenization_utils_base.py:1802] 2021-01-14 14:47:05,622 >> loading file https://huggingface.co/sshleifer/bart-tiny-random/resolve/main/special_tokens_map.json from cache at None\n",
      "[INFO|tokenization_utils_base.py:1802] 2021-01-14 14:47:05,622 >> loading file https://huggingface.co/sshleifer/bart-tiny-random/resolve/main/tokenizer_config.json from cache at None\n",
      "01/14/2021 14:47:06 - INFO - filelock -   Lock 140577236938312 acquired on /home/marco/.cache/huggingface/transformers/feb6b01ffbc9a67f001f859a86e55a0715c1e36ac6d55a2c0d5ee8d380b7a0cc.81fe5616f45b11d37dd00ed1d7fbdced86522c68baff49bf54ad7e1a6063b7aa.lock\n",
      "[INFO|file_utils.py:1301] 2021-01-14 14:47:06,175 >> https://huggingface.co/sshleifer/bart-tiny-random/resolve/main/pytorch_model.bin not found in cache or force_download set to True, downloading to /home/marco/.cache/huggingface/transformers/tmpwoz8l415\n",
      "Downloading: 100%|█████████████████████████| 5.11M/5.11M [00:00<00:00, 7.73MB/s]\n",
      "[INFO|file_utils.py:1305] 2021-01-14 14:47:07,777 >> storing https://huggingface.co/sshleifer/bart-tiny-random/resolve/main/pytorch_model.bin in cache at /home/marco/.cache/huggingface/transformers/feb6b01ffbc9a67f001f859a86e55a0715c1e36ac6d55a2c0d5ee8d380b7a0cc.81fe5616f45b11d37dd00ed1d7fbdced86522c68baff49bf54ad7e1a6063b7aa\n",
      "[INFO|file_utils.py:1308] 2021-01-14 14:47:07,778 >> creating metadata file for /home/marco/.cache/huggingface/transformers/feb6b01ffbc9a67f001f859a86e55a0715c1e36ac6d55a2c0d5ee8d380b7a0cc.81fe5616f45b11d37dd00ed1d7fbdced86522c68baff49bf54ad7e1a6063b7aa\n",
      "01/14/2021 14:47:07 - INFO - filelock -   Lock 140577236938312 released on /home/marco/.cache/huggingface/transformers/feb6b01ffbc9a67f001f859a86e55a0715c1e36ac6d55a2c0d5ee8d380b7a0cc.81fe5616f45b11d37dd00ed1d7fbdced86522c68baff49bf54ad7e1a6063b7aa.lock\n",
      "[INFO|modeling_utils.py:1024] 2021-01-14 14:47:07,783 >> loading weights file https://huggingface.co/sshleifer/bart-tiny-random/resolve/main/pytorch_model.bin from cache at /home/marco/.cache/huggingface/transformers/feb6b01ffbc9a67f001f859a86e55a0715c1e36ac6d55a2c0d5ee8d380b7a0cc.81fe5616f45b11d37dd00ed1d7fbdced86522c68baff49bf54ad7e1a6063b7aa\n",
      "[INFO|modeling_utils.py:1140] 2021-01-14 14:47:07,931 >> All model checkpoint weights were used when initializing BartForConditionalGeneration.\n",
      "\n",
      "[INFO|modeling_utils.py:1149] 2021-01-14 14:47:07,931 >> All the weights of BartForConditionalGeneration were initialized from the model checkpoint at sshleifer/bart-tiny-random.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BartForConditionalGeneration for predictions without further training.\n",
      "01/14/2021 14:47:07 - INFO - utils -   using task specific params for summarization: {'early_stopping': True, 'length_penalty': 1, 'max_length': 150, 'min_length': 10, 'no_repeat_ngram_size': 5, 'num_beams': 1}\n",
      "01/14/2021 14:47:07 - INFO - __main__ -   *** Train ***\n",
      "[INFO|trainer.py:703] 2021-01-14 14:47:07,946 >> ***** Running training *****\n",
      "[INFO|trainer.py:704] 2021-01-14 14:47:07,946 >>   Num examples = 100\n",
      "[INFO|trainer.py:705] 2021-01-14 14:47:07,946 >>   Num Epochs = 10\n",
      "[INFO|trainer.py:706] 2021-01-14 14:47:07,946 >>   Instantaneous batch size per device = 4\n",
      "[INFO|trainer.py:707] 2021-01-14 14:47:07,946 >>   Total train batch size (w. parallel, distributed & accumulation) = 4\n",
      "[INFO|trainer.py:708] 2021-01-14 14:47:07,946 >>   Gradient Accumulation steps = 1\n",
      "[INFO|trainer.py:709] 2021-01-14 14:47:07,946 >>   Total optimization steps = 250\n",
      "/home/marco/epfl/magma/fine-tuning/sshleifer?bart-tiny-random_karger_books_para_train\n",
      "[INFO|integrations.py:371] 2021-01-14 14:47:07,947 >> Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mmarcoabrate\u001b[0m (use `wandb login --relogin` to force relogin)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.10.13\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33m/home/marco/epfl/magma/fine-tuning/sshleifer?bart-tiny-random_karger_books_para_train\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/marcoabrate/huggingface\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/marcoabrate/huggingface/runs/5m25kgs6\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in /home/marco/epfl/magma/fine-tuning/wandb/run-20210114_144708-5m25kgs6\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run `wandb offline` to turn off syncing.\n",
      "\n",
      "  0%|          | 0/250 [00:00<?, ?it/s]/home/marco/epfl/transformers/src/transformers/optimization.py:506: UserWarning: This overload of add_ is deprecated:\n",
      "\tadd_(Number alpha, Tensor other)\n",
      "Consider using one of the following signatures instead:\n",
      "\tadd_(Tensor other, *, Number alpha) (Triggered internally at  /opt/conda/conda-bld/pytorch_1607370140761/work/torch/csrc/utils/python_arg_parser.cpp:882.)\n",
      "  exp_avg_sq_row.mul_(beta2t).add_(1.0 - beta2t, update.mean(dim=-1))\n",
      "  4%|▍         | 10/250 [00:01<00:37,  6.43it/s]{'loss': 1378.905859375, 'learning_rate': 2.88e-05, 'epoch': 0.4}\n",
      "  8%|▊         | 20/250 [00:03<00:41,  5.58it/s]{'loss': 1631.523046875, 'learning_rate': 2.7600000000000003e-05, 'epoch': 0.8}\n",
      " 12%|█▏        | 30/250 [00:05<00:40,  5.44it/s]{'loss': 1313.713671875, 'learning_rate': 2.64e-05, 'epoch': 1.2}\n",
      " 16%|█▌        | 40/250 [00:06<00:30,  6.86it/s]{'loss': 1519.269140625, 'learning_rate': 2.52e-05, 'epoch': 1.6}\n",
      " 20%|██        | 50/250 [00:08<00:32,  6.12it/s]{'loss': 1403.31171875, 'learning_rate': 2.4e-05, 'epoch': 2.0}\n",
      " 24%|██▍       | 60/250 [00:10<00:29,  6.46it/s]{'loss': 1508.65546875, 'learning_rate': 2.2800000000000002e-05, 'epoch': 2.4}\n",
      " 28%|██▊       | 70/250 [00:11<00:24,  7.34it/s]{'loss': 1368.84990234375, 'learning_rate': 2.16e-05, 'epoch': 2.8}\n",
      " 32%|███▏      | 80/250 [00:12<00:23,  7.33it/s]{'loss': 1427.1505859375, 'learning_rate': 2.04e-05, 'epoch': 3.2}\n",
      " 36%|███▌      | 90/250 [00:14<00:22,  7.21it/s]{'loss': 1507.09833984375, 'learning_rate': 1.9200000000000003e-05, 'epoch': 3.6}\n",
      " 40%|████      | 100/250 [00:16<00:21,  7.07it/s]{'loss': 1435.0376953125, 'learning_rate': 1.8e-05, 'epoch': 4.0}\n",
      " 44%|████▍     | 110/250 [00:17<00:19,  7.08it/s]{'loss': 1302.04619140625, 'learning_rate': 1.6800000000000002e-05, 'epoch': 4.4}\n",
      " 48%|████▊     | 120/250 [00:19<00:19,  6.71it/s]{'loss': 1524.2771484375, 'learning_rate': 1.56e-05, 'epoch': 4.8}\n",
      " 52%|█████▏    | 130/250 [00:20<00:16,  7.41it/s]{'loss': 1401.09384765625, 'learning_rate': 1.44e-05, 'epoch': 5.2}\n",
      " 56%|█████▌    | 139/250 [00:22<00:15,  6.99it/s]{'loss': 1396.17158203125, 'learning_rate': 1.32e-05, 'epoch': 5.6}\n",
      " 60%|██████    | 150/250 [00:23<00:19,  5.17it/s]{'loss': 1622.8462890625, 'learning_rate': 1.2e-05, 'epoch': 6.0}\n",
      " 64%|██████▍   | 160/250 [00:25<00:12,  7.14it/s]{'loss': 1277.368359375, 'learning_rate': 1.08e-05, 'epoch': 6.4}\n",
      " 68%|██████▊   | 170/250 [00:27<00:15,  5.26it/s]{'loss': 1606.00966796875, 'learning_rate': 9.600000000000001e-06, 'epoch': 6.8}\n",
      " 72%|███████▏  | 180/250 [00:29<00:11,  6.03it/s]{'loss': 1415.0240234375, 'learning_rate': 8.400000000000001e-06, 'epoch': 7.2}\n",
      " 76%|███████▌  | 190/250 [00:30<00:11,  5.41it/s]{'loss': 1408.77216796875, 'learning_rate': 7.2e-06, 'epoch': 7.6}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 200/250 [00:32<00:07,  6.87it/s]{'loss': 1538.95517578125, 'learning_rate': 6e-06, 'epoch': 8.0}\n",
      " 84%|████████▍ | 210/250 [00:33<00:05,  6.80it/s]{'loss': 1365.183984375, 'learning_rate': 4.800000000000001e-06, 'epoch': 8.4}\n",
      " 88%|████████▊ | 220/250 [00:35<00:05,  5.72it/s]{'loss': 1575.63134765625, 'learning_rate': 3.6e-06, 'epoch': 8.8}\n",
      " 92%|█████████▏| 230/250 [00:36<00:03,  6.47it/s]{'loss': 1374.159765625, 'learning_rate': 2.4000000000000003e-06, 'epoch': 9.2}\n",
      " 96%|█████████▌| 240/250 [00:38<00:01,  7.25it/s]{'loss': 1367.71884765625, 'learning_rate': 1.2000000000000002e-06, 'epoch': 9.6}\n",
      "100%|█████████▉| 249/250 [00:39<00:00,  6.15it/s]{'loss': 1563.52060546875, 'learning_rate': 0.0, 'epoch': 10.0}\n",
      "100%|██████████| 250/250 [00:40<00:00,  4.58it/s][INFO|trainer.py:862] 2021-01-14 14:47:49,655 >> \n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "100%|██████████| 250/250 [00:40<00:00,  6.25it/s]\n",
      "[INFO|trainer.py:1226] 2021-01-14 14:47:49,656 >> Saving model checkpoint to /home/marco/epfl/magma/fine-tuning/sshleifer?bart-tiny-random_karger_books_para_train\n",
      "\n",
      "[INFO|configuration_utils.py:289] 2021-01-14 14:47:49,662 >> Configuration saved in /home/marco/epfl/magma/fine-tuning/sshleifer?bart-tiny-random_karger_books_para_train/config.json\n",
      "[INFO|modeling_utils.py:814] 2021-01-14 14:47:49,673 >> Model weights saved in /home/marco/epfl/magma/fine-tuning/sshleifer?bart-tiny-random_karger_books_para_train/pytorch_model.bin\n",
      "01/14/2021 14:47:49 - INFO - __main__ -   ***** train metrics *****\n",
      "01/14/2021 14:47:49 - INFO - __main__ -     train_samples_per_second = 2.397\n",
      "01/14/2021 14:47:49 - INFO - __main__ -     train_runtime = 41.7114\n",
      "01/14/2021 14:47:49 - INFO - __main__ -     train_n_ojbs = 100\n",
      "01/14/2021 14:47:49 - INFO - __main__ -   *** Evaluate ***\n",
      "[INFO|trainer.py:1412] 2021-01-14 14:47:49,759 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:1413] 2021-01-14 14:47:49,759 >>   Num examples = 10\n",
      "[INFO|trainer.py:1414] 2021-01-14 14:47:49,759 >>   Batch size = 4\n",
      "100%|██████████| 3/3 [00:02<00:00,  1.22it/s]\n",
      "01/14/2021 14:47:53 - INFO - __main__ -   ***** val metrics *****\n",
      "01/14/2021 14:47:53 - INFO - __main__ -     val_loss = 1782.3679\n",
      "01/14/2021 14:47:53 - INFO - __main__ -     val_rouge1 = 0.1316\n",
      "01/14/2021 14:47:53 - INFO - __main__ -     val_rouge2 = 0.0\n",
      "01/14/2021 14:47:53 - INFO - __main__ -     val_rougeL = 0.1316\n",
      "01/14/2021 14:47:53 - INFO - __main__ -     val_rougeLsum = 0.1316\n",
      "01/14/2021 14:47:53 - INFO - __main__ -     val_gen_len = 150.0\n",
      "01/14/2021 14:47:53 - INFO - __main__ -     epoch = 10.0\n",
      "01/14/2021 14:47:53 - INFO - __main__ -     val_samples_per_second = 2.377\n",
      "01/14/2021 14:47:53 - INFO - __main__ -     val_runtime = 4.2061\n",
      "01/14/2021 14:47:53 - INFO - __main__ -     val_n_ojbs = 10\n",
      "\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish, PID 18695\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Program ended successfully.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find user logs for this run at: /home/marco/epfl/magma/fine-tuning/wandb/run-20210114_144708-5m25kgs6/logs/debug.log\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find internal logs for this run at: /home/marco/epfl/magma/fine-tuning/wandb/run-20210114_144708-5m25kgs6/logs/debug-internal.log\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                        train/loss 1563.52061\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                               train/learning_rate 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                       train/epoch 10.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                             _step 250\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                          _runtime 45\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                        _timestamp 1610632073\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                  train/total_flos 2493999251136\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                    train/val_loss 1782.36792\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                  train/val_rouge1 0.1316\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                  train/val_rouge2 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                  train/val_rougeL 0.1316\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                               train/val_rougeLsum 0.1316\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                 train/val_gen_len 150.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            train/loss ▃█▂▆▃▆▃▄▆▄▁▆▃▃█▁▇▄▄▆▃▇▃▃▇\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   train/learning_rate ██▇▇▇▇▆▆▆▅▅▅▅▄▄▄▃▃▃▂▂▂▂▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           train/epoch ▁▁▂▂▂▂▃▃▃▄▄▄▄▅▅▅▆▆▆▇▇▇▇██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                 _step ▁▁▂▂▂▂▃▃▃▄▄▄▅▅▅▅▆▆▆▇▇▇▇██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              _runtime ▁▁▂▂▂▂▃▃▃▃▄▄▄▅▅▅▅▆▆▆▇▇▇▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            _timestamp ▁▁▂▂▂▂▃▃▃▃▄▄▄▅▅▅▅▆▆▆▇▇▇▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      train/total_flos ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        train/val_loss ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      train/val_rouge1 ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      train/val_rouge2 ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      train/val_rougeL ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   train/val_rougeLsum ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     train/val_gen_len ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 1 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33m/home/marco/epfl/magma/fine-tuning/sshleifer?bart-tiny-random_karger_books_para_train\u001b[0m: \u001b[34mhttps://wandb.ai/marcoabrate/huggingface/runs/5m25kgs6\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!python3 $finetune_script \\\n",
    "--model_name_or_path $model_name_or_path \\\n",
    "--config_name $model_config_dir \\\n",
    "--tokenizer_name $model_name_or_path \\\n",
    "--data_dir $data_dir \\\n",
    "--fp16 \\\n",
    "--learning_rate 3e-5 --label_smoothing 0.1 \\\n",
    "--sortish_sampler --freeze_embeds --adafactor \\\n",
    "--task summarization \\\n",
    "--max_source_length 1024 \\\n",
    "--max_target_length $config.ONE_BULLET_MAX_LEN \\\n",
    "--val_max_target_length $config.ONE_BULLET_MAX_LEN \\\n",
    "--test_max_target_length $config.ONE_BULLET_MAX_LEN \\\n",
    "--do_train \\\n",
    "--num_train_epochs 10 \\\n",
    "--logging_steps 10 --save_steps 1000 --save_total_limit 3 \\\n",
    "--per_device_train_batch_size 4 --per_device_eval_batch_size 4 \\\n",
    "--do_eval --evaluation_strategy steps --eval_steps 1000 --eval_beams 2 \\\n",
    "--metric_for_best_model rougeL --greater_is_better True \\\n",
    "--predict_with_generate \\\n",
    "--output_dir $output_dir \\\n",
    "--overwrite_output_dir \\\n",
    "--seed $config.SEED \\\n",
    "--run_name $output_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "move: sshleifer?bart-tiny-random_karger_books_para_train/all_results.json to s3://marcoabrate/output/all_results.json\n",
      "move: sshleifer?bart-tiny-random_karger_books_para_train/special_tokens_map.json to s3://marcoabrate/output/special_tokens_map.json\n",
      "move: sshleifer?bart-tiny-random_karger_books_para_train/tokenizer_config.json to s3://marcoabrate/output/tokenizer_config.json\n",
      "move: sshleifer?bart-tiny-random_karger_books_para_train/trainer_state.json to s3://marcoabrate/output/trainer_state.json\n",
      "move: sshleifer?bart-tiny-random_karger_books_para_train/train_results.json to s3://marcoabrate/output/train_results.json\n",
      "move: sshleifer?bart-tiny-random_karger_books_para_train/val_results.json to s3://marcoabrate/output/val_results.json\n",
      "move: sshleifer?bart-tiny-random_karger_books_para_train/config.json to s3://marcoabrate/output/config.json\n",
      "move: sshleifer?bart-tiny-random_karger_books_para_train/training_args.bin to s3://marcoabrate/output/training_args.bin\n",
      "move: sshleifer?bart-tiny-random_karger_books_para_train/merges.txt to s3://marcoabrate/output/merges.txt\n",
      "move: sshleifer?bart-tiny-random_karger_books_para_train/vocab.json to s3://marcoabrate/output/vocab.json\n",
      "move: sshleifer?bart-tiny-random_karger_books_para_train/pytorch_model.bin to s3://marcoabrate/output/pytorch_model.bin\n"
     ]
    }
   ],
   "source": [
    "!aws s3 mv $output_dir \"s3://marcoabrate/output\" --recursive\n",
    "# should do the same with model_config_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -r $output_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aeSSMVZwVOa1"
   },
   "source": [
    "##### Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "C2YaHOesVOa4"
   },
   "outputs": [],
   "source": [
    "source_test_dir = data_dir[:-1] + '/test.source\"'\n",
    "reference_test_dir = data_dir[:-1] + '/test.target\"'\n",
    "\n",
    "save_dir = output_dir[:-1] + '/'+model_name_or_path.replace('/', '?')+'_test_karger_books_para.txt\"'\n",
    "score_dir = output_dir[:-1] + '/'+model_name_or_path.replace('/', '?')+'_test_karger_books_para.json\"'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1399,
     "status": "ok",
     "timestamp": 1610471442216,
     "user": {
      "displayName": "Marco Pietro Abrate",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gjh-8YF-8BlnrkN9mLZ0xfVOWfOh7kYncpYRv-Y=s64",
      "userId": "15422244832836998434"
     },
     "user_tz": -60
    },
    "id": "AgY3gO94VOa9",
    "outputId": "8436601c-f530-405f-e6c6-c025a7cf5b71"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unknown option: --\n",
      "usage: python3 [option] ... [-c cmd | -m mod | file | -] [arg] ...\n",
      "Try `python -h' for more information.\n"
     ]
    }
   ],
   "source": [
    "!python3 $eval_script \\\n",
    "$output_dir \\\n",
    "$source_test_dir \\\n",
    "$save_dir \\\n",
    "--reference_path $reference_test_dir \\\n",
    "--score_path $score_dir \\\n",
    "--task summarization \\\n",
    "--bs 2 \\\n",
    "--length_penalty $config.LENAGTH_PENALTY \\\n",
    "--no_repeat_ngram_size $config.NO_REPEAT_NGRAM_SIZE \\\n",
    "--num_beams $config.NUM_BEAMS \\\n",
    "--dump-args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1bbRUTtNDHth"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyNa0Dk3mImrCcZO3VdQRayI",
   "collapsed_sections": [
    "P95DxvqWi_2Y",
    "L5sXxqeNCtkN",
    "S0FByNNOIRvG",
    "GPbOrCLWACbm",
    "siT4m5aYCFSh",
    "Dk1uGO5SCDNa",
    "WdDCBiMOBWiO",
    "pr_0J4xgBWiW",
    "l8hQT6ksBWin",
    "d5V0QCdf04Yx",
    "KQj3gt6s5ACz",
    "ah9sssub5DXX",
    "M58yiP1yVOav",
    "aeSSMVZwVOa1"
   ],
   "name": "bart_finetune.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "88734567ccb2435091eeab9f30b2de9b": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_bd07faa8d1534ff9b1967f18e6fca2c2",
       "IPY_MODEL_43ac5522170c45f7856f7097ff9fee58"
      ],
      "layout": "IPY_MODEL_431d75cb2dd2403e88015f4e009080d4"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

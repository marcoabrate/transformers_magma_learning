{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "executionInfo": {
     "elapsed": 30194,
     "status": "ok",
     "timestamp": 1610616621856,
     "user": {
      "displayName": "Marco Pietro Abrate",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gjh-8YF-8BlnrkN9mLZ0xfVOWfOh7kYncpYRv-Y=s64",
      "userId": "15422244832836998434"
     },
     "user_tz": -60
    },
    "id": "au5Z9XQAC7C-"
   },
   "outputs": [],
   "source": [
    "magma_dir = '/home/ubuntu/magma/'\n",
    "transformers_dir = '/home/ubuntu/transformers/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EddY1WDNsKlS"
   },
   "source": [
    "## **Fine-tuning**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "executionInfo": {
     "elapsed": 85455,
     "status": "ok",
     "timestamp": 1610616677129,
     "user": {
      "displayName": "Marco Pietro Abrate",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gjh-8YF-8BlnrkN9mLZ0xfVOWfOh7kYncpYRv-Y=s64",
      "userId": "15422244832836998434"
     },
     "user_tz": -60
    },
    "id": "2d6M41X9AKBi"
   },
   "outputs": [],
   "source": [
    "finetune_script = '\"'+transformers_dir+'examples/seq2seq/finetune_trainer.py\"'\n",
    "eval_script = '\"'+transformers_dir+'examples/seq2seq/run_eval.py\"'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S0FByNNOIRvG"
   },
   "source": [
    "### **Config**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 104
    },
    "executionInfo": {
     "elapsed": 113930,
     "status": "ok",
     "timestamp": 1610616705611,
     "user": {
      "displayName": "Marco Pietro Abrate",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gjh-8YF-8BlnrkN9mLZ0xfVOWfOh7kYncpYRv-Y=s64",
      "userId": "15422244832836998434"
     },
     "user_tz": -60
    },
    "id": "82WSp6khIcua",
    "outputId": "54de6794-ef3c-41f4-b0e3-e108cfc4e333"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.insert(0, magma_dir)\n",
    "import config\n",
    "\n",
    "import torch\n",
    "torch.manual_seed = config.SEED\n",
    "\n",
    "import wandb\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uPZ7A-sBVOam"
   },
   "source": [
    "### Karger Books Para"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 113928,
     "status": "ok",
     "timestamp": 1610616705613,
     "user": {
      "displayName": "Marco Pietro Abrate",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gjh-8YF-8BlnrkN9mLZ0xfVOWfOh7kYncpYRv-Y=s64",
      "userId": "15422244832836998434"
     },
     "user_tz": -60
    },
    "id": "vJOYl_g6F1e2"
   },
   "outputs": [],
   "source": [
    "model_name_or_path = 'sshleifer/bart-tiny-random'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 113926,
     "status": "ok",
     "timestamp": 1610616705616,
     "user": {
      "displayName": "Marco Pietro Abrate",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gjh-8YF-8BlnrkN9mLZ0xfVOWfOh7kYncpYRv-Y=s64",
      "userId": "15422244832836998434"
     },
     "user_tz": -60
    },
    "id": "4xs_XkbCVOar"
   },
   "outputs": [],
   "source": [
    "data_dir = '\"'+magma_dir+'datasets/karger_books_para/bart\"'\n",
    "\n",
    "output_dir = '\"'+magma_dir+'fine-tuning/'+\\\n",
    "    model_name_or_path.replace('/', '?')+'_karger_books_para_train\"'\n",
    "\n",
    "log_dir = output_dir + '/logs'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34,
     "referenced_widgets": [
      "88734567ccb2435091eeab9f30b2de9b"
     ]
    },
    "executionInfo": {
     "elapsed": 120037,
     "status": "ok",
     "timestamp": 1610616711730,
     "user": {
      "displayName": "Marco Pietro Abrate",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gjh-8YF-8BlnrkN9mLZ0xfVOWfOh7kYncpYRv-Y=s64",
      "userId": "15422244832836998434"
     },
     "user_tz": -60
    },
    "id": "wtLC1O1ZJpU3",
    "outputId": "16632326-7ab5-4ef4-aa65-44efbdf45fb3"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "702a26eff7604a288d962ec0f97cda8c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.15k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoConfig\n",
    "model_config = AutoConfig.from_pretrained(model_name_or_path)\n",
    "model_config.min_length = config.ONE_BULLET_MIN_LEN\n",
    "model_config.max_length = config.ONE_BULLET_MAX_LEN\n",
    "model_config.length_penalty = config.LENGTH_PENALTY\n",
    "model_config.no_repeat_ngram_size = config.NO_REPEAT_NGRAM_SIZE\n",
    "\n",
    "model_config.task_specific_params['summarization']['min_length'] = config.ONE_BULLET_MIN_LEN\n",
    "model_config.task_specific_params['summarization']['max_length'] = config.ONE_BULLET_MAX_LEN\n",
    "model_config.task_specific_params['summarization']['length_penalty'] = config.LENGTH_PENALTY\n",
    "model_config.task_specific_params['summarization']['no_repeat_ngram_size'] = config.NO_REPEAT_NGRAM_SIZE\n",
    "model_config_dir = '\"'+magma_dir+'fine-tuning/'+\\\n",
    "    model_name_or_path.replace('/', '?')+'_config\"'\n",
    "model_config.save_pretrained(model_config_dir[1:-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M58yiP1yVOav"
   },
   "source": [
    "##### Fine tune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2522396,
     "status": "ok",
     "timestamp": 1610555308072,
     "user": {
      "displayName": "Marco Pietro Abrate",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gjh-8YF-8BlnrkN9mLZ0xfVOWfOh7kYncpYRv-Y=s64",
      "userId": "15422244832836998434"
     },
     "user_tz": -60
    },
    "id": "K66kY1WOVOaw",
    "outputId": "11421fe6-93e5-461f-8b97-0615b4c2e7af"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "01/14/2021 11:44:08 - WARNING - __main__ -   Process rank: -1, device: cuda:0, n_gpu: 1, distributed training: False, 16-bits training: True\n",
      "01/14/2021 11:44:08 - INFO - __main__ -   Training/evaluation parameters Seq2SeqTrainingArguments(output_dir='/home/ubuntu/magma/fine-tuning/sshleifer?bart-tiny-random_karger_books_para_train', overwrite_output_dir=True, do_train=True, do_eval=True, do_predict=False, model_parallel=False, evaluation_strategy=<EvaluationStrategy.STEPS: 'steps'>, prediction_loss_only=False, per_device_train_batch_size=4, per_device_eval_batch_size=4, per_gpu_train_batch_size=None, per_gpu_eval_batch_size=None, gradient_accumulation_steps=1, eval_accumulation_steps=None, learning_rate=3e-05, weight_decay=0.0, adam_beta1=0.9, adam_beta2=0.999, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=10.0, max_steps=-1, warmup_steps=0, logging_dir='runs/Jan14_11-44-08_ip-172-31-39-35', logging_first_step=False, logging_steps=10, save_steps=1000, save_total_limit=3, no_cuda=False, seed=42, fp16=True, fp16_opt_level='O1', local_rank=-1, tpu_num_cores=None, tpu_metrics_debug=False, debug=False, dataloader_drop_last=False, eval_steps=1000, dataloader_num_workers=0, past_index=-1, run_name='/home/ubuntu/magma/fine-tuning/sshleifer?bart-tiny-random_karger_books_para_train', disable_tqdm=False, remove_unused_columns=True, label_names=None, load_best_model_at_end=False, metric_for_best_model='rougeL', greater_is_better='True', ignore_data_skip=False, fp16_backend='auto', sharded_ddp=False, label_smoothing=0.1, sortish_sampler=True, predict_with_generate=True, adafactor=True, encoder_layerdrop=None, decoder_layerdrop=None, dropout=None, attention_dropout=None, lr_scheduler='linear')\n",
      "[INFO|configuration_utils.py:429] 2021-01-14 11:44:08,027 >> loading configuration file /home/ubuntu/magma/fine-tuning/sshleifer?bart-tiny-random_config/config.json\n",
      "[INFO|configuration_utils.py:467] 2021-01-14 11:44:08,028 >> Model config BartConfig {\n",
      "  \"_num_labels\": 3,\n",
      "  \"activation_dropout\": 0.0,\n",
      "  \"activation_function\": \"gelu\",\n",
      "  \"add_bias_logits\": false,\n",
      "  \"add_final_layer_norm\": false,\n",
      "  \"architectures\": [\n",
      "    \"BartForConditionalGeneration\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classif_dropout\": 0.0,\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"d_model\": 24,\n",
      "  \"decoder_attention_heads\": 2,\n",
      "  \"decoder_ffn_dim\": 16,\n",
      "  \"decoder_layerdrop\": 0.0,\n",
      "  \"decoder_layers\": 2,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"do_blenderbot_90_layernorm\": false,\n",
      "  \"dropout\": 0.1,\n",
      "  \"encoder_attention_heads\": 2,\n",
      "  \"encoder_ffn_dim\": 16,\n",
      "  \"encoder_layerdrop\": 0.0,\n",
      "  \"encoder_layers\": 2,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"extra_pos_embeddings\": 2,\n",
      "  \"force_bos_token_to_be_generated\": false,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\"\n",
      "  },\n",
      "  \"init_std\": 0.02,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2\n",
      "  },\n",
      "  \"max_length\": 150,\n",
      "  \"max_position_embeddings\": 1024,\n",
      "  \"min_length\": 10,\n",
      "  \"model_type\": \"bart\",\n",
      "  \"no_repeat_ngram_size\": 5,\n",
      "  \"normalize_before\": false,\n",
      "  \"normalize_embedding\": true,\n",
      "  \"num_hidden_layers\": 2,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"prefix\": \" \",\n",
      "  \"scale_embedding\": false,\n",
      "  \"static_position_embeddings\": false,\n",
      "  \"task_specific_params\": {\n",
      "    \"summarization\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"length_penalty\": 1,\n",
      "      \"max_length\": 150,\n",
      "      \"min_length\": 10,\n",
      "      \"no_repeat_ngram_size\": 5,\n",
      "      \"num_beams\": 1\n",
      "    }\n",
      "  },\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "[INFO|configuration_utils.py:431] 2021-01-14 11:44:08,322 >> loading configuration file https://huggingface.co/sshleifer/bart-tiny-random/resolve/main/config.json from cache at /home/ubuntu/.cache/huggingface/transformers/d8da4d5b573fc14e71d1ccfef673e4d1bc1877d4488cbcacf0416c23fc30a3f3.9e2b1e8a205de2082b8ab3d9b358d32d0a5aa36c28ca62d9a21a3057fa42d78b\n",
      "[INFO|configuration_utils.py:467] 2021-01-14 11:44:08,322 >> Model config BartConfig {\n",
      "  \"_num_labels\": 3,\n",
      "  \"activation_dropout\": 0.0,\n",
      "  \"activation_function\": \"gelu\",\n",
      "  \"add_bias_logits\": false,\n",
      "  \"add_final_layer_norm\": false,\n",
      "  \"architectures\": [\n",
      "    \"BartForConditionalGeneration\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classif_dropout\": 0.0,\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"d_model\": 24,\n",
      "  \"decoder_attention_heads\": 2,\n",
      "  \"decoder_ffn_dim\": 16,\n",
      "  \"decoder_layerdrop\": 0.0,\n",
      "  \"decoder_layers\": 2,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"do_blenderbot_90_layernorm\": false,\n",
      "  \"dropout\": 0.1,\n",
      "  \"encoder_attention_heads\": 2,\n",
      "  \"encoder_ffn_dim\": 16,\n",
      "  \"encoder_layerdrop\": 0.0,\n",
      "  \"encoder_layers\": 2,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"extra_pos_embeddings\": 2,\n",
      "  \"force_bos_token_to_be_generated\": false,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\"\n",
      "  },\n",
      "  \"init_std\": 0.02,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2\n",
      "  },\n",
      "  \"max_position_embeddings\": 1024,\n",
      "  \"model_type\": \"bart\",\n",
      "  \"normalize_before\": false,\n",
      "  \"normalize_embedding\": true,\n",
      "  \"num_hidden_layers\": 2,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"prefix\": \" \",\n",
      "  \"scale_embedding\": false,\n",
      "  \"static_position_embeddings\": false,\n",
      "  \"task_specific_params\": {\n",
      "    \"summarization\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"max_length\": 10,\n",
      "      \"min_length\": 2,\n",
      "      \"num_beams\": 1\n",
      "    }\n",
      "  },\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "[INFO|tokenization_utils_base.py:1721] 2021-01-14 11:44:08,322 >> Model name 'sshleifer/bart-tiny-random' not found in model shortcut name list (facebook/bart-base, facebook/bart-large, facebook/bart-large-mnli, facebook/bart-large-cnn, facebook/bart-large-xsum, yjernite/bart_eli5). Assuming 'sshleifer/bart-tiny-random' is a path, a model identifier, or url to a directory containing tokenizer files.\n",
      "01/14/2021 11:44:08 - INFO - filelock -   Lock 139704027060712 acquired on /home/ubuntu/.cache/huggingface/transformers/6c6a5c8768403bcf7d2da061e943e18fa6d570179aac8951d8df0a45e5e8071e.d67d6b367eb24ab43b08ad55e014cf254076934f71d832bbab9ad35644a375ab.lock\n",
      "[INFO|file_utils.py:1301] 2021-01-14 11:44:08,607 >> https://huggingface.co/sshleifer/bart-tiny-random/resolve/main/vocab.json not found in cache or force_download set to True, downloading to /home/ubuntu/.cache/huggingface/transformers/tmpk794zqsv\n",
      "Downloading: 100%|████████████████████████████| 899k/899k [00:01<00:00, 507kB/s]\n",
      "[INFO|file_utils.py:1305] 2021-01-14 11:44:10,666 >> storing https://huggingface.co/sshleifer/bart-tiny-random/resolve/main/vocab.json in cache at /home/ubuntu/.cache/huggingface/transformers/6c6a5c8768403bcf7d2da061e943e18fa6d570179aac8951d8df0a45e5e8071e.d67d6b367eb24ab43b08ad55e014cf254076934f71d832bbab9ad35644a375ab\n",
      "[INFO|file_utils.py:1308] 2021-01-14 11:44:10,666 >> creating metadata file for /home/ubuntu/.cache/huggingface/transformers/6c6a5c8768403bcf7d2da061e943e18fa6d570179aac8951d8df0a45e5e8071e.d67d6b367eb24ab43b08ad55e014cf254076934f71d832bbab9ad35644a375ab\n",
      "01/14/2021 11:44:10 - INFO - filelock -   Lock 139704027060712 released on /home/ubuntu/.cache/huggingface/transformers/6c6a5c8768403bcf7d2da061e943e18fa6d570179aac8951d8df0a45e5e8071e.d67d6b367eb24ab43b08ad55e014cf254076934f71d832bbab9ad35644a375ab.lock\n",
      "01/14/2021 11:44:10 - INFO - filelock -   Lock 139704027060152 acquired on /home/ubuntu/.cache/huggingface/transformers/19b7b337f8ee4dea92f336e87e5a4e785eef3ba09323cda02617d338ec06eee0.5d12962c5ee615a4c803841266e9c3be9a691a924f72d395d3a6c6c81157788b.lock\n",
      "[INFO|file_utils.py:1301] 2021-01-14 11:44:10,951 >> https://huggingface.co/sshleifer/bart-tiny-random/resolve/main/merges.txt not found in cache or force_download set to True, downloading to /home/ubuntu/.cache/huggingface/transformers/tmp8ljt9afb\n",
      "Downloading: 100%|████████████████████████████| 456k/456k [00:00<00:00, 466kB/s]\n",
      "[INFO|file_utils.py:1305] 2021-01-14 11:44:12,215 >> storing https://huggingface.co/sshleifer/bart-tiny-random/resolve/main/merges.txt in cache at /home/ubuntu/.cache/huggingface/transformers/19b7b337f8ee4dea92f336e87e5a4e785eef3ba09323cda02617d338ec06eee0.5d12962c5ee615a4c803841266e9c3be9a691a924f72d395d3a6c6c81157788b\n",
      "[INFO|file_utils.py:1308] 2021-01-14 11:44:12,215 >> creating metadata file for /home/ubuntu/.cache/huggingface/transformers/19b7b337f8ee4dea92f336e87e5a4e785eef3ba09323cda02617d338ec06eee0.5d12962c5ee615a4c803841266e9c3be9a691a924f72d395d3a6c6c81157788b\n",
      "01/14/2021 11:44:12 - INFO - filelock -   Lock 139704027060152 released on /home/ubuntu/.cache/huggingface/transformers/19b7b337f8ee4dea92f336e87e5a4e785eef3ba09323cda02617d338ec06eee0.5d12962c5ee615a4c803841266e9c3be9a691a924f72d395d3a6c6c81157788b.lock\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO|tokenization_utils_base.py:1802] 2021-01-14 11:44:13,333 >> loading file https://huggingface.co/sshleifer/bart-tiny-random/resolve/main/vocab.json from cache at /home/ubuntu/.cache/huggingface/transformers/6c6a5c8768403bcf7d2da061e943e18fa6d570179aac8951d8df0a45e5e8071e.d67d6b367eb24ab43b08ad55e014cf254076934f71d832bbab9ad35644a375ab\n",
      "[INFO|tokenization_utils_base.py:1802] 2021-01-14 11:44:13,334 >> loading file https://huggingface.co/sshleifer/bart-tiny-random/resolve/main/merges.txt from cache at /home/ubuntu/.cache/huggingface/transformers/19b7b337f8ee4dea92f336e87e5a4e785eef3ba09323cda02617d338ec06eee0.5d12962c5ee615a4c803841266e9c3be9a691a924f72d395d3a6c6c81157788b\n",
      "[INFO|tokenization_utils_base.py:1802] 2021-01-14 11:44:13,334 >> loading file https://huggingface.co/sshleifer/bart-tiny-random/resolve/main/tokenizer.json from cache at None\n",
      "[INFO|tokenization_utils_base.py:1802] 2021-01-14 11:44:13,334 >> loading file https://huggingface.co/sshleifer/bart-tiny-random/resolve/main/added_tokens.json from cache at None\n",
      "[INFO|tokenization_utils_base.py:1802] 2021-01-14 11:44:13,334 >> loading file https://huggingface.co/sshleifer/bart-tiny-random/resolve/main/special_tokens_map.json from cache at None\n",
      "[INFO|tokenization_utils_base.py:1802] 2021-01-14 11:44:13,334 >> loading file https://huggingface.co/sshleifer/bart-tiny-random/resolve/main/tokenizer_config.json from cache at None\n",
      "01/14/2021 11:44:13 - INFO - filelock -   Lock 139704063516800 acquired on /home/ubuntu/.cache/huggingface/transformers/feb6b01ffbc9a67f001f859a86e55a0715c1e36ac6d55a2c0d5ee8d380b7a0cc.81fe5616f45b11d37dd00ed1d7fbdced86522c68baff49bf54ad7e1a6063b7aa.lock\n",
      "[INFO|file_utils.py:1301] 2021-01-14 11:44:13,741 >> https://huggingface.co/sshleifer/bart-tiny-random/resolve/main/pytorch_model.bin not found in cache or force_download set to True, downloading to /home/ubuntu/.cache/huggingface/transformers/tmpnf4xn0w6\n",
      "Downloading: 100%|█████████████████████████| 5.11M/5.11M [00:00<00:00, 7.03MB/s]\n",
      "[INFO|file_utils.py:1305] 2021-01-14 11:44:15,009 >> storing https://huggingface.co/sshleifer/bart-tiny-random/resolve/main/pytorch_model.bin in cache at /home/ubuntu/.cache/huggingface/transformers/feb6b01ffbc9a67f001f859a86e55a0715c1e36ac6d55a2c0d5ee8d380b7a0cc.81fe5616f45b11d37dd00ed1d7fbdced86522c68baff49bf54ad7e1a6063b7aa\n",
      "[INFO|file_utils.py:1308] 2021-01-14 11:44:15,009 >> creating metadata file for /home/ubuntu/.cache/huggingface/transformers/feb6b01ffbc9a67f001f859a86e55a0715c1e36ac6d55a2c0d5ee8d380b7a0cc.81fe5616f45b11d37dd00ed1d7fbdced86522c68baff49bf54ad7e1a6063b7aa\n",
      "01/14/2021 11:44:15 - INFO - filelock -   Lock 139704063516800 released on /home/ubuntu/.cache/huggingface/transformers/feb6b01ffbc9a67f001f859a86e55a0715c1e36ac6d55a2c0d5ee8d380b7a0cc.81fe5616f45b11d37dd00ed1d7fbdced86522c68baff49bf54ad7e1a6063b7aa.lock\n",
      "[INFO|modeling_utils.py:1024] 2021-01-14 11:44:15,010 >> loading weights file https://huggingface.co/sshleifer/bart-tiny-random/resolve/main/pytorch_model.bin from cache at /home/ubuntu/.cache/huggingface/transformers/feb6b01ffbc9a67f001f859a86e55a0715c1e36ac6d55a2c0d5ee8d380b7a0cc.81fe5616f45b11d37dd00ed1d7fbdced86522c68baff49bf54ad7e1a6063b7aa\n",
      "[INFO|modeling_utils.py:1140] 2021-01-14 11:44:15,176 >> All model checkpoint weights were used when initializing BartForConditionalGeneration.\n",
      "\n",
      "[INFO|modeling_utils.py:1149] 2021-01-14 11:44:15,176 >> All the weights of BartForConditionalGeneration were initialized from the model checkpoint at sshleifer/bart-tiny-random.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BartForConditionalGeneration for predictions without further training.\n",
      "01/14/2021 11:44:15 - INFO - utils -   using task specific params for summarization: {'early_stopping': True, 'length_penalty': 1, 'max_length': 150, 'min_length': 10, 'no_repeat_ngram_size': 5, 'num_beams': 1}\n",
      "01/14/2021 11:44:19 - INFO - __main__ -   *** Train ***\n",
      "[INFO|trainer.py:703] 2021-01-14 11:44:19,717 >> ***** Running training *****\n",
      "[INFO|trainer.py:704] 2021-01-14 11:44:19,718 >>   Num examples = 2046\n",
      "[INFO|trainer.py:705] 2021-01-14 11:44:19,718 >>   Num Epochs = 10\n",
      "[INFO|trainer.py:706] 2021-01-14 11:44:19,718 >>   Instantaneous batch size per device = 4\n",
      "[INFO|trainer.py:707] 2021-01-14 11:44:19,718 >>   Total train batch size (w. parallel, distributed & accumulation) = 4\n",
      "[INFO|trainer.py:708] 2021-01-14 11:44:19,718 >>   Gradient Accumulation steps = 1\n",
      "[INFO|trainer.py:709] 2021-01-14 11:44:19,718 >>   Total optimization steps = 5120\n",
      "/home/ubuntu/magma/fine-tuning/sshleifer?bart-tiny-random_karger_books_para_train\n",
      "[INFO|integrations.py:371] 2021-01-14 11:44:19,719 >> Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mmarcoabrate\u001b[0m (use `wandb login --relogin` to force relogin)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.10.13\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33m/home/ubuntu/magma/fine-tuning/sshleifer?bart-tiny-random_karger_books_para_train\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/marcoabrate/huggingface\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/marcoabrate/huggingface/runs/abl7vul8\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in /home/ubuntu/magma/fine-tuning/wandb/run-20210114_114420-abl7vul8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run `wandb offline` to turn off syncing.\n",
      "\n",
      "  0%|          | 0/5120 [00:00<?, ?it/s]/home/ubuntu/transformers/src/transformers/optimization.py:506: UserWarning: This overload of add_ is deprecated:\n",
      "\tadd_(Number alpha, Tensor other)\n",
      "Consider using one of the following signatures instead:\n",
      "\tadd_(Tensor other, *, Number alpha) (Triggered internally at  /opt/conda/conda-bld/pytorch_1607370120218/work/torch/csrc/utils/python_arg_parser.cpp:882.)\n",
      "  exp_avg_sq_row.mul_(beta2t).add_(1.0 - beta2t, update.mean(dim=-1))\n",
      "  0%|          | 10/5120 [00:01<09:36,  8.86it/s]140625e-05, 'epoch': 0.01953125}\n",
      "  0%|          | 20/5120 [00:02<05:36, 15.17it/s]2812500000002e-05, 'epoch': 0.0390625}\n",
      "                                                 {'loss': 1406.6224609375, 'learning_rate': 2.982421875e-05, 'epoch': 0.05859375}\n",
      "                                                 {'loss': 1199.0234375, 'learning_rate': 2.9765625e-05, 'epoch': 0.078125}\n",
      "                                                 {'loss': 1492.6685546875, 'learning_rate': 2.970703125e-05, 'epoch': 0.09765625}\n",
      "                                                 {'loss': 1490.1173828125, 'learning_rate': 2.96484375e-05, 'epoch': 0.1171875}\n",
      "  1%|▏         | 70/5120 [00:05<04:57, 16.98it/s]{'loss': 1748.6869140625, 'learning_rate': 2.958984375e-05, 'epoch': 0.13671875}\n",
      "  2%|▏         | 80/5120 [00:05<04:52, 17.26it/s]{'loss': 1316.88681640625, 'learning_rate': 2.953125e-05, 'epoch': 0.15625}\n",
      "  2%|▏         | 90/5120 [00:06<04:51, 17.23it/s]{'loss': 1596.56904296875, 'learning_rate': 2.9472656250000002e-05, 'epoch': 0.17578125}\n",
      "  2%|▏         | 100/5120 [00:07<05:25, 15.40it/s]5e-05, 'epoch': 0.1953125}\n",
      "  2%|▏         | 110/5120 [00:07<05:02, 16.56it/s]{'loss': 1473.1515625, 'learning_rate': 2.935546875e-05, 'epoch': 0.21484375}\n",
      "  2%|▏         | 120/5120 [00:08<04:57, 16.79it/s]{'loss': 1583.68076171875, 'learning_rate': 2.9296875000000002e-05, 'epoch': 0.234375}\n",
      "                                                  {'loss': 1357.29052734375, 'learning_rate': 2.923828125e-05, 'epoch': 0.25390625}\n",
      "  3%|▎         | 140/5120 [00:09<04:56, 16.81it/s]{'loss': 1401.07919921875, 'learning_rate': 2.91796875e-05, 'epoch': 0.2734375}\n",
      "  3%|▎         | 150/5120 [00:10<04:57, 16.71it/s]{'loss': 1483.4328125, 'learning_rate': 2.912109375e-05, 'epoch': 0.29296875}\n",
      "                                                  {'loss': 1423.69736328125, 'learning_rate': 2.90625e-05, 'epoch': 0.3125}\n",
      "  3%|▎         | 170/5120 [00:11<04:55, 16.75it/s]{'loss': 1555.1904296875, 'learning_rate': 2.900390625e-05, 'epoch': 0.33203125}\n",
      "  4%|▎         | 180/5120 [00:11<04:52, 16.90it/s]125e-05, 'epoch': 0.3515625}\n",
      "  4%|▎         | 188/5120 [00:12<04:54, 16.74it/s]^C\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/transformers/examples/seq2seq/finetune_trainer.py\", line 379, in <module>\n",
      "    main()\n",
      "  File \"/home/ubuntu/transformers/examples/seq2seq/finetune_trainer.py\", line 316, in main\n",
      "    model_path=model_args.model_name_or_path if os.path.isdir(model_args.model_name_or_path) else None\n",
      "  File \"/home/ubuntu/transformers/src/transformers/trainer.py\", line 799, in train\n",
      "    tr_loss += self.training_step(model, inputs)\n",
      "  File \"/home/ubuntu/transformers/src/transformers/trainer.py\", line 1137, in training_step\n",
      "    loss = self.compute_loss(model, inputs)\n",
      "  File \"/home/ubuntu/transformers/examples/seq2seq/seq2seq_trainer.py\", line 180, in compute_loss\n",
      "    loss, _ = self._compute_loss(model, inputs, labels)\n",
      "  File \"/home/ubuntu/transformers/examples/seq2seq/seq2seq_trainer.py\", line 173, in _compute_loss\n",
      "    logits = model(**inputs, use_cache=False)[0]\n",
      "  File \"/home/ubuntu/miniconda3/envs/magma/lib/python3.6/site-packages/torch/nn/modules/module.py\", line 727, in _call_impl\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"/home/ubuntu/transformers/src/transformers/models/bart/modeling_bart.py\", line 1246, in forward\n",
      "    return_dict=return_dict,\n",
      "  File \"/home/ubuntu/miniconda3/envs/magma/lib/python3.6/site-packages/torch/nn/modules/module.py\", line 727, in _call_impl\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"/home/ubuntu/transformers/src/transformers/models/bart/modeling_bart.py\", line 1097, in forward\n",
      "    return_dict=return_dict,\n",
      "  File \"/home/ubuntu/miniconda3/envs/magma/lib/python3.6/site-packages/torch/nn/modules/module.py\", line 727, in _call_impl\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"/home/ubuntu/transformers/src/transformers/models/bart/modeling_bart.py\", line 775, in forward\n",
      "    hidden_states, attn = encoder_layer(hidden_states, attention_mask, output_attentions=output_attentions)\n",
      "  File \"/home/ubuntu/miniconda3/envs/magma/lib/python3.6/site-packages/torch/nn/modules/module.py\", line 727, in _call_impl\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"/home/ubuntu/transformers/src/transformers/models/bart/modeling_bart.py\", line 357, in forward\n",
      "    hidden_states=hidden_states, attention_mask=attention_mask, output_attentions=output_attentions\n",
      "  File \"/home/ubuntu/miniconda3/envs/magma/lib/python3.6/site-packages/torch/nn/modules/module.py\", line 727, in _call_impl\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"/home/ubuntu/transformers/src/transformers/models/bart/modeling_bart.py\", line 239, in forward\n",
      "    query_states = self.q_proj(hidden_states) * self.scaling\n",
      "  File \"/home/ubuntu/miniconda3/envs/magma/lib/python3.6/site-packages/torch/nn/modules/module.py\", line 727, in _call_impl\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"/home/ubuntu/miniconda3/envs/magma/lib/python3.6/site-packages/torch/nn/modules/linear.py\", line 93, in forward\n",
      "    return F.linear(input, self.weight, self.bias)\n",
      "  File \"/home/ubuntu/miniconda3/envs/magma/lib/python3.6/site-packages/torch/nn/functional.py\", line 1692, in linear\n",
      "    output = input.matmul(weight.t())\n",
      "KeyboardInterrupt\n",
      "\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish, PID 4185\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Program failed with code 255.  Press ctrl-c to abort syncing.\n"
     ]
    }
   ],
   "source": [
    "!python3 $finetune_script \\\n",
    "--model_name_or_path $model_name_or_path \\\n",
    "--config_name $model_config_dir \\\n",
    "--tokenizer_name $model_name_or_path \\\n",
    "--data_dir $data_dir \\\n",
    "--fp16 \\\n",
    "--learning_rate 3e-5 --label_smoothing 0.1 \\\n",
    "--sortish_sampler --freeze_embeds --adafactor \\\n",
    "--task summarization \\\n",
    "--max_source_length 1024 \\\n",
    "--max_target_length $config.ONE_BULLET_MAX_LEN \\\n",
    "--val_max_target_length $config.ONE_BULLET_MAX_LEN \\\n",
    "--test_max_target_length $config.ONE_BULLET_MAX_LEN \\\n",
    "--do_train \\\n",
    "--num_train_epochs 10 \\\n",
    "--logging_steps 10 --save_steps 1000 --save_total_limit 3 \\\n",
    "--per_device_train_batch_size 4 --per_device_eval_batch_size 4 \\\n",
    "--do_eval --evaluation_strategy steps --eval_steps 1000 --eval_beams 2 \\\n",
    "--metric_for_best_model rougeL --greater_is_better True \\\n",
    "--predict_with_generate \\\n",
    "--output_dir $output_dir \\\n",
    "--overwrite_output_dir \\\n",
    "--seed $config.SEED \\\n",
    "--run_name $output_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aeSSMVZwVOa1"
   },
   "source": [
    "##### Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "C2YaHOesVOa4"
   },
   "outputs": [],
   "source": [
    "source_test_dir = data_dir[:-1] + '/test.source\"'\n",
    "reference_test_dir = data_dir[:-1] + '/test.target\"'\n",
    "\n",
    "save_dir = output_dir[:-1] + '/'+model_name_or_path.replace('/', '?')+'_test_karger_books_para.txt\"'\n",
    "score_dir = output_dir[:-1] + '/'+model_name_or_path.replace('/', '?')+'_test_karger_books_para.json\"'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1399,
     "status": "ok",
     "timestamp": 1610471442216,
     "user": {
      "displayName": "Marco Pietro Abrate",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gjh-8YF-8BlnrkN9mLZ0xfVOWfOh7kYncpYRv-Y=s64",
      "userId": "15422244832836998434"
     },
     "user_tz": -60
    },
    "id": "AgY3gO94VOa9",
    "outputId": "8436601c-f530-405f-e6c6-c025a7cf5b71"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unknown option: --\n",
      "usage: python3 [option] ... [-c cmd | -m mod | file | -] [arg] ...\n",
      "Try `python -h' for more information.\n"
     ]
    }
   ],
   "source": [
    "!python3 $eval_script \\\n",
    "$output_dir \\\n",
    "$source_test_dir \\\n",
    "$save_dir \\\n",
    "--reference_path $reference_test_dir \\\n",
    "--score_path $score_dir \\\n",
    "--task summarization \\\n",
    "--bs 2 \\\n",
    "--length_penalty $config.LENAGTH_PENALTY \\\n",
    "--no_repeat_ngram_size $config.NO_REPEAT_NGRAM_SIZE \\\n",
    "--num_beams $config.NUM_BEAMS \\\n",
    "--dump-args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1bbRUTtNDHth"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyNa0Dk3mImrCcZO3VdQRayI",
   "collapsed_sections": [
    "P95DxvqWi_2Y",
    "L5sXxqeNCtkN",
    "S0FByNNOIRvG",
    "GPbOrCLWACbm",
    "siT4m5aYCFSh",
    "Dk1uGO5SCDNa",
    "WdDCBiMOBWiO",
    "pr_0J4xgBWiW",
    "l8hQT6ksBWin",
    "d5V0QCdf04Yx",
    "KQj3gt6s5ACz",
    "ah9sssub5DXX",
    "M58yiP1yVOav",
    "aeSSMVZwVOa1"
   ],
   "name": "bart_finetune.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "88734567ccb2435091eeab9f30b2de9b": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_bd07faa8d1534ff9b1967f18e6fca2c2",
       "IPY_MODEL_43ac5522170c45f7856f7097ff9fee58"
      ],
      "layout": "IPY_MODEL_431d75cb2dd2403e88015f4e009080d4"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "magma_dir = '/home/marco/epfl/magma/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S0FByNNOIRvG"
   },
   "source": [
    "### **Config**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "executionInfo": {
     "elapsed": 58788,
     "status": "ok",
     "timestamp": 1610359570812,
     "user": {
      "displayName": "Marco Pietro Abrate",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gjh-8YF-8BlnrkN9mLZ0xfVOWfOh7kYncpYRv-Y=s64",
      "userId": "15422244832836998434"
     },
     "user_tz": -60
    },
    "id": "TAoI-Sm37yuM"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "sys.path.insert(0, magma_dir)\n",
    "import config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "executionInfo": {
     "elapsed": 59486,
     "status": "ok",
     "timestamp": 1610359571513,
     "user": {
      "displayName": "Marco Pietro Abrate",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gjh-8YF-8BlnrkN9mLZ0xfVOWfOh7kYncpYRv-Y=s64",
      "userId": "15422244832836998434"
     },
     "user_tz": -60
    },
    "id": "82WSp6khIcua"
   },
   "outputs": [],
   "source": [
    "MODEL = 'bart'\n",
    "\n",
    "RE_SPLITTER = '\\n'              # do we split sentences of paragraphs?\n",
    "                                # use '\\.(?!\\d)|\\n' or '\\n', respectively\n",
    "\n",
    "TOKEN_MAX_LEN = 99              # max length of a word\n",
    "PARA_MIN_LENGTH = 2             # minimum length for a sentence or\n",
    "                                # a paragraph, in tokens\n",
    "\n",
    "# Output path\n",
    "OUTPUT_PATH = magma_dir+'pipeline/karger_books_para_extraction/'+MODEL+'/'\n",
    "if not os.path.exists(OUTPUT_PATH):\n",
    "    os.makedirs(OUTPUT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "executionInfo": {
     "elapsed": 59489,
     "status": "ok",
     "timestamp": 1610359571520,
     "user": {
      "displayName": "Marco Pietro Abrate",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gjh-8YF-8BlnrkN9mLZ0xfVOWfOh7kYncpYRv-Y=s64",
      "userId": "15422244832836998434"
     },
     "user_tz": -60
    },
    "id": "KJMpUw0Wl8NH"
   },
   "outputs": [],
   "source": [
    "# Topic modeling specific configurations\n",
    "\n",
    "REDUCTION_MAX_LEN = 1024        # maximum length of the LDA/LSI/TextRank reduction\n",
    "\n",
    "STOPWORDS_EXTENSION =\\\n",
    "    ['may', 'might',\n",
    "     'also', 'with',\n",
    "     'without', 'use',\n",
    "     'uses', 'used', 'using']\n",
    "\n",
    "STEMMER = 'snowball'            # name of the stemmer, might use 'porter'\n",
    "\n",
    "N_GRAM = 2                      # the length of n-gram we want to create\n",
    "N_GRAM_MIN_COUNT = 2            # there should be at least N_GRAM_MIN_COUNT\n",
    "                                # repetitions in the text\n",
    "N_GRAM_THRESHOLD = 20           # see gensim.Phrases documentation\n",
    "\n",
    "DIC_NO_BELOW = 3                # keep tokens present in DIC_NO_BELOW+ sentences/paragraphs\n",
    "DIC_NO_ABOVE = 1                # fraction of total corpus size (default: 1)\n",
    "\n",
    "TOP_N = 30                      # number of words to keep for each topic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tb7fAfzaK4es"
   },
   "source": [
    "### **Init**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0,
     "referenced_widgets": [
      "3a0917c309734495885543d54e7bd8c2",
      "7aa26b43182d43058c2a04e7cec5cf71"
     ]
    },
    "executionInfo": {
     "elapsed": 66395,
     "status": "ok",
     "timestamp": 1610359578432,
     "user": {
      "displayName": "Marco Pietro Abrate",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gjh-8YF-8BlnrkN9mLZ0xfVOWfOh7kYncpYRv-Y=s64",
      "userId": "15422244832836998434"
     },
     "user_tz": -60
    },
    "id": "wvbMlPBxk45S",
    "outputId": "b4ac510d-34d9-4940-fa2c-38bdf017e9bd"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import re\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import gensim\n",
    "from textwrap import fill\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "\n",
    "if 'pegasus' in MODEL:\n",
    "    from transformers import PegasusTokenizer\n",
    "    tokenizer =\\\n",
    "        PegasusTokenizer.from_pretrained('google/pegasus-large')\n",
    "elif 'bart' in MODEL:\n",
    "    from transformers import BartTokenizer\n",
    "    tokenizer =\\\n",
    "        BartTokenizer.from_pretrained('facebook/bart-large-cnn')\n",
    "elif 't5' in MODEL:\n",
    "    from transformers import T5Tokenizer\n",
    "    tokenizer =\\\n",
    "        T5Tokenizer.from_pretrained('t5-large')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JFd0ppeJyX1o"
   },
   "source": [
    "### **Karger Books Base Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "Z0lbkScg0a7j"
   },
   "outputs": [],
   "source": [
    "base_dataset = magma_dir+'datasets/karger_books_base/df.csv'\n",
    "df = pd.read_csv(base_dataset)\n",
    "df = df.set_index(['book', 'chapter', 'section', 'subsection'])\n",
    "df.bullets = df.bullets.map(eval, na_action='ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vb_MdivVauzb"
   },
   "source": [
    "## **Topic modeling**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "id": "SSd3WuiICKfQ"
   },
   "source": [
    "### **Preprocessing**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true,
    "id": "8fXJEMYaCKfn"
   },
   "source": [
    "#### Preprocessing\n",
    "\n",
    "* Split based on RE_SPLITTER\n",
    "* Explode the dataset\n",
    "* Remove unwanted chars at beginning or end of sentence\n",
    "* Remove multiple spaces\n",
    "* Remove long words (> TOKEN_MAX_LEN chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "hidden": true,
    "id": "aaYoqzcyCKfp"
   },
   "outputs": [],
   "source": [
    "# Split in sentences / paragraphs based on RE_SPLITTER\n",
    "df.text =\\\n",
    "    df.text.map(lambda x: [p.strip() for p in re.split(RE_SPLITTER, x) if p!=''],\n",
    "                na_action='ignore')\n",
    "    \n",
    "# explode to get one row for each paragraph /sentence\n",
    "df = df.explode('text')\n",
    "df = df.rename(columns={'text': 'para'})\n",
    "df = df.dropna()\n",
    "\n",
    "# Remove unwanted chars at beginning or end of sentence\n",
    "df.para = df.para.map(lambda p: p.lstrip('.,;:-)] \\n'))\n",
    "df.para = df.para.map(lambda p: p.rstrip('.,;:-([ \\n'))\n",
    "\n",
    "# Remove multiple spaces\n",
    "df.para = df.para.map(lambda p:\n",
    "    re.sub('\\s+', ' ', p).strip())\n",
    "\n",
    "# Remove long words (> TOKEN_MAX_LEN chars)\n",
    "def para2words(para):\n",
    "    return gensim.utils.simple_preprocess(\n",
    "        para, deacc=True, max_len=TOKEN_MAX_LEN)\n",
    "df['para_proc'] = df.para.map(para2words)\n",
    "df['bullets_proc'] = df.bullets.map(lambda bs: [para2words(b) for b in bs])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Further Preprocessing\n",
    "\n",
    "* Remove stop words\n",
    "* Remove short sentences / paragraphs (< PARA_MIN_LENGTH tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/marco/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = stopwords.words('english')\n",
    "\n",
    "df.para_proc = df.para_proc.map(lambda p:\n",
    "    [w for w in p if w not in stop_words])\n",
    "df.bullets_proc = df.bullets_proc.map(lambda bs:\n",
    "    [[w for w in b if w not in stop_words] for b in bs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Remove short sentences / paragraphs (< PARA_MIN_LENGTH tokens)\n",
    "df.loc[df.para_proc.map(len) <\\\n",
    "    PARA_MIN_LENGTH, 'para_proc'] = np.nan\n",
    "\n",
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df.para = df.para.map(lambda p: p+'.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UpaitY9dlTM5"
   },
   "source": [
    "### **Topic modeling**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "gKBuLTt5qQ1Z"
   },
   "outputs": [],
   "source": [
    "# Stem\n",
    "if 'port' in STEMMER:\n",
    "    from nltk.stem.porter import PorterStemmer\n",
    "    st = PorterStemmer()\n",
    "elif 'snow' in STEMMER:\n",
    "    from nltk.stem.snowball import SnowballStemmer\n",
    "    st = SnowballStemmer('english')\n",
    "\n",
    "df.para_proc = df.para_proc.map(lambda p:\n",
    "    [st.stem(w) for w in p], na_action='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "QHKOznWOqQ1i"
   },
   "outputs": [],
   "source": [
    "# Create n-grams (N_GRAM)\n",
    "data_words = df.para_proc.dropna().values.tolist()\n",
    "\n",
    "if N_GRAM == 2:\n",
    "    bigram = gensim.models.Phrases(\n",
    "        data_words,\n",
    "        min_count=N_GRAM_MIN_COUNT,\n",
    "        threshold=N_GRAM_THRESHOLD)\n",
    "\n",
    "    df.para_proc = df.para_proc.map(lambda p:\n",
    "        [b for b in bigram[p]], na_action='ignore')\n",
    "    \n",
    "elif N_GRAM == 3:\n",
    "    trigram = gensim.models.Phrases(\n",
    "        bigram[data_words],\n",
    "        min_count=N_GRAM_MIN_COUNT,\n",
    "        threshold=N_GRAM_THRESHOLD)\n",
    "    \n",
    "    df.para_proc = df.para_proc.map(lambda p:\n",
    "        [b for b in trigram[bigram[p]]], na_action='ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UMPw10hNljZ1"
   },
   "source": [
    "#### Dictionary (DIC_NO_BELOW, DIC_NO_ABOVE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 14060,
     "status": "ok",
     "timestamp": 1610110852799,
     "user": {
      "displayName": "Marco Pietro Abrate",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gjh-8YF-8BlnrkN9mLZ0xfVOWfOh7kYncpYRv-Y=s64",
      "userId": "15422244832836998434"
     },
     "user_tz": -60
    },
    "id": "OaMCDRcNlW9M",
    "outputId": "3f9bb004-e958-42d8-9970-b2ac462fa6f4"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/marco/miniconda3/envs/magma/lib/python3.6/site-packages/ipykernel_launcher.py:11: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    }
   ],
   "source": [
    "# Create dictionary for topic model (DIC_NO_BELOW, DIC_NO_ABOVE)\n",
    "book_ch_comb = set(zip(df.index.get_level_values(0),\n",
    "    df.index.get_level_values(1)))\n",
    "\n",
    "id2word = {}\n",
    "for book, ch in book_ch_comb:\n",
    "    if book not in id2word:\n",
    "        id2word[book] = {}\n",
    "\n",
    "    id2word[book][ch] = gensim.corpora.Dictionary(\n",
    "        df.loc[book, ch].para_proc.dropna().values.tolist() )\n",
    "\n",
    "    id2word[book][ch].filter_extremes(\n",
    "        no_below = DIC_NO_BELOW, no_above = DIC_NO_ABOVE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WhO2hirsvrcc"
   },
   "source": [
    "#### LDA\n",
    "\n",
    "https://radimrehurek.com/gensim_3.8.3/models/ldamodel.html\n",
    "\n",
    "https://www.di.ens.fr/~fbach/mdhnips2010.pdf\n",
    "\n",
    "Keep N_TOP words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "R1QAj1x72aqb"
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "def get_lda_model(df, book, ch):\n",
    "    corpus = df.loc[book, ch].para_proc.map(id2word[book][ch].doc2bow,\n",
    "        na_action='ignore').dropna().values.tolist()\n",
    "\n",
    "    return gensim.models.ldamodel.LdaModel(\n",
    "        corpus = corpus,\n",
    "        num_topics = 1,\n",
    "        id2word = id2word[book][ch],\n",
    "        alpha = 'auto',\n",
    "        random_state = config.SEED)\n",
    "\n",
    "lda_word2prob = {}\n",
    "for book, ch in book_ch_comb:       \n",
    "    if book not in lda_word2prob:\n",
    "        lda_word2prob[book] = {}\n",
    "\n",
    "    lda_word2prob[book][ch] = dict(\\\n",
    "        get_lda_model(df, book, ch).show_topic(0, TOP_N))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IeDlmvn43RsI"
   },
   "source": [
    "### **Paragraph importance**\n",
    "\n",
    "\\begin{equation}\n",
    "\\text{importance}(p) = \\frac{\\sum_{w \\in p} \\text{probability}(w)}{\\sqrt{\\text{length}(p)}}\\quad\\quad\\text{what about}\\quad\\frac{\\sum_{w \\in p} \\text{probability}(w)}{log(\\text{length}(p))}\\quad?\n",
    "\\end{equation}\n",
    "\n",
    "Where $p$ is a paragraph or a sentence, $w$ is a word (token) and $\\text{probability}$ is the probability assigned by LDA or LSI model to $w$ (0 if it is not present in the TOP_N words)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 42565,
     "status": "ok",
     "timestamp": 1610110906175,
     "user": {
      "displayName": "Marco Pietro Abrate",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gjh-8YF-8BlnrkN9mLZ0xfVOWfOh7kYncpYRv-Y=s64",
      "userId": "15422244832836998434"
     },
     "user_tz": -60
    },
    "id": "EnODsA484Zrr",
    "outputId": "0f9dbf85-cbb8-4e7b-a70b-07e3ec9fda5c"
   },
   "outputs": [],
   "source": [
    "def word_importance(model_word2prob, word):\n",
    "    return model_word2prob.get(word, 0)\n",
    "\n",
    "def para_importance(model_word2prob, para):\n",
    "    l_importance = [word_importance(model_word2prob, w) for w in para]\n",
    "    return  np.sum(l_importance) / np.sqrt(len(l_importance))\n",
    "\n",
    "df['lda_imp'] = np.nan\n",
    "df['lda_imp_norm'] = np.nan\n",
    "for book, ch in book_ch_comb:\n",
    "    idx_slice = pd.IndexSlice[book, ch, :, :]\n",
    "    # getting LDA and LSI importance\n",
    "    df.loc[idx_slice, 'lda_imp'] = df.loc[idx_slice, 'para_proc'].map(lambda p:\n",
    "        para_importance(lda_word2prob[book][ch], p), na_action='ignore')\n",
    "\n",
    "    # normalizing\n",
    "    s = df.loc[idx_slice, 'lda_imp']\n",
    "    df.loc[idx_slice, 'lda_imp_norm'] = s.sub(s.min()).div((s.max() - s.min()))\n",
    "\n",
    "df['n_tok'] = df.para.map(lambda p: len(tokenizer.encode(p)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KckYUropR-xG"
   },
   "source": [
    "### **Reducing**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NfsBzMt1OoAP"
   },
   "source": [
    "#### 0-1 Knapsack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Kh12oYLXOroc"
   },
   "outputs": [],
   "source": [
    "def knap_sack(max_l, df, name_value = 'lda_imp_norm'):\n",
    "    \"\"\"Return max possible good items fit within capacity.\n",
    "    \"\"\"\n",
    "\n",
    "    df_rst = df.dropna().reset_index()\n",
    "    m = [[0 for j in range(max_l + 1)] for i in range(len(df_rst))]\n",
    "    for index, row in df_rst.iterrows():\n",
    "        for j in range(1, max_l + 1):\n",
    "            if j < row.n_tok:\n",
    "                m[index][j] = m[index - 1][j]\n",
    "            else:\n",
    "                m[index][j] = max(row[name_value] +\\\n",
    "                                  m[index - 1][j - row.n_tok],\n",
    "                    m[index - 1][j])\n",
    "\n",
    "    ans = []\n",
    "    i = len(df_rst) - 1\n",
    "    j = max_l\n",
    "    while i > 0 and j > 0:\n",
    "        if m[i][j] != m[i - 1][j]:\n",
    "            ans.append((i, df_rst.iloc[i].para))\n",
    "            j -= df_rst.iloc[i].n_tok\n",
    "        i -= 1\n",
    "\n",
    "    ans = sorted(ans, key = lambda x: x[0])\n",
    "    return [x[1] for x in ans]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1x886q72Ggs0"
   },
   "source": [
    "#### LDA reduction\n",
    "\n",
    "* Keep REDUCTION_MAX_LEN tokens and maximize importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "O_6p7MGKtpbz"
   },
   "outputs": [],
   "source": [
    "reductions = ['lda', 'lsi']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 32566,
     "status": "ok",
     "timestamp": 1610110906507,
     "user": {
      "displayName": "Marco Pietro Abrate",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gjh-8YF-8BlnrkN9mLZ0xfVOWfOh7kYncpYRv-Y=s64",
      "userId": "15422244832836998434"
     },
     "user_tz": -60
    },
    "id": "3-yNIL30RzUp",
    "outputId": "86c4a42c-517b-4261-e6c1-0cc740df9f16"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "df = df.sort_index()\n",
    "print(df.index.is_lexsorted())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1744275,
     "status": "ok",
     "timestamp": 1610112618220,
     "user": {
      "displayName": "Marco Pietro Abrate",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gjh-8YF-8BlnrkN9mLZ0xfVOWfOh7kYncpYRv-Y=s64",
      "userId": "15422244832836998434"
     },
     "user_tz": -60
    },
    "id": "NozpEdhtK4NF",
    "outputId": "4e980318-642a-4717-9a37-be73e573a493"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 453/453 [28:31<00:00,  3.78s/it]\n"
     ]
    }
   ],
   "source": [
    "from gensim.summarization.summarizer import summarize\n",
    "\n",
    "df['lda_reduction'] = ''\n",
    "df['lsi_reduction'] = ''\n",
    "df['textrank_reduction'] = ''\n",
    "for book, ch in tqdm(set(zip(df.index.get_level_values(0),\n",
    "                        df.index.get_level_values(1)))):\n",
    "    for redu in reductions:\n",
    "        # LDA, LSI\n",
    "        redu_text = knap_sack(REDUCTION_MAX_LEN,\n",
    "            df.loc[book, ch], name_value = redu+'_imp_norm')\n",
    "        df.loc[(book, ch), redu+'_reduction'] = ''.join(redu_text)\n",
    "\n",
    "    # TextRank\n",
    "    textrank_redu = summarize(\n",
    "        df.loc[book, ch].para.str.cat(),\n",
    "        word_count=int(0.5*REDUCTION_MAX_LEN),\n",
    "        split=True)\n",
    "    df.loc[(book, ch), 'textrank_reduction'] = ' '.join(textrank_redu)\n",
    "\n",
    "reductions.append('textrank')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fWM3YGRgU0ts"
   },
   "outputs": [],
   "source": [
    "df = df.groupby(level=[0, 1], sort=False).agg(\n",
    "    {'para': lambda t: ''.join([p for p in t]),\n",
    "     'bullets': lambda b: list(b)[0],\n",
    "     'lda_reduction': lambda t: list(t)[0],\n",
    "     'lsi_reduction': lambda t: list(t)[0],\n",
    "     'textrank_reduction': lambda t: list(t)[0]})\n",
    "df = df.rename(columns={'para': 'text'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L9AIlf42vH_v"
   },
   "source": [
    "#### Number of remaining tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1742629,
     "status": "ok",
     "timestamp": 1610112623190,
     "user": {
      "displayName": "Marco Pietro Abrate",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gjh-8YF-8BlnrkN9mLZ0xfVOWfOh7kYncpYRv-Y=s64",
      "userId": "15422244832836998434"
     },
     "user_tz": -60
    },
    "id": "8amZeq1D9xOO",
    "outputId": "5d4091cd-445d-4fdc-dad2-dfe2a91f99a9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lda\n",
      "count    453.000000\n",
      "mean     883.463576\n",
      "std       38.790641\n",
      "min      579.000000\n",
      "25%      874.000000\n",
      "50%      890.000000\n",
      "75%      903.000000\n",
      "max      941.000000\n",
      "Name: lda_reduction, dtype: float64\n",
      "\n",
      "lsi\n",
      "count    453.000000\n",
      "mean     871.805740\n",
      "std       45.373156\n",
      "min      579.000000\n",
      "25%      861.000000\n",
      "50%      883.000000\n",
      "75%      899.000000\n",
      "max      941.000000\n",
      "Name: lsi_reduction, dtype: float64\n",
      "\n",
      "textrank\n",
      "count    453.00000\n",
      "mean     684.89404\n",
      "std       60.12875\n",
      "min      555.00000\n",
      "25%      640.00000\n",
      "50%      678.00000\n",
      "75%      720.00000\n",
      "max      920.00000\n",
      "Name: textrank_reduction, dtype: float64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for redu in reductions:\n",
    "    print(redu)\n",
    "    print(df[redu+'_reduction'].map(tokenizer.encode).map(len).describe())\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BjUSYyty8Jlx"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "P95DxvqWi_2Y",
    "Yib4JoG59ZhY",
    "S0FByNNOIRvG",
    "tb7fAfzaK4es",
    "JFd0ppeJyX1o",
    "SSd3WuiICKfQ",
    "8fXJEMYaCKfn",
    "z1by1i56qQ0q",
    "UMPw10hNljZ1",
    "WhO2hirsvrcc",
    "W4K-CTF-vtha",
    "IeDlmvn43RsI",
    "z2es0TkqG7Q8",
    "NfsBzMt1OoAP",
    "1x886q72Ggs0",
    "L9AIlf42vH_v",
    "X2xp7jJNwB6b",
    "VndEUBoDjjkV"
   ],
   "name": "topic_modeling.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "3a0917c309734495885543d54e7bd8c2": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_d2951197dc524cf398449229119fc731",
       "IPY_MODEL_3607591535e04a18851f3ef1cb96afa1"
      ],
      "layout": "IPY_MODEL_e605902f06844a85be28925d0fc208e4"
     }
    },
    "7aa26b43182d43058c2a04e7cec5cf71": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_cf6df9999a93469ab081ff01db781b25",
       "IPY_MODEL_5d28e3032abe4568bc298405b0677d1c"
      ],
      "layout": "IPY_MODEL_b63c21b93cb846999844233e6bdea0c3"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
